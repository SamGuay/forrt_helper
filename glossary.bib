
@article{duyx_strong_2019,
	title = {The strong focus on positive results in abstracts may cause bias in systematic reviews: a case study on abstract reporting bias},
	volume = {8},
	issn = {2046-4053},
	shorttitle = {The strong focus on positive results in abstracts may cause bias in systematic reviews},
	url = {10.1186/s13643-019-1082-9},
	doi = {10.1186/s13643-019-1082-9},
	language = {en},
	number = {1},
	urldate = {2021-07-08},
	journal = {Systematic Reviews},
	author = {Duyx, Bram and Swaen, Gerard M. H. and Urlings, Miriam J. E. and Bouter, Lex M. and Zeegers, Maurice P.},
	month = dec,
	year = {2019},
	pages = {174},
}

@misc{noauthor_what_nodate,
	title = {What is impact? - {Economic} and {Social} {Research} {Council}},
	url = {https://esrc.ukri.org/research/impact-toolkit/what-is-impact/},
	urldate = {2021-07-08},
	journal = {Economic and Social Research Council},
}

@article{arslan_how_2019,
	title = {How to {Automatically} {Document} {Data} {With} the \textit{codebook} {Package} to {Facilitate} {Data} {Reuse}},
	volume = {2},
	issn = {2515-2459, 2515-2467},
	url = {10.1177/2515245919838783},
	doi = {10.1177/2515245919838783},
	abstract = {Data documentation in psychology lags behind not only many other disciplines, but also basic standards of usefulness. Psychological scientists often prefer to invest the time and effort that would be necessary to document existing data well in other duties, such as writing and collecting more data. Codebooks therefore tend to be unstandardized and stored in proprietary formats, and they are rarely properly indexed in search engines. This means that rich data sets are sometimes used only once—by their creators—and left to disappear into oblivion. Even if they can find an existing data set, researchers are unlikely to publish analyses based on it if they cannot be confident that they understand it well enough. My codebook package makes it easier to generate rich metadata in human- and machine-readable codebooks. It uses metadata from existing sources and automates some tedious tasks, such as documenting psychological scales and reliabilities, summarizing descriptive statistics, and identifying patterns of missingness. The codebook R package and Web app make it possible to generate a rich codebook in a few minutes and just three clicks. Over time, its use could lead to psychological data becoming findable, accessible, interoperable, and reusable, thereby reducing research waste and benefiting both its users and the scientific community as a whole.},
	language = {en},
	number = {2},
	urldate = {2021-07-08},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Arslan, Ruben C.},
	month = jun,
	year = {2019},
	pages = {169--187},
}

@article{tvina_bias_2019,
	title = {Bias in the {Peer} {Review} {Process}: {Can} {We} {Do} {Better}?},
	volume = {133},
	issn = {0029-7844},
	shorttitle = {Bias in the {Peer} {Review} {Process}},
	url = {10.1097/AOG.0000000000003260},
	doi = {10.1097/AOG.0000000000003260},
	language = {en},
	number = {6},
	urldate = {2021-07-08},
	journal = {Obstetrics \& Gynecology},
	author = {Tvina, Alina and Spellecy, Ryan and Palatnik, Anna},
	month = jun,
	year = {2019},
	pages = {1081--1083},
}

@article{kiureghian_aleatory_2009,
	title = {Aleatory or epistemic? {Does} it matter?},
	volume = {31},
	issn = {01674730},
	shorttitle = {Aleatory or epistemic?},
	url = {10.1016/j.strusafe.2008.06.020},
	doi = {10.1016/j.strusafe.2008.06.020},
	language = {en},
	number = {2},
	urldate = {2021-07-08},
	journal = {Structural Safety},
	author = {Kiureghian, Armen Der and Ditlevsen, Ove},
	month = mar,
	year = {2009},
	pages = {105--112},
}

@article{galligan_altmetrics_2013,
	title = {Altmetrics: {Rethinking} the {Way} {We} {Measure}},
	volume = {39},
	issn = {0098-7913, 1879-095X},
	shorttitle = {Altmetrics},
	url = {10.1080/00987913.2013.10765486},
	doi = {10.1080/00987913.2013.10765486},
	language = {en},
	number = {1},
	urldate = {2021-07-08},
	journal = {Serials Review},
	author = {Galligan, Finbar and Dyas-Correia, Sharon},
	month = mar,
	year = {2013},
	pages = {56--61},
}

@article{ali_understanding_2021,
	title = {Understanding the {Altmetrics}},
	issn = {0882-0538, 1744-5205},
	url = {10.1080/08820538.2021.1930806},
	doi = {10.1080/08820538.2021.1930806},
	language = {en},
	urldate = {2021-07-08},
	journal = {Seminars in Ophthalmology},
	author = {Ali, Mohammad Javed},
	month = may,
	year = {2021},
	pages = {1--3},
}

@article{deutsche_forschungsgemeinschaft_guidelines_2019,
	title = {Guidelines for {Safeguarding} {Good} {Research} {Practice}. {Code} of {Conduct}},
	copyright = {Creative Commons Attribution Share Alike 4.0 International, Open Access},
	url = {https://zenodo.org/record/3923602},
	doi = {10.5281/ZENODO.3923602},
	abstract = {The DFG´s Code of Conduct “Safeguarding Good Research Practice” represents the consensus among the member organisations of the DFG on the fundamental principles and standards of good practice and are upheld by these organisations. These guidelines underline the importance of integrity in the everyday practice of research and provide researchers with a reliable reference with which to embed good research practice as an established and binding aspect of their work.},
	language = {de},
	urldate = {2021-07-08},
	author = {Deutsche Forschungsgemeinschaft},
	month = sep,
	year = {2019},
	note = {Publisher: Zenodo},
	keywords = {code of conduct, Deutsche Forschungsgemeinschaft, DFG, German research foundation, good scientific practice, gute wissenschaftliche Praxis, Kodex, Leitlinien zur Sicherung guter wissenschaftlicher Praxis, research integrity, scientific misconduct, Wissenschaftliche Integrität, wissenschaftliches Fehlverhalten},
}

@article{mcnutt_transparency_2018,
	title = {Transparency in authors’ contributions and responsibilities to promote integrity in scientific publication},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {10.1073/pnas.1715374115},
	doi = {10.1073/pnas.1715374115},
	abstract = {In keeping with the growing movement in scientific publishing toward transparency in data and methods, we propose changes to journal authorship policies and procedures to provide insight into which author is responsible for which contributions, better assurance that the list is complete, and clearly articulated standards to justify earning authorship credit. To accomplish these goals, we recommend that journals adopt common and transparent standards for authorship, outline responsibilities for corresponding authors, adopt the Contributor Roles Taxonomy (CRediT) (
              docs.casrai.org/CRediT
              ) methodology for attributing contributions, include this information in article metadata, and require authors to use the ORCID persistent digital identifier (
              https://orcid.org
              ). Additionally, we recommend that universities and research institutions articulate expectations about author roles and responsibilities to provide a point of common understanding for discussion of authorship across research teams. Furthermore, we propose that funding agencies adopt the ORCID identifier and accept the CRediT taxonomy. We encourage scientific societies to further authorship transparency by signing on to these recommendations and promoting them through their meetings and publications programs.},
	language = {en},
	number = {11},
	urldate = {2021-07-08},
	journal = {Proceedings of the National Academy of Sciences},
	author = {McNutt, Marcia K. and Bradford, Monica and Drazen, Jeffrey M. and Hanson, Brooks and Howard, Bob and Jamieson, Kathleen Hall and Kiermer, Véronique and Marcus, Emilie and Pope, Barbara Kline and Schekman, Randy and Swaminathan, Sowmya and Stang, Peter J. and Verma, Inder M.},
	month = mar,
	year = {2018},
	pages = {2557--2560},
}

@article{patience_intellectual_2019,
	title = {Intellectual contributions meriting authorship: {Survey} results from the top cited authors across all science categories},
	volume = {14},
	issn = {1932-6203},
	shorttitle = {Intellectual contributions meriting authorship},
	url = {10.1371/journal.pone.0198117},
	doi = {10.1371/journal.pone.0198117},
	language = {en},
	number = {1},
	urldate = {2021-07-08},
	journal = {PLOS ONE},
	author = {Patience, Gregory S. and Galli, Federico and Patience, Paul A. and Boffito, Daria C.},
	editor = {Sugimoto, Cassidy Rose},
	month = jan,
	year = {2019},
	pages = {e0198117},
}

@book{allea_-_all_european_academies_european_2017,
	address = {Berlin},
	edition = {Revised Edition},
	title = {The {European} {Code} of {Conduct} for {Research} {Integrity}},
	url = {https://allea.org/code-of-conduct/},
	language = {en-US},
	urldate = {2021-07-08},
	publisher = {ALLEA},
	author = {{ALLEA - All European Academies}},
	year = {2017},
}

@article{dienes_bayesian_2011,
	title = {Bayesian {Versus} {Orthodox} {Statistics}: {Which} {Side} {Are} {You} {On}?},
	volume = {6},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Bayesian {Versus} {Orthodox} {Statistics}},
	url = {10.1177/1745691611406920},
	doi = {10.1177/1745691611406920},
	abstract = {Researchers are often confused about what can be inferred from significance tests. One problem occurs when people apply Bayesian intuitions to significance testing—two approaches that must be firmly separated. This article presents some common situations in which the approaches come to different conclusions; you can see where your intuitions initially lie. The situations include multiple testing, deciding when to stop running participants, and when a theory was thought of relative to finding out results. The interpretation of nonsignificant results has also been persistently problematic in a way that Bayesian inference can clarify. The Bayesian and orthodox approaches are placed in the context of different notions of rationality, and I accuse myself and others as having been irrational in the way we have been using statistics on a key notion of rationality. The reader is shown how to apply Bayesian inference in practice, using free online software, to allow more coherent inferences from data.},
	language = {en},
	number = {3},
	urldate = {2021-07-08},
	journal = {Perspectives on Psychological Science},
	author = {Dienes, Zoltan},
	month = may,
	year = {2011},
	pages = {274--290},
}

@article{dienes_using_2014,
	title = {Using {Bayes} to get the most out of non-significant results},
	volume = {5},
	issn = {1664-1078},
	url = {10.3389/fpsyg.2014.00781},
	doi = {10.3389/fpsyg.2014.00781},
	urldate = {2021-07-08},
	journal = {Frontiers in Psychology},
	author = {Dienes, Zoltan},
	month = jul,
	year = {2014},
}

@article{dienes_how_2016,
	title = {How {Bayes} factors change scientific practice},
	volume = {72},
	issn = {00222496},
	url = {10.1016/j.jmp.2015.10.003},
	doi = {10.1016/j.jmp.2015.10.003},
	language = {en},
	urldate = {2021-07-08},
	journal = {Journal of Mathematical Psychology},
	author = {Dienes, Zoltan},
	month = jun,
	year = {2016},
	pages = {78--89},
}

@book{dienes_understanding_2008,
	title = {Understanding {Psychology} as a {Science}: {An} {Introduction} to {Scientific} and {Statistical} {Inference}},
	isbn = {978-1-137-09605-0},
	url = {https://books.google.ca/books?id=qCQdBQAAQBAJ},
	publisher = {Palgrave Macmillan},
	author = {Dienes, Z.},
	year = {2008},
}

@book{lakatos_methodology_1978,
	address = {Cambridge},
	title = {The {Methodology} of {Scientiﬁc} {Research} {Programs}},
	volume = {I},
	publisher = {Cambridge University Press},
	author = {Lakatos, I},
	year = {1978},
}

@misc{science_open_nodate,
	title = {Open {Science} {Badges}},
	url = {https://www.cos.io/initiatives/badges},
	urldate = {2021-07-09},
	journal = {Centre for Open Science},
	author = {{Science}},
}

@article{rowhani-farid_did_2020,
	title = {Did awarding badges increase data sharing in \textit{{BMJ} {Open}} ? {A} randomized controlled trial},
	volume = {7},
	issn = {2054-5703},
	shorttitle = {Did awarding badges increase data sharing in \textit{{BMJ} {Open}} ?},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.191818},
	doi = {10.1098/rsos.191818},
	abstract = {Sharing data and code are important components of reproducible research. Data sharing in research is widely discussed in the literature; however, there are no well-established evidence-based incentives that reward data sharing, nor randomized studies that demonstrate the effectiveness of data sharing policies at increasing data sharing. A simple incentive, such as an Open Data Badge, might provide the change needed to increase data sharing in health and medical research. This study was a parallel group randomized controlled trial (protocol registration:
              doi:10.17605/OSF.IO/PXWZQ
              ) with two groups, control and intervention, with 80 research articles published in
              BMJ Open
              per group, with a total of 160 research articles. The intervention group received an email offer for an Open Data Badge if they shared their data along with their final publication and the control group received an email with no offer of a badge if they shared their data with their final publication. The primary outcome was the data sharing rate. Badges did not noticeably motivate researchers who published in
              BMJ Open
              to share their data; the odds of awarding badges were nearly equal in the intervention and control groups (odds ratio = 0.9, 95\% CI [0.1, 9.0]). Data sharing rates were low in both groups, with just two datasets shared in each of the intervention and control groups. The global movement towards open science has made significant gains with the development of numerous data sharing policies and tools. What remains to be established is an effective incentive that motivates researchers to take up such tools to share their data.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Royal Society Open Science},
	author = {Rowhani-Farid, Anisa and Aldcroft, Adrian and Barnett, Adrian G.},
	month = mar,
	year = {2020},
	pages = {191818},
}

@article{kidwell_badges_2016,
	title = {Badges to {Acknowledge} {Open} {Practices}: {A} {Simple}, {Low}-{Cost}, {Effective} {Method} for {Increasing} {Transparency}},
	volume = {14},
	issn = {1545-7885},
	shorttitle = {Badges to {Acknowledge} {Open} {Practices}},
	url = {https://dx.plos.org/10.1371/journal.pbio.1002456},
	doi = {10.1371/journal.pbio.1002456},
	language = {en},
	number = {5},
	urldate = {2021-07-09},
	journal = {PLOS Biology},
	author = {Kidwell, Mallory C. and Lazarević, Ljiljana B. and Baranski, Erica and Hardwicke, Tom E. and Piechowski, Sarah and Falkenberg, Lina-Sophia and Kennett, Curtis and Slowik, Agnieszka and Sonnleitner, Carina and Hess-Holden, Chelsey and Errington, Timothy M. and Fiedler, Susann and Nosek, Brian A.},
	editor = {Macleod, Malcolm R},
	month = may,
	year = {2016},
	pages = {e1002456},
}

@article{hardwicke_analytic_2021,
	title = {Analytic reproducibility in articles receiving open data badges at the journal \textit{{Psychological} {Science}} : an observational study},
	volume = {8},
	issn = {2054-5703},
	shorttitle = {Analytic reproducibility in articles receiving open data badges at the journal \textit{{Psychological} {Science}}},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.201494},
	doi = {10.1098/rsos.201494},
	abstract = {For any scientific report, repeating the original analyses upon the original data should yield the original outcomes. We evaluated analytic reproducibility in 25
              Psychological Science
              articles awarded open data badges between 2014 and 2015. Initially, 16 (64\%, 95\% confidence interval [43,81]) articles contained at least one ‘major numerical discrepancy' ({\textgreater}10\% difference) prompting us to request input from original authors. Ultimately, target values were reproducible without author involvement for 9 (36\% [20,59]) articles; reproducible with author involvement for 6 (24\% [8,47]) articles; not fully reproducible with no substantive author response for 3 (12\% [0,35]) articles; and not fully reproducible despite author involvement for 7 (28\% [12,51]) articles. Overall, 37 major numerical discrepancies remained out of 789 checked values (5\% [3,6]), but original conclusions did not appear affected. Non-reproducibility was primarily caused by unclear reporting of analytic procedures. These results highlight that open data alone is not sufficient to ensure analytic reproducibility.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Royal Society Open Science},
	author = {Hardwicke, Tom E. and Bohn, Manuel and MacDonald, Kyle and Hembacher, Emily and Nuijten, Michèle B. and Peloquin, Benjamin N. and deMayo, Benjamin E. and Long, Bria and Yoon, Erica J. and Frank, Michael C.},
	month = jan,
	year = {2021},
	pages = {201494},
}

@article{hardwicke_only_2014,
	title = {Only {Human}: {Scientists}, {Systems}, and {Suspect} {Statistics}},
	issn = {2049-8128},
	shorttitle = {Only {Human}},
	url = {http://www.opticon1826.com/articles/10.5334/opt.ch/},
	doi = {10.5334/opt.ch},
	language = {en},
	number = {16},
	urldate = {2021-07-09},
	journal = {Opticon1826},
	author = {Hardwicke, Tom E. and Jameel, Leila and Jones, Matthew and Walczak, Eryk J. and Magis-Weinberg, Lucía},
	month = dec,
	year = {2014},
}

@techreport{smith_assessing_2020,
	type = {preprint},
	title = {Assessing the effect of article processing charges on the geographic diversity of authors using {Elsevier}’s ‘{Mirror} {Journal}’ system},
	url = {https://osf.io/s7cx4},
	abstract = {Journals publishing open access (OA) articles often require that authors pay article processing charges (APC). Researchers in the Global South often cite APCs as a major financial obstacle to OA publishing, especially in widely-recognized or prestigious outlets. Consequently, it has been hypothesized that authors from the Global South will be underrepresented in journals charging APCs. We tested this hypothesis using \&gt;37,000 articles from Elsevier's 'Mirror journal' system, in which a hybrid 'Parent' journal and its Gold-OA 'Mirror' share editorial boards and standards for acceptance. Most articles were non-OA; 45\% of articles had lead authors based in either the United States of America (USA) or China. After correcting for the effect of this dominance and differences in sample size, we found that OA articles published in Parent and Mirror journals had lead authors with similar Geographic Diversity. However, Author Geographic Diversity of OA articles was significantly lower than that of non-OA articles. Most OA articles were written by authors in high-income countries, and there were no articles in Mirror journals by authors in low-income countries. Our results for Elsevier's Mirror-Parent system are consistent with the hypothesis that APCs are a barrier to OA publication for scientists from the Global South.},
	urldate = {2021-07-09},
	institution = {MetaArXiv},
	author = {Smith, Audrey Culver and Merz, Leandra and Borden, Jesse B. and Gulick, Chris and Kshirsagar, Akhil Ravindra and Bruna, Emilio Miguel},
	month = sep,
	year = {2020},
	doi = {10.31222/osf.io/s7cx4},
}

@article{grossmann_current_2021,
	title = {Current market rates for scholarly publishing services},
	volume = {10},
	issn = {2046-1402},
	url = {https://f1000research.com/articles/10-20/v1},
	doi = {10.12688/f1000research.27468.1},
	abstract = {For decades, the supra-inflation increase of subscription prices for scholarly journals has concerned scholarly institutions. After years of fruitless efforts to solve this “serials crisis”, open access has been proposed as the latest potential solution. However, the prices for open access publishing are also high and are rising well beyond inflation. What has been missing from the public discussion so far is a quantitative approach to determine the actual
              costs
              of efficiently publishing a scholarly article using state-of-the-art technologies, such that informed decisions can be made as to appropriate
              price
              levels. Here we provide a granular, step-by-step calculation of the costs associated with publishing primary research articles, from submission, through peer-review, to publication, indexing and archiving. We find that these costs range from less than US\$200 per article in modern, large-scale publishing platforms using post-publication peer-review, to about US\$1,000 per article in prestigious journals with rejection rates exceeding 90\%. The publication costs for a representative scholarly article today come to lie at around US\$400. We discuss the additional non-publication items that make up the difference between publication costs and final price.},
	language = {en},
	urldate = {2021-07-09},
	journal = {F1000Research},
	author = {Grossmann, Alexander and Brembs, Björn},
	month = jan,
	year = {2021},
	pages = {20},
}

@article{percie_du_sert_arrive_2020,
	title = {The {ARRIVE} guidelines 2.0: {Updated} guidelines for reporting animal research},
	volume = {18},
	issn = {1545-7885},
	shorttitle = {The {ARRIVE} guidelines 2.0},
	url = {https://dx.plos.org/10.1371/journal.pbio.3000410},
	doi = {10.1371/journal.pbio.3000410},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {PLOS Biology},
	author = {Percie du Sert, Nathalie and Hurst, Viki and Ahluwalia, Amrita and Alam, Sabina and Avey, Marc T. and Baker, Monya and Browne, William J. and Clark, Alejandra and Cuthill, Innes C. and Dirnagl, Ulrich and Emerson, Michael and Garner, Paul and Holgate, Stephen T. and Howells, David W. and Karp, Natasha A. and Lazic, Stanley E. and Lidster, Katie and MacCallum, Catriona J. and Macleod, Malcolm and Pearl, Esther J. and Petersen, Ole H. and Rawle, Frances and Reynolds, Penny and Rooney, Kieron and Sena, Emily S. and Silberberg, Shai D. and Steckler, Thomas and Würbel, Hanno},
	editor = {Boutron, Isabelle},
	month = jul,
	year = {2020},
	pages = {e3000410},
}

@book{braun_successful_2013,
	address = {Thousand Oaks},
	title = {Successful qualitative research: {A} practical guide for beginners.},
	isbn = {978-1-84787-581-5},
	url = {https://books.google.co.uk/books?hl=en&lr=&id=nYMQAgAAQBAJ&oi=fnd&pg=PP2&ots=SqJAD7C-5w&sig=6hBnRUj4z31CbylBTRzfIudISME#v=onepage&q&f=false},
	publisher = {Sage},
	author = {Braun, Virginia and Clarke, Victoria},
	year = {2013},
	keywords = {Qualitative research, Research Methodology, Social sciences},
}

@article{simmons_false-positive_2011,
	title = {False-{Positive} {Psychology}: {Undisclosed} {Flexibility} in {Data} {Collection} and {Analysis} {Allows} {Presenting} {Anything} as {Significant}},
	volume = {22},
	issn = {0956-7976, 1467-9280},
	shorttitle = {False-{Positive} {Psychology}},
	url = {http://journals.sagepub.com/doi/10.1177/0956797611417632},
	doi = {10.1177/0956797611417632},
	abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists’ nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	language = {en},
	number = {11},
	urldate = {2021-07-09},
	journal = {Psychological Science},
	author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	month = nov,
	year = {2011},
	pages = {1359--1366},
}

@article{jones_may_2021,
	title = {May {I} have your attention, please? {Methodological} and analytical flexibility in the addiction stroop},
	issn = {1606-6359, 1476-7392},
	shorttitle = {May {I} have your attention, please?},
	url = {https://www.tandfonline.com/doi/full/10.1080/16066359.2021.1876847},
	doi = {10.1080/16066359.2021.1876847},
	language = {en},
	urldate = {2021-07-09},
	journal = {Addiction Research \& Theory},
	author = {Jones, Andrew and Worrall, Semra and Rudin, Lara and Duckworth, Jay J. and Christiansen, Paul},
	month = mar,
	year = {2021},
	pages = {1--14},
}

@article{carp_plurality_2012,
	title = {On the {Plurality} of ({Methodological}) {Worlds}: {Estimating} the {Analytic} {Flexibility} of {fMRI} {Experiments}},
	volume = {6},
	issn = {1662-4548},
	shorttitle = {On the {Plurality} of ({Methodological}) {Worlds}},
	url = {http://journal.frontiersin.org/article/10.3389/fnins.2012.00149/abstract},
	doi = {10.3389/fnins.2012.00149},
	urldate = {2021-07-09},
	journal = {Frontiers in Neuroscience},
	author = {Carp, Joshua},
	year = {2012},
}

@misc{open_aire_amnesia_nodate,
	title = {Amnesia {Anonymization} {Tool} - {Data} anonymization made easy},
	url = {https://amnesia.openaire.eu/},
	urldate = {2021-07-09},
	journal = {High accuracy Data anonymisation.},
	author = {{Open Aire}},
}

@article{silberzahn_matched-names_2014,
	title = {Matched-{Names} {Analysis} {Reveals} {No} {Evidence} of {Name}-{Meaning} {Effects}: {A} {Collaborative} {Commentary} on {Silberzahn} and {Uhlmann} (2013)},
	volume = {25},
	issn = {0956-7976, 1467-9280},
	shorttitle = {Matched-{Names} {Analysis} {Reveals} {No} {Evidence} of {Name}-{Meaning} {Effects}},
	url = {http://journals.sagepub.com/doi/10.1177/0956797614533802},
	doi = {10.1177/0956797614533802},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {Psychological Science},
	author = {Silberzahn, Raphael and Simonsohn, Uri and Uhlmann, Eric Luis},
	month = jul,
	year = {2014},
	pages = {1504--1505},
}

@article{rabagliati_can_2020,
	title = {Can {Item} {Effects} {Explain} {Away} the {Evidence} for {Unconscious} {Sound} {Symbolism}? {An} {Adversarial} {Commentary} on {Heyman}, {Maerten}, {Vankrunkelsven}, {Voorspoels}, and {Moors} (2019)},
	volume = {31},
	issn = {0956-7976, 1467-9280},
	shorttitle = {Can {Item} {Effects} {Explain} {Away} the {Evidence} for {Unconscious} {Sound} {Symbolism}?},
	url = {http://journals.sagepub.com/doi/10.1177/0956797620949461},
	doi = {10.1177/0956797620949461},
	language = {en},
	number = {9},
	urldate = {2021-07-09},
	journal = {Psychological Science},
	author = {Rabagliati, Hugh and Moors, Pieter and Heyman, Tom},
	month = sep,
	year = {2020},
	pages = {1200--1204},
}

@article{heyman_benefits_2020,
	title = {The benefits of adversarial collaboration for commentaries},
	volume = {4},
	issn = {2397-3374},
	url = {http://www.nature.com/articles/s41562-020-00978-6},
	doi = {10.1038/s41562-020-00978-6},
	language = {en},
	number = {12},
	urldate = {2021-07-09},
	journal = {Nature Human Behaviour},
	author = {Heyman, Tom and Moors, Pieter and Rabagliati, Hugh},
	month = dec,
	year = {2020},
	pages = {1217--1217},
}

@article{rakow_rationale_2015,
	title = {Rationale and guidelines for empirical adversarial collaboration: {A} \textit{{Thinking} \& {Reasoning}} initiative},
	volume = {21},
	issn = {1354-6783, 1464-0708},
	shorttitle = {Rationale and guidelines for empirical adversarial collaboration},
	url = {http://www.tandfonline.com/doi/abs/10.1080/13546783.2015.975405},
	doi = {10.1080/13546783.2015.975405},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Thinking \& Reasoning},
	author = {Rakow, Tim and Thompson, Valerie and Ball, Linden and Markovits, Henry},
	month = apr,
	year = {2015},
	pages = {167--175},
}

@article{mellers_frequency_2001,
	title = {Do {Frequency} {Representations} {Eliminate} {Conjunction} {Effects}? {An} {Exercise} in {Adversarial} {Collaboration}},
	volume = {12},
	issn = {0956-7976, 1467-9280},
	shorttitle = {Do {Frequency} {Representations} {Eliminate} {Conjunction} {Effects}?},
	url = {http://journals.sagepub.com/doi/10.1111/1467-9280.00350},
	doi = {10.1111/1467-9280.00350},
	abstract = {The present article offers an approach to scientific debate called adversarial collaboration. The approach requires both parties to agree on empirical tests for resolving a dispute and to conduct these tests with the help of an arbiter. In dispute were Hertwig's claims that frequency formats eliminate conjunction effects and that the conjunction effects previously reported by Kahneman and Tversky occurred because some participants interpreted the word “and” in “bank tellers and feminists” as a union operator. Hertwig proposed two new conjunction phrases, “and are” and “who are,” that would eliminate the ambiguity. Kahneman disagreed with Hertwig's predictions for “and are,” but agreed with his predictions for “who are.” Mellers served as arbiter. Frequency formats by themselves did not eliminate conjunction effects with any of the phrases, but when filler items were removed, conjunction effects disappeared with Hertwig's phrases. Kahneman and Hertwig offer different interpretations of the findings. We discuss the benefits of adversarial collaboration over replies and rejoinders, and present a suggested protocol for adversarial collaboration.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Psychological Science},
	author = {Mellers, Barbara and Hertwig, Ralph and Kahneman, Daniel},
	month = jul,
	year = {2001},
	pages = {269--275},
}

@article{kerr_addressing_2018,
	title = {Addressing replicability concerns via adversarial collaboration: {Discovering} hidden moderators of the minimal intergroup discrimination effect},
	volume = {78},
	issn = {00221031},
	shorttitle = {Addressing replicability concerns via adversarial collaboration},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022103117306352},
	doi = {10.1016/j.jesp.2018.05.001},
	language = {en},
	urldate = {2021-07-09},
	journal = {Journal of Experimental Social Psychology},
	author = {Kerr, Norbert L. and Ao, Xiang and Hogg, Michael A. and Zhang, Jinghui},
	month = sep,
	year = {2018},
	pages = {66--76},
}

@article{kerr_harking_1998,
	title = {{HARKing}: {Hypothesizing} {After} the {Results} are {Known}},
	volume = {2},
	issn = {1088-8683, 1532-7957},
	shorttitle = {{HARKing}},
	url = {http://journals.sagepub.com/doi/10.1207/s15327957pspr0203_4},
	doi = {10.1207/s15327957pspr0203_4},
	abstract = {This article considers a practice in scientific communication termed HARKing (Hypothesizing After the Results are Known). HARKing is defined as presenting a post hoc hypothesis (i.e., one based on or informed by one's results) in one's research report as if it were, in fact, an a priori hypotheses. Several forms of HARKing are identified and survey data are presented that suggests that at least some forms of HARKing are widely practiced and widely seen as inappropriate. I identify several reasons why scientists might HARK. Then I discuss several reasons why scientists ought not to HARK. It is conceded that the question of whether HARKing's costs exceed its benefits is a complex one that ought to be addressed through research, open discussion, and debate. To help stimulate such discussion (and for those such as myself who suspect that HARKing's costs do exceed its benefits), I conclude the article with some suggestions for deterring HARKing.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Personality and Social Psychology Review},
	author = {Kerr, Norbert L.},
	month = aug,
	year = {1998},
	pages = {196--217},
}

@article{cowan_how_2020,
	title = {How {Do} {Scientific} {Views} {Change}? {Notes} {From} an {Extended} {Adversarial} {Collaboration}},
	volume = {15},
	issn = {1745-6916, 1745-6924},
	shorttitle = {How {Do} {Scientific} {Views} {Change}?},
	url = {http://journals.sagepub.com/doi/10.1177/1745691620906415},
	doi = {10.1177/1745691620906415},
	abstract = {There are few examples of an extended adversarial collaboration, in which investigators committed to different theoretical views collaborate to test opposing predictions. Whereas previous adversarial collaborations have produced single research articles, here, we share our experience in programmatic, extended adversarial collaboration involving three laboratories in different countries with different theoretical views regarding working memory, the limited information retained in mind, serving ongoing thought and action. We have focused on short-term memory retention of items (letters) during a distracting task (arithmetic), and effects of aging on these tasks. Over several years, we have conducted and published joint research with preregistered predictions, methods, and analysis plans, with replication of each study across two laboratories concurrently. We argue that, although an adversarial collaboration will not usually induce senior researchers to abandon favored theoretical views and adopt opposing views, it will necessitate varieties of their views that are more similar to one another, in that they must account for a growing, common corpus of evidence. This approach promotes understanding of others’ views and presents to the field research findings accepted as valid by researchers with opposing interpretations. We illustrate this process with our own research experiences and make recommendations applicable to diverse scientific areas.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Cowan, Nelson and Belletier, Clément and Doherty, Jason M. and Jaroslawska, Agnieszka J. and Rhodes, Stephen and Forsberg, Alicia and Naveh-Benjamin, Moshe and Barrouillet, Pierre and Camos, Valérie and Logie, Robert H.},
	month = jul,
	year = {2020},
	pages = {1011--1025},
}

@article{bateman_testing_2005,
	title = {Testing competing models of loss aversion: an adversarial collaboration},
	volume = {89},
	issn = {00472727},
	shorttitle = {Testing competing models of loss aversion},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047272704001689},
	doi = {10.1016/j.jpubeco.2004.06.013},
	language = {en},
	number = {8},
	urldate = {2021-07-09},
	journal = {Journal of Public Economics},
	author = {Bateman, Ian and Kahneman, Daniel and Munro, Alistair and Starmer, Chris and Sugden, Robert},
	month = aug,
	year = {2005},
	pages = {1561--1580},
}

@article{barnes_effect_2018,
	title = {The effect of ad hominem attacks on the evaluation of claims promoted by scientists},
	volume = {13},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0192025},
	doi = {10.1371/journal.pone.0192025},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {PLOS ONE},
	author = {Barnes, Ralph M. and Johnston, Heather M. and MacKenzie, Noah and Tobin, Stephanie J. and Taglang, Chelsea M.},
	editor = {Smalheiser, Neil R.},
	month = jan,
	year = {2018},
	pages = {e0192025},
}

@misc{suber_its_2004,
	title = {"{It}'s the authors, stupid!"},
	url = {https://dash.harvard.edu/bitstream/handle/1/4391161/suber_authors.htm?sequence=1&isAllowed=y},
	urldate = {2021-07-09},
	journal = {SPARC Open Access Newsletter},
	author = {Suber, P.},
	month = feb,
	year = {2004},
}

@misc{world_wide_web_consortium_home_nodate,
	title = {Home {\textbar} {Web} {Accessibility} {Initiative} ({WAI}) {\textbar} {W3C}},
	url = {https://www.w3.org/WAI/},
	urldate = {2021-07-09},
	journal = {Web Accessibility Initiative},
	author = {{World Wide Web Consortium}},
}

@article{brown_making_2018,
	title = {Making {Academia} {More} {Accessible}},
	volume = {6},
	issn = {2051-9788},
	url = {https://jpaap.napier.ac.uk/index.php/JPAAP/article/view/348},
	doi = {10.14297/jpaap.v6i2.348},
	abstract = {Academia can be a challenging place to work and academics who have a disability, neurodiversity or chronic illness are further disadvantaged, as non-stereotypical ways of working are not necessarily supported or catered for. The remit of this paper is to provide practical ideas and recommendations to address accessibility issues in events and conferences as a first step to improving existing working conditions. We start with providing a brief overview of and background to the issues of ableism, disabilities, chronic illnesses and neurodiversities in academia. We then offer a detailed description of the organisational and developmental strategies relating to the Ableism in Academia conference to practically demonstrate how accessibility can be achieved. Despite vast literature available on theorisations of reasonable adjustments and some individual handbooks on conference accessibility, noted the absence of a systematic write-up of a case study that would demonstrate the thought processes required for the organisation of a fully accessible and inclusive event. This paper provides almost a step-by-step rationale and rundown of the decisions that had to be taken in order to facilitate an accessible event. After a brief consideration of challenges we encountered along the way, we share personal reflections regarding the event and future developments.},
	number = {2},
	urldate = {2021-07-09},
	journal = {Journal of Perspectives in Applied Academic Practice},
	author = {Brown, Nicole and Thompson, Paul and Leigh, Jennifer S},
	month = sep,
	year = {2018},
	pages = {82--90},
}

@article{pollet_evaluation_2021,
	title = {Evaluation and recommendations for greater accessibility of colour figures in ornithology},
	volume = {163},
	issn = {0019-1019, 1474-919X},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/ibi.12887},
	doi = {10.1111/ibi.12887},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Ibis},
	author = {Pollet, Ingrid L. and Bond, Alexander L.},
	month = jan,
	year = {2021},
	pages = {292--295},
}

@techreport{pownall_navigating_2020,
	type = {preprint},
	title = {Navigating {Open} {Science} as {Early} {Career} {Feminist} {Researchers}},
	url = {https://osf.io/f9m47},
	abstract = {[Note that this paper is currently in press at Psychology of Women Quarterly in the Special Issue on Feminist Psychology and Open Science] Open science aims to improve the rigor, robustness, and reproducibility of psychological research. Despite resistance from some academics, the open science movement has been championed by some early career researchers, who have proposed innovative new tools and methods to promote and employ open research principles. Feminist early career researchers  have much to contribute to this emerging way of doing research. However, they face unique barriers, which may prohibit their full engagement with the open science movement. We, ten feminist early career researchers in psychology, from a diverse range of academic and personal backgrounds, explore open science through a feminist lens, to consider how voice and power may be negotiated in unique ways for early career researchers. Taking a critical and intersectional approach, we discuss    how feminist early career research may be complemented or challenged by shifts towards open science. We also propose how early career researchers can act as grassroots changemakers within the context of academic precarity. We identify ways in which open science can benefit from feminist epistemology and end with envisaging a future for feminist early career researchers who wish to engage with open science practices in their own research.},
	urldate = {2021-07-09},
	institution = {PsyArXiv},
	author = {Pownall, Madeleine and Talbot, Catherine V. and Henschel, Anna and Lautarescu, Alexandra and Lloyd, Kelly and Hartmann, Helena and Darda, Kohinoor Monish and Tang, Karen T. Y. and Carmichael-Murphy, Parise and Siegel, Jaclyn Amanda},
	month = oct,
	year = {2020},
	doi = {10.31234/osf.io/f9m47},
}

@article{open_science_collaboration_estimating_2015,
	title = {Estimating the reproducibility of psychological science},
	volume = {349},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aac4716},
	doi = {10.1126/science.aac4716},
	language = {en},
	number = {6251},
	urldate = {2021-07-09},
	journal = {Science},
	author = {{Open Science Collaboration}},
	month = aug,
	year = {2015},
	pages = {aac4716--aac4716},
}

@article{nosek_scientific_2012,
	title = {Scientific {Utopia}: {I}. {Opening} {Scientific} {Communication}},
	volume = {23},
	issn = {1047-840X, 1532-7965},
	shorttitle = {Scientific {Utopia}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/1047840X.2012.692215},
	doi = {10.1080/1047840X.2012.692215},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Psychological Inquiry},
	author = {Nosek, Brian A. and Bar-Anan, Yoav},
	month = jul,
	year = {2012},
	pages = {217--243},
}

@techreport{syed_cultural_2020,
	type = {preprint},
	title = {Cultural {Psychology}, {Diversity}, and {Representation} in {Open} {Science}},
	url = {https://osf.io/t7hp2},
	abstract = {The current moment in psychology is one of great challenges and great opportunities. The open science movement--the move towards more transparent, credible, and reproducible science--has led to a redefinition of what constitutes “normal science.” However, the field of cultural psychology, broadly construed, has by and large not engaged with the open science movement, and likewise, the open science movement has by and large not engaged with cultural psychology. The purpose of the present chapter is to bring open science and cultural psychology closer together, highlighting how they can benefit one another. In doing so, we focus our discussion on three types of representations regarding diversity in psychological research and how they intersect with open science: representation of researchers, or the diversity of the scientists actually doing the research, representation of samples, or who is included as participants in our research studies, and representation of perspectives, or the substantive conceptual and theoretical views we bring to our work. For each of these three types of representation we outline the problem, and then discuss how embracing the principles and behaviors of open science can help.},
	urldate = {2021-07-09},
	institution = {PsyArXiv},
	author = {Syed, Moin and Kathawalla, Ummul-Kiram},
	month = feb,
	year = {2020},
	doi = {10.31234/osf.io/t7hp2},
}

@article{kathawalla_easing_2021,
	title = {Easing {Into} {Open} {Science}: {A} {Guide} for {Graduate} {Students} and {Their} {Advisors}},
	volume = {7},
	issn = {2474-7394},
	shorttitle = {Easing {Into} {Open} {Science}},
	url = {https://online.ucpress.edu/collabra/article/doi/10.1525/collabra.18684/115927/Easing-Into-Open-Science-A-Guide-for-Graduate},
	doi = {10.1525/collabra.18684},
	abstract = {This article provides a roadmap to assist graduate students and their advisors to engage in open science practices. We suggest eight open science practices that novice graduate students could begin adopting today. The topics we cover include journal clubs, project workflow, preprints, reproducible code, data sharing, transparent writing, preregistration, and registered reports. To address concerns about not knowing how to engage in open science practices, we provide a difficulty rating of each behavior (easy, medium, difficult), present them in order of suggested adoption, and follow the format of what, why, how, and worries. We give graduate students ideas on how to approach conversations with their advisors/collaborators, ideas on how to integrate open science practices within the graduate school framework, and specific resources on how to engage with each behavior. We emphasize that engaging in open science behaviors need not be an all or nothing approach, but rather graduate students can engage with any number of the behaviors outlined.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Collabra: Psychology},
	author = {Kathawalla, Ummul-Kiram and Silverstein, Priya and Syed, Moin},
	month = jan,
	year = {2021},
	pages = {18684},
}

@article{cruwell_seven_2019,
	title = {Seven {Easy} {Steps} to {Open} {Science}: {An} {Annotated} {Reading} {List}},
	volume = {227},
	issn = {2190-8370, 2151-2604},
	shorttitle = {Seven {Easy} {Steps} to {Open} {Science}},
	url = {https://econtent.hogrefe.com/doi/10.1027/2151-2604/a000387},
	doi = {10.1027/2151-2604/a000387},
	abstract = {Abstract. The open science movement is rapidly changing the scientific landscape. Because exact definitions are often lacking and reforms are constantly evolving, accessible guides to open science are needed. This paper provides an introduction to open science and related reforms in the form of an annotated reading list of seven peer-reviewed articles, following the format of Etz, Gronau, Dablander, Edelsbrunner, and Baribault (2018) . Written for researchers and students – particularly in psychological science – it highlights and introduces seven topics: understanding open science; open access; open data, materials, and code; reproducible analyses; preregistration and registered reports; replication research; and teaching open science. For each topic, we provide a detailed summary of one particularly informative and actionable article and suggest several further resources. Supporting a broader understanding of open science issues, this overview should enable researchers to engage with, improve, and implement current open, transparent, reproducible, replicable, and cumulative scientific practices.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Zeitschrift für Psychologie},
	author = {Crüwell, Sophia and van Doorn, Johnny and Etz, Alexander and Makel, Matthew C. and Moshontz, Hannah and Niebaum, Jesse C. and Orben, Amy and Parsons, Sam and Schulte-Mecklenbeck, Michael},
	month = oct,
	year = {2019},
	pages = {237--248},
}

@article{holcombe_contributorship_2019,
	title = {Contributorship, {Not} {Authorship}: {Use} {CRediT} to {Indicate} {Who} {Did} {What}},
	volume = {7},
	issn = {2304-6775},
	shorttitle = {Contributorship, {Not} {Authorship}},
	url = {https://www.mdpi.com/2304-6775/7/3/48},
	doi = {10.3390/publications7030048},
	abstract = {Participation in the writing or revising of a manuscript is, according to many journal guidelines, necessary to be listed as an author of the resulting article. This is the traditional concept of authorship. But there are good reasons to shift to a contributorship model, under which it is not necessary to contribute to the writing or revision of a manuscript, and all those who make substantial contributions to a project are credited. Many journals and publishers have already taken steps in this direction, and further adoption will have several benefits. This article makes the case for continuing to move down that path. Use of a contributorship model should improve the ability of universities and funders to identify effective individual researchers and improving their ability to identify the right mix of researchers needed to advance modern science. Other benefits should include facilitating the formation of productive collaborations and the creation of important scientific tools and software. The CRediT (Contributor Roles Taxonomy) taxonomy is a machine-readable standard already incorporated into some journal management systems and it allows incremental transition toward contributorship.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Publications},
	author = {Holcombe, Alex O.},
	month = jul,
	year = {2019},
	pages = {48},
}

@article{brandt_replication_2014,
	title = {The {Replication} {Recipe}: {What} makes for a convincing replication?},
	volume = {50},
	issn = {00221031},
	shorttitle = {The {Replication} {Recipe}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022103113001819},
	doi = {10.1016/j.jesp.2013.10.005},
	language = {en},
	urldate = {2021-07-09},
	journal = {Journal of Experimental Social Psychology},
	author = {Brandt, Mark J. and IJzerman, Hans and Dijksterhuis, Ap and Farach, Frank J. and Geller, Jason and Giner-Sorolla, Roger and Grange, James A. and Perugini, Marco and Spies, Jeffrey R. and van 't Veer, Anna},
	month = jan,
	year = {2014},
	pages = {217--224},
}

@article{brand_beyond_2015,
	title = {Beyond authorship: attribution, contribution, collaboration, and credit},
	volume = {28},
	issn = {09531513, 17414857},
	shorttitle = {Beyond authorship},
	url = {http://doi.wiley.com/10.1087/20150211},
	doi = {10.1087/20150211},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Learned Publishing},
	author = {Brand, Amy and Allen, Liz and Altman, Micah and Hlava, Marjorie and Scott, Jo},
	month = apr,
	year = {2015},
	pages = {151--155},
}

@article{hoijtink_tutorial_2019,
	title = {A tutorial on testing hypotheses using the {Bayes} factor.},
	volume = {24},
	issn = {1939-1463, 1082-989X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000201},
	doi = {10.1037/met0000201},
	language = {en},
	number = {5},
	urldate = {2021-07-09},
	journal = {Psychological Methods},
	author = {Hoijtink, Herbert and Mulder, Joris and van Lissa, Caspar and Gu, Xin},
	month = oct,
	year = {2019},
	pages = {539--556},
}

@article{makowski_indices_2019,
	title = {Indices of {Effect} {Existence} and {Significance} in the {Bayesian} {Framework}},
	volume = {10},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767/full},
	doi = {10.3389/fpsyg.2019.02767},
	urldate = {2021-07-09},
	journal = {Frontiers in Psychology},
	author = {Makowski, Dominique and Ben-Shachar, Mattan S. and Chen, S. H. Annabel and Lüdecke, Daniel},
	month = dec,
	year = {2019},
	pages = {2767},
}

@book{kruschke_doing_2015,
	address = {United States},
	edition = {2nd},
	title = {Doing {Bayesian} data analysis: {A} tutorial with {R}, {JAGS}, and {Stan}},
	isbn = {978-0-12-405888-0},
	language = {English},
	publisher = {Academic Press},
	author = {Kruschke, John K.},
	year = {2015},
	keywords = {Bayesian statistical decision theory, R (Computer program language)},
}

@article{etz_how_2018,
	title = {How to become a {Bayesian} in eight easy steps: {An} annotated reading list},
	volume = {25},
	issn = {1069-9384, 1531-5320},
	shorttitle = {How to become a {Bayesian} in eight easy steps},
	url = {http://link.springer.com/10.3758/s13423-017-1317-5},
	doi = {10.3758/s13423-017-1317-5},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Psychonomic Bulletin \& Review},
	author = {Etz, Alexander and Gronau, Quentin F. and Dablander, Fabian and Edelsbrunner, Peter A. and Baribault, Beth},
	month = feb,
	year = {2018},
	pages = {219--234},
}

@book{mcelreath_statistical_2020,
	address = {United States},
	edition = {2nd},
	title = {Statistical rethinking: {A} {Bayesian} course with examples in {R} and {Stan}},
	isbn = {978-1-4822-5344-3},
	language = {English},
	publisher = {Taylor and Francis, CRC Press},
	author = {McElreath, Richard},
	year = {2020},
	keywords = {Bayesian statistical decision theory, R (Computer program language)},
}

@article{wagenmakers_bayesian_2018,
	title = {Bayesian inference for psychology. {Part} {I}: {Theoretical} advantages and practical ramifications},
	volume = {25},
	issn = {1069-9384, 1531-5320},
	shorttitle = {Bayesian inference for psychology. {Part} {I}},
	url = {http://link.springer.com/10.3758/s13423-017-1343-3},
	doi = {10.3758/s13423-017-1343-3},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Psychonomic Bulletin \& Review},
	author = {Wagenmakers, Eric-Jan and Marsman, Maarten and Jamil, Tahira and Ly, Alexander and Verhagen, Josine and Love, Jonathon and Selker, Ravi and Gronau, Quentin F. and Šmíra, Martin and Epskamp, Sacha and Matzke, Dora and Rouder, Jeffrey N. and Morey, Richard D.},
	month = feb,
	year = {2018},
	pages = {35--57},
}

@article{wagenmakers_agenda_2012,
	title = {An {Agenda} for {Purely} {Confirmatory} {Research}},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://journals.sagepub.com/doi/10.1177/1745691612463078},
	doi = {10.1177/1745691612463078},
	abstract = {The veracity of substantive research claims hinges on the way experimental data are collected and analyzed. In this article, we discuss an uncomfortable fact that threatens the core of psychology’s academic enterprise: almost without exception, psychologists do not commit themselves to a method of data analysis before they see the actual data. It then becomes tempting to fine tune the analysis to the data in order to obtain a desired result—a procedure that invalidates the interpretation of the common statistical tests. The extent of the fine tuning varies widely across experiments and experimenters but is almost impossible for reviewers and readers to gauge. To remedy the situation, we propose that researchers preregister their studies and indicate in advance the analyses they intend to conduct. Only these analyses deserve the label “confirmatory,” and only for these analyses are the common statistical tests valid. Other analyses can be carried out but these should be labeled “exploratory.” We illustrate our proposal with a confirmatory replication attempt of a study on extrasensory perception.},
	language = {en},
	number = {6},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Wagenmakers, Eric-Jan and Wetzels, Ruud and Borsboom, Denny and van der Maas, Han L. J. and Kievit, Rogier A.},
	month = nov,
	year = {2012},
	pages = {632--638},
}

@article{foreman-mackey_emcee_2013,
	title = {emcee : {The} {MCMC} {Hammer}},
	volume = {125},
	issn = {00046280, 15383873},
	shorttitle = {emcee},
	url = {http://iopscience.iop.org/article/10.1086/670067},
	doi = {10.1086/670067},
	language = {en},
	number = {925},
	urldate = {2021-07-09},
	journal = {Publications of the Astronomical Society of the Pacific},
	author = {Foreman-Mackey, Daniel and Hogg, David W. and Lang, Dustin and Goodman, Jonathan},
	month = mar,
	year = {2013},
	pages = {306--312},
}

@book{press_numerical_2007,
	address = {Cambridge},
	edition = {3rd},
	title = {Numerical recipes: the art of scientific computing,},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Press, W.},
	year = {2007},
	keywords = {C++ (Computer program language), Computer programs, Mathematics Computer programs, Numerical analysis, Science},
}

@misc{huber_introduction_2016,
	title = {Introduction to {Bayesian} statistics, part 2: {MCMC} and the {Metropolis}–{Hastings} algorithm},
	url = {https://blog.stata.com/2016/11/15/introduction-to-bayesian-statistics-part-2-mcmc-and-the-metropolis-hastings-algorithm/},
	language = {English},
	journal = {The Stata Blog},
	author = {Huber, Chuck},
	month = nov,
	year = {2016},
}

@article{gorgolewski_brain_2016,
	title = {The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments},
	volume = {3},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/sdata201644},
	doi = {10.1038/sdata.2016.44},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Scientific Data},
	author = {Gorgolewski, Krzysztof J. and Auer, Tibor and Calhoun, Vince D. and Craddock, R. Cameron and Das, Samir and Duff, Eugene P. and Flandin, Guillaume and Ghosh, Satrajit S. and Glatard, Tristan and Halchenko, Yaroslav O. and Handwerker, Daniel A. and Hanke, Michael and Keator, David and Li, Xiangrui and Michael, Zachary and Maumet, Camille and Nichols, B. Nolan and Nichols, Thomas E. and Pellman, John and Poline, Jean-Baptiste and Rokem, Ariel and Schaefer, Gunnar and Sochat, Vanessa and Triplett, William and Turner, Jessica A. and Varoquaux, Gaël and Poldrack, Russell A.},
	month = dec,
	year = {2016},
	pages = {160044},
}

@misc{bids_about_2020,
	title = {About {BIDS}},
	url = {https://bids.neuroimaging.io/},
	urldate = {2021-07-09},
	journal = {Brain Imaging Data Structure},
	author = {{BIDS}},
	year = {2020},
}

@article{clark_ontogeny_2019,
	title = {Ontogeny vs. phylogeny in primate/canid comparisons: {A} meta-analysis of the object choice task},
	volume = {105},
	issn = {01497634},
	shorttitle = {Ontogeny vs. phylogeny in primate/canid comparisons},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763419300831},
	doi = {10.1016/j.neubiorev.2019.06.001},
	language = {en},
	urldate = {2021-07-09},
	journal = {Neuroscience \& Biobehavioral Reviews},
	author = {Clark, Hannah and Elsherif, Mahmoud M. and Leavens, David A.},
	month = oct,
	year = {2019},
	pages = {178--189},
}

@article{button_grassroots_2020,
	title = {Grassroots {Training} for {Reproducible} {Science}: {A} {Consortium}-{Based} {Approach} to the {Empirical} {Dissertation}},
	volume = {19},
	issn = {1475-7257, 1475-7257},
	shorttitle = {Grassroots {Training} for {Reproducible} {Science}},
	url = {http://journals.sagepub.com/doi/10.1177/1475725719857659},
	doi = {10.1177/1475725719857659},
	abstract = {There is a widely acknowledged need to improve the reliability and efficiency of scientific research to increase the credibility of the published scientific literature and accelerate discovery. Widespread improvement requires a cultural shift in both thinking and practice, and better education will be instrumental to achieve this. Here we argue that education in reproducible science should start at the grassroots. We present our model of consortium-based student projects to train undergraduates in reproducible team science. We discuss how with careful design we have aligned collaboration with the current conventions for individual student assessment. We reflect on our experiences of several years running the GW4 Undergraduate Psychology Consortium offering insights we hope will be of practical use to others wishing to adopt a similar approach. We consider the pedagogical benefits of our approach in equipping students with 21st-century skills. Finally, we reflect on the need to shift incentives to reward to team science in global research and how this applies to the reward structures of student assessment.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Psychology Learning \& Teaching},
	author = {Button, Katherine S. and Chambers, Christopher D. and Lawrence, Natalia and Munafò, Marcus R.},
	month = mar,
	year = {2020},
	pages = {77--90},
}

@article{leavens_bizarre_2010,
	title = {{BIZARRE} chimpanzees do not represent “the chimpanzee”},
	volume = {33},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X10000166/type/journal_article},
	doi = {10.1017/S0140525X10000166},
	abstract = {Abstract
            Henrich et al. convincingly caution against the overgeneralization of findings from particular human populations, but fail to apply their own compelling reasoning to our nearest living relatives, the great apes. Here we argue that rearing history is every bit as important for understanding cognition in other species as it is in humans.},
	language = {en},
	number = {2-3},
	urldate = {2021-07-09},
	journal = {Behavioral and Brain Sciences},
	author = {Leavens, David A. and Bard, Kim A. and Hopkins, William D.},
	month = jun,
	year = {2010},
	pages = {100--101},
}

@article{button_instilling_2016,
	title = {Instilling scientific rigour at the grassroots},
	volume = {29},
	number = {16},
	journal = {The Psychologist},
	author = {Button, Katherine S. and Lawrence, Natalia and Chambers, Christopher D. and Munafò, Marcus R.},
	year = {2016},
	pages = {158--167},
}

@article{hart_rebuilding_nodate,
	title = {Rebuilding the {Ivory} {Tower}: {A} {Bottom}-{Up} {Experiment} in {Aligning} {Research} {With} {Societal} {Needs}},
	volume = {36},
	url = {https://issues.org/aligning-research-with-societal-needs/},
	number = {3},
	journal = {Issues in Science and Technology},
	author = {Hart, David and Silka, Linda},
	pages = {79--85},
}

@incollection{green_achieving_2008,
	address = {Oxford : Oxford ; New York},
	series = {Issues in biomedical ethics},
	title = {Achieving global justice in health through global research ethics: supplementing {Macklin}'s ‘top-down' approach with one from the ‘ground up’},
	isbn = {978-0-19-954659-6},
	booktitle = {Global bioethics: issues of conscience for the twenty-first century},
	publisher = {Clarendon Press ; Oxford University Press},
	author = {Meslin, E.M.},
	editor = {Green, Ronald Michael and Donovan, Aine and Jauss, Steven A.},
	year = {2008},
	note = {OCLC: 229023774},
	keywords = {Bioethical Issues, Medicine, ethics, Biomedical Research, Bioethics, Ethics, Medical, Globalization, Medical ethics, Research Moral and ethical aspects, trends, World health, World Health},
	pages = {163--177},
}

@misc{nosek_strategy_2019,
	title = {Strategy for {Culture} {Change}},
	url = {https://www.cos.io/blog/strategy-for-culture-change},
	language = {English},
	journal = {Center for Open Science},
	author = {Nosek, Brian A.},
	month = jun,
	year = {2019},
}

@article{moran_understanding_2020,
	title = {Understanding {Research} {Culture}: {What} researchers think about the culture they work in},
	volume = {5},
	issn = {2398-502X},
	shorttitle = {Understanding {Research} {Culture}},
	url = {https://wellcomeopenresearch.org/articles/5-201/v1},
	doi = {10.12688/wellcomeopenres.15832.1},
	abstract = {Background:
              The current performance of UK research can be presented as highly successful, but evidence has emerged about issues with working culture in research and the impact this may have on people and their work. Wellcome commissioned market research agency Shift Learning to investigate current perceptions and experiences of research culture among the research community.
            
            
              Methods:
              This article presents key findings from two phases of this project: 94 qualitative interviews and a quantitative e-survey with 4267 usable responses. Interview invitations were sent out to UK-based research staff at various career stages. The survey was open to international respondents, but the majority of responses came from the UK. Respondents came predominantly from academia and the sample was intentionally skewed towards biological and biomedical sciences.
            
            
              Results:
              While participants considered the quality of research outputs to have generally remained high, many felt that issues impacting research culture were becoming more apparent and there was real concern about the future of research professions and the high personal cost for individuals.
            
            Factors identified as disruptive to research culture included chasing impact, increased competition, proliferation of metrics, job insecurity and rigid career pathways. Poor research culture manifested in workplace behaviours and practices, including problems with management and leadership and unhealthy power dynamics, such as patronage, bullying and harassment, discrimination and exploitation. These conditions were linked to a range of negative impacts on the researchers and the research outputs.
            
              Conclusions:
              The research ecosystem is characterised by increased levels of competition, lack of job security and insufficient career flexibility. A key takeaway is that the conditions in which research takes place are not inclusive and lack sufficient support mechanisms, which is negatively affecting researchers’ wellbeing, and work-life balance. Such research culture was perceived as unsustainable.},
	language = {en},
	urldate = {2021-07-09},
	journal = {Wellcome Open Research},
	author = {Moran, Helene and Karlin, Lena and Lauchlan, Elsie and Rappaport, Sarah J. and Bleasdale, Ben and Wild, Lucy and Dorr, Josh},
	month = aug,
	year = {2020},
	pages = {201},
}

@article{sorsa_bracketing_2015,
	title = {Bracketing as a skill in conducting unstructured qualitative interviews},
	volume = {22},
	issn = {1351-5578, 2047-8992},
	url = {http://journals.rcni.com/doi/10.7748/nr.22.4.8.e1317},
	doi = {10.7748/nr.22.4.8.e1317},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Nurse Researcher},
	author = {Sorsa, Minna Anneli and Kiikkala, Irma and Åstedt-Kurki, Päivi},
	month = mar,
	year = {2015},
	pages = {8--12},
}

@article{rolls_bracketing_2006,
	title = {Bracketing interviews: addressing methodological challenges in qualitative interviewing in bereavement and palliative care},
	volume = {11},
	issn = {1357-6275, 1469-9885},
	shorttitle = {Bracketing interviews},
	url = {http://www.tandfonline.com/doi/abs/10.1080/13576270600774893},
	doi = {10.1080/13576270600774893},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Mortality},
	author = {Rolls, Liz and Relf, Marilyn},
	month = aug,
	year = {2006},
	pages = {286--305},
}

@article{whitaker_bropenscience_2020,
	title = {\#bropenscience is broken science.},
	volume = {33},
	journal = {The Psychologist},
	author = {Whitaker, Kirstie and Guest, Olivia},
	year = {2020},
	pages = {34--37},
}

@article{guest_how_2021,
	title = {How {Computational} {Modeling} {Can} {Force} {Theory} {Building} in {Psychological} {Science}},
	issn = {1745-6916, 1745-6924},
	url = {http://journals.sagepub.com/doi/10.1177/1745691620970585},
	doi = {10.1177/1745691620970585},
	abstract = {Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined—what we dub open theory. Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all.},
	language = {en},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Guest, Olivia and Martin, Andrea E.},
	month = jan,
	year = {2021},
	pages = {174569162097058},
}

@misc{guest_briannosek_2017,
	type = {Tweet},
	title = {@{BrianNosek} @ctitusbrown @{StuartBuck1} @{DaniRabaiotti} @{Julie}\_B92 @jeroenbosman @blahah404 @{OSFramework} {Thanks}! {Hopefully} this thread \& many other similar discussions \& blogs will help make it less {Bropen} {Science} and more {Open} {Science}. *hides*},
	url = {https://twitter.com/o_guest/status/871675631062458368},
	language = {en},
	urldate = {2021-07-09},
	journal = {@o\_guest},
	author = {Guest, Olivia},
	month = jun,
	year = {2017},
}

@article{nosek_registered_2014,
	title = {Registered {Reports}: {A} {Method} to {Increase} the {Credibility} of {Published} {Results}},
	volume = {45},
	issn = {1864-9335, 2151-2590},
	shorttitle = {Registered {Reports}},
	url = {https://econtent.hogrefe.com/doi/10.1027/1864-9335/a000192},
	doi = {10.1027/1864-9335/a000192},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Social Psychology},
	author = {Nosek, Brian A. and Lakens, Daniël},
	month = may,
	year = {2014},
	pages = {137--141},
}

@incollection{lewis_what_2018,
	address = {Cambridge},
	edition = {2nd},
	title = {What lessons does the “replication crisis”  in psychology hold for experimental economics?},
	isbn = {978-1-107-65415-0 978-0-521-85665-2},
	booktitle = {The {Cambridge} {Handbook} of {Psychology} and {Economic} {Behavior}},
	publisher = {CAMBRIDGE UNIVERSITY PRESS},
	author = {Bardsley, N.},
	editor = {Lewis, Alan},
	year = {2018},
	keywords = {Consumer behavior, Economics, Psychological aspects},
}

@misc{centre_for_open_science_show_nodate,
	title = {Show {Your} {Work}. {Share} {Your} {Work}.},
	url = {https://www.cos.io/},
	urldate = {2021-07-09},
	journal = {Centre for Open Science},
	author = {{Centre for Open Science}},
}

@article{cohn_citizen_2008,
	title = {Citizen {Science}: {Can} {Volunteers} {Do} {Real} {Research}?},
	volume = {58},
	issn = {1525-3244, 0006-3568},
	shorttitle = {Citizen {Science}},
	url = {https://academic.oup.com/bioscience/article/58/3/192/230689},
	doi = {10.1641/B580303},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {BioScience},
	author = {Cohn, Jeffrey P.},
	month = mar,
	year = {2008},
	pages = {192--197},
}

@misc{european_commission_european_2021,
	title = {European {Commission}},
	url = {https://ec.europa.eu/programmes/horizon2020/en/h2020-section/responsible-research-innovation},
	urldate = {2021-07-09},
	journal = {Responsible research \& innovation {\textbar} Horizon 2020},
	author = {{European Commission}},
	year = {2021},
}

@article{lintott_galaxy_2008,
	title = {Galaxy {Zoo}: morphologies derived from visual inspection of galaxies from the {Sloan} {Digital} {Sky} {Survey} $^{\textrm{★}}$},
	volume = {389},
	issn = {00358711, 13652966},
	shorttitle = {Galaxy {Zoo}},
	url = {https://academic.oup.com/mnras/article-lookup/doi/10.1111/j.1365-2966.2008.13689.x},
	doi = {10.1111/j.1365-2966.2008.13689.x},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Lintott, Chris J. and Schawinski, Kevin and Slosar, Anže and Land, Kate and Bamford, Steven and Thomas, Daniel and Raddick, M. Jordan and Nichol, Robert C. and Szalay, Alex and Andreescu, Dan and Murray, Phil and Vandenberg, Jan},
	month = sep,
	year = {2008},
	pages = {1179--1189},
}

@article{zurn_citation_2020,
	title = {The {Citation} {Diversity} {Statement}: {A} {Practice} of {Transparency}, {A} {Way} of {Life}},
	volume = {24},
	issn = {13646613},
	shorttitle = {The {Citation} {Diversity} {Statement}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661320301649},
	doi = {10.1016/j.tics.2020.06.009},
	language = {en},
	number = {9},
	urldate = {2021-07-09},
	journal = {Trends in Cognitive Sciences},
	author = {Zurn, Perry and Bassett, Danielle S. and Rust, Nicole C.},
	month = sep,
	year = {2020},
	pages = {669--672},
}

@article{thombs_potentially_2015,
	title = {Potentially coercive self-citation by peer reviewers: {A} cross-sectional study},
	volume = {78},
	issn = {00223999},
	shorttitle = {Potentially coercive self-citation by peer reviewers},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022399914003468},
	doi = {10.1016/j.jpsychores.2014.09.015},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Journal of Psychosomatic Research},
	author = {Thombs, Brett D. and Levis, Alexander W. and Razykov, Ilya and Syamchandra, Achyuth and Leentjens, Albert F.G. and Levenson, James L. and Lumley, Mark A.},
	month = jan,
	year = {2015},
	pages = {1--6},
}

@article{jannot_citation_2013,
	title = {Citation bias favoring statistically significant studies was present in medical research},
	volume = {66},
	issn = {08954356},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0895435612003198},
	doi = {10.1016/j.jclinepi.2012.09.015},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Journal of Clinical Epidemiology},
	author = {Jannot, Anne-Sophie and Agoritsas, Thomas and Gayet-Ageron, Angèle and Perneger, Thomas V.},
	month = mar,
	year = {2013},
	pages = {296--301},
}

@article{brooks_private_1985,
	title = {Private acts and public objects: {An} investigation of citer motivations},
	volume = {36},
	issn = {00028231, 10974571},
	shorttitle = {Private acts and public objects},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/asi.4630360402},
	doi = {10.1002/asi.4630360402},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Journal of the American Society for Information Science},
	author = {Brooks, Terrence A.},
	month = jul,
	year = {1985},
	pages = {223--229},
}

@misc{noauthor_ckan_nodate,
	title = {{CKAN} - {The} open source data management system},
	url = {https://ckan.org/},
	urldate = {2021-07-09},
	journal = {Ckan},
}

@techreport{confederation_of_open_access_repositories_coar_2020,
	title = {{COAR} {Community} {Framework} for {Best} {Practices} in {Repositories}.},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/4110829},
	abstract = {The purpose of the framework is to assist repositories to evaluate and improve their current operations based on a set of applicable and achievable good practices. Currently, there are a number of existing frameworks and evaluation criteria that were developed to assist repositories in assessing certain facets of their operations (such as discovery, access, reuse, integrity, quality assurance, preservation, privacy, and sustainability), but these criteria are spread across different organizations and are often relevant for only one region or one type of repository. The aim of this work was to bring together relevant criteria into a {\textless}strong{\textgreater}global, multidimensional framework for assessing best practices{\textless}/strong{\textgreater} that can be adopted and used by different types of repositories (publication, institutional, data, etc.) and in different geographical and thematic contexts.},
	language = {en},
	urldate = {2021-07-09},
	institution = {Zenodo},
	author = {Confederation Of Open Access Repositories},
	month = oct,
	year = {2020},
	doi = {10.5281/ZENODO.4110829},
	note = {Version Number: 1},
	keywords = {repositories, open science, assessment framework},
}

@misc{noauthor_what_nodate-1,
	title = {What is a {Codebook}?},
	url = {https://www.icpsr.umich.edu/icpsrweb/content/shared/ICPSR/faqs/what-is-a-codebook.html},
	urldate = {2021-07-09},
	journal = {ICPSR.},
}

@article{petre_code_2014,
	title = {Code {Review} {For} and {By} {Scientists}},
	url = {http://arxiv.org/abs/1407.5648},
	abstract = {We describe two pilot studies of code review by and for scientists. Our principal findings are that scientists are enthusiastic, but need to be shown code review in action, and that just-in-time review of small code changes is more likely to succeed than large-scale end-of-work reviews.},
	urldate = {2021-07-09},
	journal = {arXiv:1407.5648 [cs]},
	author = {Petre, Marian and Wilson, Greg},
	month = sep,
	year = {2014},
	note = {arXiv: 1407.5648},
	keywords = {Computer Science - Software Engineering},
}

@article{nichols_best_2017,
	title = {Best practices in data analysis and sharing in neuroimaging using {MRI}},
	volume = {20},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/nn.4500},
	doi = {10.1038/nn.4500},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Nature Neuroscience},
	author = {Nichols, Thomas E and Das, Samir and Eickhoff, Simon B and Evans, Alan C and Glatard, Tristan and Hanke, Michael and Kriegeskorte, Nikolaus and Milham, Michael P and Poldrack, Russell A and Poline, Jean-Baptiste and Proal, Erika and Thirion, Bertrand and Van Essen, David C and White, Tonya and Yeo, B T Thomas},
	month = mar,
	year = {2017},
	pages = {299--303},
}

@article{wagge_demonstration_2019,
	title = {A {Demonstration} of the {Collaborative} {Replication} and {Education} {Project}: {Replication} {Attempts} of the {Red}-{Romance} {Effect}},
	volume = {5},
	issn = {2474-7394},
	shorttitle = {A {Demonstration} of the {Collaborative} {Replication} and {Education} {Project}},
	url = {https://online.ucpress.edu/collabra/article/5/1/5/112984/A-Demonstration-of-the-Collaborative-Replication},
	doi = {10.1525/collabra.177},
	abstract = {The present article reports the results of a meta-analysis of nine student replication projects of Elliot et al.’s (2010) findings from Experiment 3, that women were more attracted to photographs of men with red borders (total n = 640). The eight student projects were part of the Collaborative Replication and Education Project (CREP; https://osf.io/wfc6u/), a research crowdsourcing project for undergraduate students. All replications were reviewed by experts to ensure high quality data, and were pre-registered prior to data collection. Results of this meta-analysis showed no effect of red on attractiveness ratings for either perceived attractiveness (mean ratings difference = –0.07, 95\% CI [–0.31, 0.16]) or sexual attractiveness (mean ratings difference = –0.06, 95\% CI [–0.36, 0.24]); this null result held with and without Elliot et al.’s (2010) data included in analyses. Exploratory analyses examining whether being in a relationship moderated the effect of color on attractiveness ratings also produced null results.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Collabra: Psychology},
	author = {Wagge, Jordan R. and Baciu, Cristina and Banas, Kasia and Nadler, Joel T. and Schwarz, Sascha and Weisberg, Yanna and IJzerman, Hans and Legate, Nicole and Grahe, Jon},
	editor = {Vazire, Simine and McCarthy, Randy},
	month = jan,
	year = {2019},
	pages = {5},
}

@book{scopatz_effective_2015,
	address = {Sebastopol, CA},
	edition = {First Edition},
	title = {Effective computation in physics},
	isbn = {978-1-4919-0153-3},
	publisher = {O'Reilly Media},
	author = {Scopatz, Anthony and Huff, Kathryn D.},
	year = {2015},
	note = {OCLC: ocn895728657},
	keywords = {Computer software, Data processing, Development, Physics, Python (Computer program language)},
}

@article{pernet_null_2016,
	title = {Null hypothesis significance testing: a short tutorial},
	volume = {4},
	issn = {2046-1402},
	shorttitle = {Null hypothesis significance testing},
	url = {https://f1000research.com/articles/4-621/v3},
	doi = {10.12688/f1000research.6963.3},
	abstract = {Although thoroughly criticized, null hypothesis significance testing (NHST) remains the statistical method of choice used to provide evidence for an effect, in biological, biomedical and social sciences. In this short tutorial, I first summarize the concepts behind the method, distinguishing test of significance (Fisher) and test of acceptance (Newman-Pearson) and point to common interpretation errors regarding the p-value. I then present the related concepts of confidence intervals and again point to common interpretation errors. Finally, I discuss what should be reported in which context. The goal is to clarify concepts to avoid interpretation errors and propose reporting practices.},
	language = {en},
	urldate = {2021-07-09},
	journal = {F1000Research},
	author = {Pernet, Cyril},
	month = oct,
	year = {2016},
	pages = {621},
}

@article{pernet_eeg-bids_2019,
	title = {{EEG}-{BIDS}, an extension to the brain imaging data structure for electroencephalography},
	volume = {6},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/s41597-019-0104-8},
	doi = {10.1038/s41597-019-0104-8},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Scientific Data},
	author = {Pernet, Cyril R. and Appelhoff, Stefan and Gorgolewski, Krzysztof J. and Flandin, Guillaume and Phillips, Christophe and Delorme, Arnaud and Oostenveld, Robert},
	month = dec,
	year = {2019},
	pages = {103},
}

@article{pernet_issues_2020,
	title = {Issues and recommendations from the {OHBM} {COBIDAS} {MEEG} committee for reproducible {EEG} and {MEG} research},
	volume = {23},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/s41593-020-00709-0},
	doi = {10.1038/s41593-020-00709-0},
	language = {en},
	number = {12},
	urldate = {2021-07-09},
	journal = {Nature Neuroscience},
	author = {Pernet, Cyril and Garrido, Marta I. and Gramfort, Alexandre and Maurits, Natasha and Michel, Christoph M. and Pang, Elizabeth and Salmelin, Riitta and Schoffelen, Jan Mathijs and Valdes-Sosa, Pedro A. and Puce, Aina},
	month = dec,
	year = {2020},
	pages = {1473--1483},
}

@article{melissa_s_anderson_extending_2010,
	title = {Extending the {Mertonian} {Norms}: {Scientists}' {Subscription} to {Norms} of {Research}},
	volume = {81},
	issn = {1538-4640},
	shorttitle = {Extending the {Mertonian} {Norms}},
	url = {http://muse.jhu.edu/content/crossref/journals/journal_of_higher_education/v081/81.3.anderson.html},
	doi = {10.1353/jhe.0.0095},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {The Journal of Higher Education},
	author = {{Melissa S. Anderson} and {Emily A. Ronning} and {Raymond De Vries} and {Brian C. Martinson}},
	year = {2010},
	pages = {366--393},
}

@article{merton_matthew_1968,
	title = {The {Matthew} {Effect} in {Science}: {The} reward and communication systems of science are considered},
	volume = {159},
	issn = {0036-8075, 1095-9203},
	shorttitle = {The {Matthew} {Effect} in {Science}},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.159.3810.56},
	doi = {10.1126/science.159.3810.56},
	language = {en},
	number = {3810},
	urldate = {2021-07-09},
	journal = {Science},
	author = {Merton, R. K.},
	month = jan,
	year = {1968},
	pages = {56--63},
}

@incollection{klausnitzer_note_2015,
	address = {Berlin, München, Boston},
	title = {A {Note} on {Science} and {Democracy}? {Robert} {K}. {Mertons} {Ethos} of {Science}},
	isbn = {978-3-11-037500-8},
	shorttitle = {A {Note} on {Science} and {Democracy}?},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110375008-013/html},
	urldate = {2021-07-09},
	booktitle = {Ethos und {Pathos} der {Geisteswissenschaften}},
	publisher = {DE GRUYTER},
	author = {Menke, Cornelis},
	editor = {Klausnitzer, Ralf and Spoerhase, Carlos and Werle, Dirk},
	month = jan,
	year = {2015},
	doi = {10.1515/9783110375008-013},
}

@article{merton_science_1938,
	title = {Science and the {Social} {Order}},
	volume = {5},
	issn = {0031-8248, 1539-767X},
	url = {https://www.journals.uchicago.edu/doi/10.1086/286513},
	doi = {10.1086/286513},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Philosophy of Science},
	author = {Merton, Robert K.},
	month = jul,
	year = {1938},
	pages = {321--337},
}

@article{orben_journal_2019,
	title = {A journal club to fix science},
	volume = {573},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/d41586-019-02842-8},
	doi = {10.1038/d41586-019-02842-8},
	language = {en},
	number = {7775},
	urldate = {2021-07-09},
	journal = {Nature},
	author = {Orben, Amy},
	month = sep,
	year = {2019},
	pages = {465--465},
}

@article{ellemers_science_2021,
	title = {Science as collaborative knowledge generation},
	volume = {60},
	issn = {0144-6665, 2044-8309},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/bjso.12430},
	doi = {10.1111/bjso.12430},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {British Journal of Social Psychology},
	author = {Ellemers, Naomi},
	month = jan,
	year = {2021},
	pages = {1--28},
}

@book{shepard_community_2015,
	address = {Thousand Oaks, CA},
	title = {Community practice as social activism: from direct action to direct services},
	isbn = {978-1-4129-6426-5},
	shorttitle = {Community practice as social activism},
	publisher = {SAGE Publications, Inc},
	author = {Shepard, Benjamin},
	year = {2015},
	keywords = {United States, Community-based social services, Political participation, Social movements},
}

@article{gentleman_reproducible_2005,
	title = {Reproducible {Research}: {A} {Bioinformatics} {Case} {Study}},
	volume = {4},
	issn = {1544-6115, 2194-6302},
	shorttitle = {Reproducible {Research}},
	url = {https://www.degruyter.com/document/doi/10.2202/1544-6115.1034/html},
	doi = {10.2202/1544-6115.1034},
	abstract = {While scientific research and the methodologies involved have gone through substantial technological evolution the technology involved in the publication of the results of these endeavors has remained relatively stagnant. Publication is largely done in the same manner today as it was fifty years ago. Many journals have adopted electronic formats, however, their orientation and style is little different from a printed document. The documents tend to be static and take little advantage of computational resources that might be available. Recent work, Gentleman and Temple Lang (2003), suggests a methodology and basic infrastructure that can be used to publish documents in a substantially different way. Their approach is suitable for the publication of papers whose message relies on computation. Stated quite simply, Gentleman and Temple Lang (2003) propose a paradigm where documents are mixtures of code and text. Such documents may be self-contained or they may be a component of a compendium which provides the infrastructure needed to provide access to data and supporting software. These documents, or compendiums, can be processed in a number of different ways. One transformation will be to replace the code with its output -- thereby providing the familiar, but limited, static document. In this paper we apply these concepts to a seminal paper in bioinformatics, namely The Molecular Classification of Cancer, Golub et al (1999). The authors of that paper have generously provided data and other information that have allowed us to largely reproduce their results. Rather than reproduce this paper exactly we demonstrate that such a reproduction is possible and instead concentrate on demonstrating the usefulness of the compendium concept itself.},
	number = {1},
	urldate = {2021-07-09},
	journal = {Statistical Applications in Genetics and Molecular Biology},
	author = {Gentleman, Robert},
	month = jan,
	year = {2005},
}

@inproceedings{claerbout_electronic_1992,
	title = {Electronic documents give reproducible research a new meaning},
	url = {http://library.seg.org/doi/abs/10.1190/1.1822162},
	doi = {10.1190/1.1822162},
	language = {en},
	urldate = {2021-07-09},
	booktitle = {{SEG} {Technical} {Program} {Expanded} {Abstracts} 1992},
	publisher = {Society of Exploration Geophysicists},
	author = {Claerbout, Jon F. and Karrenbach, Martin},
	month = jan,
	year = {1992},
	pages = {601--604},
}

@article{nust_how_2018,
	title = {How to {Read} a {Research} {Compendium}},
	url = {http://arxiv.org/abs/1806.09525},
	abstract = {Researchers spend a great deal of time reading research papers. Keshav (2012) provides a three-pass method to researchers to improve their reading skills. This article extends Keshav's method for reading a research compendium. Research compendia are an increasingly used form of publication, which packages not only the research paper's text and figures, but also all data and software for better reproducibility. We introduce the existing conventions for research compendia and suggest how to utilise their shared properties in a structured reading process. Unlike the original, this article is not build upon a long history but intends to provide guidance at the outset of an emerging practice.},
	urldate = {2021-07-09},
	journal = {arXiv:1806.09525 [cs]},
	author = {Nüst, Daniel and Boettiger, Carl and Marwick, Ben},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.09525},
	keywords = {Computer Science - General Literature},
}

@article{marwick_packaging_2018,
	title = {Packaging {Data} {Analytical} {Work} {Reproducibly} {Using} {R} (and {Friends})},
	volume = {72},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1375986},
	doi = {10.1080/00031305.2017.1375986},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {The American Statistician},
	author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
	month = jan,
	year = {2018},
	pages = {80--88},
}

@article{obels_analysis_2020,
	title = {Analysis of {Open} {Data} and {Computational} {Reproducibility} in {Registered} {Reports} in {Psychology}},
	volume = {3},
	issn = {2515-2459, 2515-2467},
	url = {http://journals.sagepub.com/doi/10.1177/2515245920918872},
	doi = {10.1177/2515245920918872},
	abstract = {Ongoing technological developments have made it easier than ever before for scientists to share their data, materials, and analysis code. Sharing data and analysis code makes it easier for other researchers to reuse or check published research. However, these benefits will emerge only if researchers can reproduce the analyses reported in published articles and if data are annotated well enough so that it is clear what all variable and value labels mean. Because most researchers are not trained in computational reproducibility, it is important to evaluate current practices to identify those that can be improved. We examined data and code sharing for Registered Reports published in the psychological literature from 2014 to 2018 and attempted to independently computationally reproduce the main results in each article. Of the 62 articles that met our inclusion criteria, 41 had data available, and 37 had analysis scripts available. Both data and code for 36 of the articles were shared. We could run the scripts for 31 analyses, and we reproduced the main results for 21 articles. Although the percentage of articles for which both data and code were shared (36 out of 62, or 58\%) and the percentage of articles for which main results could be computationally reproduced (21 out of 36, or 58\%) were relatively high compared with the percentages found in other studies, there is clear room for improvement. We provide practical recommendations based on our observations and cite examples of good research practices in the studies whose main results we reproduced.},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Obels, Pepijn and Lakens, Daniël and Coles, Nicholas A. and Gottfried, Jaroslav and Green, Seth A.},
	month = jun,
	year = {2020},
	pages = {229--237},
}

@article{nosek_what_2020,
	title = {What is replication?},
	volume = {18},
	issn = {1545-7885},
	url = {https://dx.plos.org/10.1371/journal.pbio.3000691},
	doi = {10.1371/journal.pbio.3000691},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {PLOS Biology},
	author = {Nosek, Brian A. and Errington, Timothy M.},
	month = mar,
	year = {2020},
	pages = {e3000691},
}

@article{lebel_brief_2019,
	title = {A {Brief} {Guide} to {Evaluate} {Replications}},
	volume = {3},
	issn = {2003-2714},
	url = {https://open.lnu.se/index.php/metapsychology/article/view/843},
	doi = {10.15626/MP.2018.843},
	abstract = {The importance of replication is becoming increasingly appreciated, however, considerably less consensus exists about how to evaluate the design and results of replications. We make concrete recommendations on how to evaluate replications with more nuance than what is typically done currently in the literature. We highlight six study characteristics that are crucial for evaluating replications: replication method similarity, replication differences, investigator independence, method/data transparency, analytic result reproducibility, and auxiliary hypotheses’ plausibility evidence. We also recommend a more nuanced approach to statistically interpret replication results at the individual-study and meta-analytic levels, and propose clearer language to communicate replication results.},
	urldate = {2021-07-09},
	journal = {Meta-Psychology},
	author = {LeBel, Etienne Philippe and Vanpaemel, Wolf and Cheung, Irene and Campbell, Lorne},
	month = jun,
	year = {2019},
}

@article{lebel_unified_2018,
	title = {A {Unified} {Framework} to {Quantify} the {Credibility} of {Scientific} {Findings}},
	volume = {1},
	issn = {2515-2459, 2515-2467},
	url = {http://journals.sagepub.com/doi/10.1177/2515245918787489},
	doi = {10.1177/2515245918787489},
	abstract = {Societies invest in scientific studies to better understand the world and attempt to harness such improved understanding to address pressing societal problems. Published research, however, can be useful for theory or application only if it is credible. In science, a credible finding is one that has repeatedly survived risky falsification attempts. However, state-of-the-art meta-analytic approaches cannot determine the credibility of an effect because they do not account for the extent to which each included study has survived such attempted falsification. To overcome this problem, we outline a unified framework for estimating the credibility of published research by examining four fundamental falsifiability-related dimensions: (a) transparency of the methods and data, (b) reproducibility of the results when the same data-processing and analytic decisions are reapplied, (c) robustness of the results to different data-processing and analytic decisions, and (d) replicability of the effect. This framework includes a standardized workflow in which the degree to which a finding has survived scrutiny is quantified along these four facets of credibility. The framework is demonstrated by applying it to published replications in the psychology literature. Finally, we outline a Web implementation of the framework and conclude by encouraging the community of researchers to contribute to the development and crowdsourcing of this platform.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {LeBel, Etienne P. and McCarthy, Randy J. and Earp, Brian D. and Elson, Malte and Vanpaemel, Wolf},
	month = sep,
	year = {2018},
	pages = {389--402},
}

@book{kitzes_practice_2018,
	address = {Oakland, California},
	title = {The practice of reproducible research: case studies and lessons from the data-intensive sciences},
	isbn = {978-0-520-29474-5 978-0-520-29475-2},
	shorttitle = {The practice of reproducible research},
	abstract = {"The Practice of Reproducible Research presents concrete examples of how researchers in the data-intensive sciences are working to improve the reproducibility of their research projects. Each of the thirty-one case studies in this volume describes the workflow that an author used to complete a real-world research project, highlighting how particular tools, ideas, and practices have been combined to support reproducibility. Authors emphasize the very practical how, rather than the why or what, of conducting reproducible research. Part 1 contains an accessible introduction to reproducible research, a basic reproducible research project template, and a synthesis of lessons learned from across the thirty-one case studies. Parts 2 and 3 focus on the case studies. The Practice of Reproducible Research is an invaluable resource for students and researchers who wish to better understand the practice of data-intensive sciences and learn how to make their own research more reproducible."--Provided by publisher},
	publisher = {University of California Press},
	editor = {Kitzes, Justin and Turek, Daniel and Deniz, Fatma},
	year = {2018},
	keywords = {Statistical methods, Data processing, Electronic data processing, Reproducible research, Research, Statistics},
}

@book{committee_on_reproducibility_and_replicability_in_science_reproducibility_2019,
	address = {Washington, D.C.},
	title = {Reproducibility and {Replicability} in {Science}},
	isbn = {978-0-309-48616-3},
	url = {https://www.nap.edu/catalog/25303},
	urldate = {2021-07-09},
	publisher = {National Academies Press},
	author = {{Committee on Reproducibility and Replicability in Science} and {Board on Behavioral, Cognitive, and Sensory Sciences} and {Committee on National Statistics} and {Division of Behavioral and Social Sciences and Education} and {Nuclear and Radiation Studies Board} and {Division on Earth and Life Studies} and {Board on Mathematical Sciences and Analytics} and {Committee on Applied and Theoretical Statistics} and {Division on Engineering and Physical Sciences} and {Board on Research Data and Information} and {Committee on Science, Engineering, Medicine, and Public Policy} and {Policy and Global Affairs} and {National Academies of Sciences, Engineering, and Medicine}},
	month = sep,
	year = {2019},
	doi = {10.17226/25303},
	note = {Pages: 25303},
}

@article{salem_conflict_2013,
	title = {Conflict of {Interest} in {Open}-{Access} {Publishing}},
	volume = {369},
	issn = {0028-4793, 1533-4406},
	url = {http://www.nejm.org/doi/10.1056/NEJMc1307577},
	doi = {10.1056/NEJMc1307577},
	language = {en},
	number = {5},
	urldate = {2021-07-09},
	journal = {New England Journal of Medicine},
	author = {Salem, Deeb N. and Boumil, Marcia M.},
	month = aug,
	year = {2013},
	pages = {491--491},
}

@misc{the_committee_on_publication_ethics_transparency_nodate,
	title = {Transparency \& best practice – {DOAJ}},
	url = {https://doaj.org/apply/transparency/},
	urldate = {2021-07-09},
	journal = {DOAJ},
	author = {{The Committee on Publication Ethics}},
}

@misc{international_committee_of_medical_journal_editors_icmje_nodate,
	title = {{ICMJE} {\textbar} {Recommendations} {\textbar} {Author} {Responsibilities}—{Disclosure} of {Financial} and {Non}-{Financial} {Relationships} and {Activities}, and {Conflicts} of {Interest}},
	url = {http://www.icmje.org/recommendations/browse/roles-and-responsibilities/author-responsibilities--conflicts-of-interest.html},
	urldate = {2021-07-09},
	journal = {ICJME},
	author = {{International Committee of Medical Journal Editors}},
}

@article{filipe_co-production_2017,
	title = {The co-production of what? {Knowledge}, values, and social relations in health care},
	volume = {15},
	issn = {1545-7885},
	shorttitle = {The co-production of what?},
	url = {https://dx.plos.org/10.1371/journal.pbio.2001403},
	doi = {10.1371/journal.pbio.2001403},
	language = {en},
	number = {5},
	urldate = {2021-07-09},
	journal = {PLOS Biology},
	author = {Filipe, Angela and Renedo, Alicia and Marston, Cicely},
	editor = {Marris, Claire},
	month = may,
	year = {2017},
	pages = {e2001403},
}

@article{graham_exploring_2019,
	title = {Exploring the frontiers of research co-production: the {Integrated} {Knowledge} {Translation} {Research} {Network} concept papers},
	volume = {17},
	issn = {1478-4505},
	shorttitle = {Exploring the frontiers of research co-production},
	url = {https://health-policy-systems.biomedcentral.com/articles/10.1186/s12961-019-0501-7},
	doi = {10.1186/s12961-019-0501-7},
	abstract = {Abstract
            Research co-production is about doing research with those who use it. This approach to research has been receiving increasing attention from research funders, academic institutions, researchers and even the public as a means of optimising the relevance, usefulness, usability and use of research findings, which together, the argument goes, produces greater and more timely impact. The papers in this cross BMC journal collection raise issues about research co-production that, to date, have not been fully considered and suggest areas for future research for advancing the science and practice of research co-production. These papers address some gaps in the literature, make connections between subfields and provide varied perspectives from researchers and knowledge users.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Health Research Policy and Systems},
	author = {Graham, Ian D. and McCutcheon, Chris and Kothari, Anita},
	month = dec,
	year = {2019},
	pages = {88, s12961--019--0501--7},
}

@misc{bortoli_nihr_2021,
	title = {{NIHR} {Guidance} on co-producing a research project},
	url = {https://www.learningforinvolvement.org.uk/?opportunity=nihr-guidance-on-co-producing-a-research-project},
	language = {en-GB},
	urldate = {2021-07-09},
	journal = {Learning For Involvement},
	author = {Bortoli, Silvia},
	month = apr,
	year = {2021},
}

@misc{noauthor_our_nodate,
	title = {Our {Approach} {\textbar} {Co}-{Production} {Collective}},
	url = {https://www.coproductioncollective.co.uk/what-is-co-production/our-approach},
	urldate = {2021-07-09},
	journal = {Co-production Collective},
}

@article{bishop_psychology_2020,
	title = {The psychology of experimental psychologists: {Overcoming} cognitive constraints to improve research: {The} 47th {Sir} {Frederic} {Bartlett} {Lecture}},
	volume = {73},
	issn = {1747-0218, 1747-0226},
	shorttitle = {The psychology of experimental psychologists},
	url = {http://journals.sagepub.com/doi/10.1177/1747021819886519},
	doi = {10.1177/1747021819886519},
	abstract = {Like many other areas of science, experimental psychology is affected by a “replication crisis” that is causing concern in many fields of research. Approaches to tackling this crisis include better training in statistical methods, greater transparency and openness, and changes to the incentives created by funding agencies, journals, and institutions. Here, I argue that if proposed solutions are to be effective, we also need to take into account human cognitive constraints that can distort all stages of the research process, including design and execution of experiments, analysis of data, and writing up findings for publication. I focus specifically on cognitive schemata in perception and memory, confirmation bias, systematic misunderstanding of statistics, and asymmetry in moral judgements of errors of commission and omission. Finally, I consider methods that may help mitigate the effect of cognitive constraints: better training, including use of simulations to overcome statistical misunderstanding; specific programmes directed at inoculating against cognitive biases; adoption of Registered Reports to encourage more critical reflection in planning studies; and using methods such as triangulation and “pre mortem” evaluation of study design to foster a culture of dialogue and criticism.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Quarterly Journal of Experimental Psychology},
	author = {Bishop, Dorothy VM},
	month = jan,
	year = {2020},
	pages = {1--19},
}

@article{nickerson_confirmation_1998,
	title = {Confirmation {Bias}: {A} {Ubiquitous} {Phenomenon} in {Many} {Guises}},
	volume = {2},
	issn = {1089-2680, 1939-1552},
	shorttitle = {Confirmation {Bias}},
	url = {http://journals.sagepub.com/doi/10.1037/1089-2680.2.2.175},
	doi = {10.1037/1089-2680.2.2.175},
	abstract = {Confirmation bias, as the term is typically used in the psychological literature, connotes the seeking or interpreting of evidence in ways that are partial to existing beliefs, expectations, or a hypothesis in hand. The author reviews evidence of such a bias in a variety of guises and gives examples of its operation in several practical contexts. Possible explanations are considered, and the question of its utility or disutility is discussed.},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Review of General Psychology},
	author = {Nickerson, Raymond S.},
	month = jun,
	year = {1998},
	pages = {175--220},
}

@misc{spencer_confirmation_2018,
	title = {Confirmation bias},
	url = {https://catalogofbias.org/biases/confirmation-bias/},
	abstract = {Confirmation bias arises when one seeks out and interprets information in a way that supports one’s preconceptions or hypotheses.},
	language = {en},
	urldate = {2021-07-09},
	journal = {Catalog of Bias},
	author = {Spencer, E.A. and Heneghan, C.},
	month = apr,
	year = {2018},
}

@article{wason_failure_1960,
	title = {On the {Failure} to {Eliminate} {Hypotheses} in a {Conceptual} {Task}},
	volume = {12},
	issn = {0033-555X},
	url = {http://journals.sagepub.com/doi/10.1080/17470216008416717},
	doi = {10.1080/17470216008416717},
	abstract = {This investigation examines the extent to which intelligent young adults seek (i) confirming evidence alone (enumerative induction) or (ii) confirming and discontinuing evidence (eliminative induction), in order to draw conclusions in a simple conceptual task. The experiment is designed so that use of confirming evidence alone will almost certainly lead to erroneous conclusions because (i) the correct concept is entailed by many more obvious ones, and (ii) the universe of possible instances (numbers) is infinite.
            Six out of 29 subjects reached the correct conclusion without previous incorrect ones, 13 reached one incorrect conclusion, nine reached two or more incorrect conclusions, and one reached no conclusion. The results showed that those subjects, who reached two or more incorrect conclusions, were unable, or unwilling to test their hypotheses. The implications are discussed in relation to scientific thinking.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Quarterly Journal of Experimental Psychology},
	author = {Wason, P. C.},
	month = jul,
	year = {1960},
	pages = {129--140},
}

@article{box_science_1976,
	title = {Science and {Statistics}},
	volume = {71},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1976.10480949},
	doi = {10.1080/01621459.1976.10480949},
	language = {en},
	number = {356},
	urldate = {2021-07-09},
	journal = {Journal of the American Statistical Association},
	author = {Box, George E. P.},
	month = dec,
	year = {1976},
	pages = {791--799},
}

@article{oberauer_addressing_2019,
	title = {Addressing the theory crisis in psychology},
	volume = {26},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/s13423-019-01645-2},
	doi = {10.3758/s13423-019-01645-2},
	language = {en},
	number = {5},
	urldate = {2021-07-09},
	journal = {Psychonomic Bulletin \& Review},
	author = {Oberauer, Klaus and Lewandowsky, Stephan},
	month = oct,
	year = {2019},
	pages = {1596--1618},
}

@book{tukey_exploratory_1977,
	address = {Reading, Mass},
	series = {Addison-{Wesley} series in behavioral science},
	title = {Exploratory data analysis},
	isbn = {978-0-201-07616-5},
	publisher = {Addison-Wesley Pub. Co},
	author = {Tukey, John Wilder},
	year = {1977},
	keywords = {Statistics},
}

@article{szollosi_arrested_2021,
	title = {Arrested {Theory} {Development}: {The} {Misguided} {Distinction} {Between} {Exploratory} and {Confirmatory} {Research}},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Arrested {Theory} {Development}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691620966796},
	doi = {10.1177/1745691620966796},
	abstract = {Science progresses by finding and correcting problems in theories. Good theories are those that help facilitate this process by being hard to vary: They explain what they are supposed to explain, they are consistent with other good theories, and they are not easily adaptable to explain anything. Here we argue that, rather than a lack of distinction between exploratory and confirmatory research, an abundance of flexible theories is a better explanation for the current replicability problems of psychology. We also explain why popular methods-oriented solutions fail to address the real problem of flexibility. Instead, we propose that a greater emphasis on theory criticism by argument might improve replicability.},
	language = {en},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Szollosi, Aba and Donkin, Chris},
	month = feb,
	year = {2021},
	pages = {174569162096679},
}

@article{busse_boundary_2017,
	title = {Boundary {Conditions}: {What} {They} {Are}, {How} to {Explore} {Them}, {Why} {We} {Need} {Them}, and {When} to {Consider} {Them}},
	volume = {20},
	issn = {1094-4281, 1552-7425},
	shorttitle = {Boundary {Conditions}},
	url = {http://journals.sagepub.com/doi/10.1177/1094428116641191},
	doi = {10.1177/1094428116641191},
	abstract = {Boundary conditions (BC) have long been discussed as an important element in theory development, referring to the “who, where, when” aspects of a theory. However, it still remains somewhat vague as to what exactly BC are, how they can or even should be explored, and why their understanding matters. This research tackles these important questions by means of an in-depth theoretical-methodological analysis. The study contributes fourfold to organizational research methods: First, it develops a more accurate and explicit conceptualization of BC. Second, it widens the understanding of how BC can be explored by suggesting and juxtaposing new tools and approaches. It also illustrates BC-exploring processes, drawing on two empirical case examples. Third, it analyzes the reasons for exploring BC, concluding that BC exploration fosters theory development, strengthens research validity, and mitigates the research-practice gap. Fourth, it synthesizes the analyses into 12 tentative suggestions for how scholars should subsequently approach the issues surrounding BC. The authors hope that the study contributes to consensus shifting with respect to BC and draws more attention to BC.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Organizational Research Methods},
	author = {Busse, Christian and Kach, Andrew P. and Wagner, Stephan M.},
	month = oct,
	year = {2017},
	pages = {574--609},
}

@article{huffmeier_reconceptualizing_2016,
	title = {Reconceptualizing replication as a sequence of different studies: {A} replication typology},
	volume = {66},
	issn = {00221031},
	shorttitle = {Reconceptualizing replication as a sequence of different studies},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022103115001195},
	doi = {10.1016/j.jesp.2015.09.009},
	language = {en},
	urldate = {2021-07-09},
	journal = {Journal of Experimental Social Psychology},
	author = {Hüffmeier, Joachim and Mazei, Jens and Schultze, Thomas},
	month = sep,
	year = {2016},
	pages = {81--92},
}

@article{yarkoni_generalizability_2020,
	title = {The generalizability crisis},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X20001685/type/journal_article},
	doi = {10.1017/S0140525X20001685},
	abstract = {Abstract
            Most theories and hypotheses in psychology are verbal in nature, yet their evaluation overwhelmingly relies on inferential statistical procedures. The validity of the move from qualitative to quantitative analysis depends on the verbal and statistical expressions of a hypothesis being closely aligned—that is, that the two must refer to roughly the same set of hypothetical observations. Here I argue that many applications of statistical inference in psychology fail to meet this basic condition. Focusing on the most widely used class of model in psychology—the linear mixed model—I explore the consequences of failing to statistically operationalize verbal hypotheses in a way that respects researchers' actual generalization intentions. I demonstrate that whereas the "random effect" formalism is used pervasively in psychology to model inter-subject variability, few researchers accord the same treatment to other variables they clearly intend to generalize over (e.g., stimuli, tasks, or research sites). The under-specification of random effects imposes far stronger constraints on the generalizability of results than most researchers appreciate. Ignoring these constraints can dramatically inflate false positive rates, and often leads researchers to draw sweeping verbal generalizations that lack a meaningful connection to the statistical quantities they are putatively based on. I argue that failure to take the alignment between verbal and statistical expressions seriously lies at the heart of many of psychology's ongoing problems (e.g., the replication crisis), and conclude with a discussion of several potential avenues for improvement.},
	language = {en},
	urldate = {2021-07-09},
	journal = {Behavioral and Brain Sciences},
	author = {Yarkoni, Tal},
	month = dec,
	year = {2020},
	pages = {1--37},
}

@article{simons_constraints_2017,
	title = {Constraints on {Generality} ({COG}): {A} {Proposed} {Addition} to {All} {Empirical} {Papers}},
	volume = {12},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Constraints on {Generality} ({COG})},
	url = {http://journals.sagepub.com/doi/10.1177/1745691617708630},
	doi = {10.1177/1745691617708630},
	abstract = {Psychological scientists draw inferences about populations based on samples—of people, situations, and stimuli—from those populations. Yet, few papers identify their target populations, and even fewer justify how or why the tested samples are representative of broader populations. A cumulative science depends on accurately characterizing the generality of findings, but current publishing standards do not require authors to constrain their inferences, leaving readers to assume the broadest possible generalizations. We propose that the discussion section of all primary research articles specify Constraints on Generality (i.e., a “COG” statement) that identify and justify target populations for the reported findings. Explicitly defining the target populations will help other researchers to sample from the same populations when conducting a direct replication, and it could encourage follow-up studies that test the boundary conditions of the original finding. Universal adoption of COG statements would change publishing incentives to favor a more cumulative science.},
	language = {en},
	number = {6},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Simons, Daniel J. and Shoda, Yuichi and Lindsay, D. Stephen},
	month = nov,
	year = {2017},
	pages = {1123--1128},
}

@article{knoth_towards_nodate,
	title = {Towards {Semantometrics}: {A} {New} {Semantic} {Similarity} {Based} {Measure} for {Assessing} a {Research} {Publication}'s {Contribution}},
	volume = {20},
	doi = {https://doi.org/10.1045/november14-knoth},
	number = {11/12},
	journal = {D-Lib Magazine},
	author = {Knoth, Petr and Herrmannova, Drahomira},
	pages = {8},
}

@article{lariviere_contributorship_2016,
	title = {Contributorship and division of labor in knowledge production},
	volume = {46},
	issn = {0306-3127, 1460-3659},
	url = {http://journals.sagepub.com/doi/10.1177/0306312716650046},
	doi = {10.1177/0306312716650046},
	abstract = {Scientific authorship has been increasingly complemented with contributorship statements. While such statements are said to ensure more equitable credit and responsibility attribution, they also provide an opportunity to examine the roles and functions that authors play in the construction of knowledge and the relationship between these roles and authorship order. Drawing on a comprehensive and multidisciplinary dataset of 87,002 documents in which contributorship statements are found, this article examines the forms that division of labor takes across disciplines, the relationships between various types of contributions, as well as the relationships between the contribution types and various indicators of authors’ seniority. It shows that scientific work is more highly divided in medical disciplines than in mathematics, physics, and disciplines of the social sciences, and that, with the exception of medicine, the writing of the paper is the task most often associated with authorship. The results suggest a clear distinction between contributions that could be labeled as ‘technical’ and those that could be considered ‘conceptual’: While conceptual tasks are typically associated with authors with higher seniority, technical tasks are more often performed by younger scholars. Finally, results provide evidence of a U-shaped relationship between extent of contribution and author order: In all disciplines, first and last authors typically contribute to more tasks than middle authors. The paper concludes with a discussion of the implications of the results for the reward system of science.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Social Studies of Science},
	author = {Larivière, Vincent and Desrochers, Nadine and Macaluso, Benoît and Mongeon, Philippe and Paul-Hus, Adèle and Sugimoto, Cassidy R},
	month = jun,
	year = {2016},
	pages = {417--435},
}

@article{harris_array_2020,
	title = {Array programming with {NumPy}},
	volume = {585},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/s41586-020-2649-2},
	doi = {10.1038/s41586-020-2649-2},
	abstract = {Abstract
            
              Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves
              1
              and in the first imaging of a black hole
              2
              . Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. NumPy is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Owing to its central position in the ecosystem, NumPy increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface (API), provides a flexible framework to support the next decade of scientific and industrial analysis.},
	language = {en},
	number = {7825},
	urldate = {2021-07-09},
	journal = {Nature},
	author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, Stéfan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del Río, Jaime Fernández and Wiebe, Mark and Peterson, Pearu and Gérard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
	month = sep,
	year = {2020},
	pages = {357--362},
}

@article{noauthor_correction_2006,
	title = {Correction or retraction?},
	volume = {444},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/444123b},
	doi = {10.1038/444123b},
	language = {en},
	number = {7116},
	urldate = {2021-07-09},
	journal = {Nature},
	month = nov,
	year = {2006},
	pages = {123--124},
}

@article{tierney_creative_2020,
	title = {Creative destruction in science},
	volume = {161},
	issn = {07495978},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0749597820303678},
	doi = {10.1016/j.obhdp.2020.07.002},
	language = {en},
	urldate = {2021-07-09},
	journal = {Organizational Behavior and Human Decision Processes},
	author = {Tierney, Warren and Hardy, Jay H. and Ebersole, Charles R. and Leavitt, Keith and Viganola, Domenico and Clemente, Elena Giulia and Gordon, Michael and Dreber, Anna and Johannesson, Magnus and Pfeiffer, Thomas and Uhlmann, Eric Luis},
	month = nov,
	year = {2020},
	pages = {291--309},
}

@article{tierney_creative_2021,
	title = {A creative destruction approach to replication: {Implicit} work and sex morality across cultures},
	volume = {93},
	issn = {00221031},
	shorttitle = {A creative destruction approach to replication},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022103120304005},
	doi = {10.1016/j.jesp.2020.104060},
	language = {en},
	urldate = {2021-07-09},
	journal = {Journal of Experimental Social Psychology},
	author = {Tierney, Warren and Hardy, Jay and Ebersole, Charles R. and Viganola, Domenico and Clemente, Elena Giulia and Gordon, Michael and Hoogeveen, Suzanne and Haaf, Julia and Dreber, Anna and Johannesson, Magnus and Pfeiffer, Thomas and Huang, Jason L. and Vaughn, Leigh Ann and DeMarree, Kenneth and Igou, Eric R. and Chapman, Hanah and Gantman, Ana and Vanaman, Matthew and Wylie, Jordan and Storbeck, Justin and Andreychik, Michael R. and McPhetres, Jon and Uhlmann, Eric Luis},
	month = mar,
	year = {2021},
	pages = {104060},
}

@misc{noauthor_authorship_nodate,
	title = {Authorship \& contributorship {\textbar} {The} {BMJ}},
	url = {https://www.bmj.com/about-bmj/resources-authors/article-submission/authorship-contributorship},
	urldate = {2021-07-09},
	journal = {The British Medical Journal},
}

@misc{editorial_director_what_2021,
	title = {What is a group author (collaborative author) and does it need an {ORCID}?},
	url = {https://support.jmir.org/hc/en-us/articles/115001449591-What-is-a-group-author-collaborative-author-and-does-it-need-an-ORCID-},
	abstract = {A group author (also called collaborative author) is a group name (such as "CONSORT Group" or "AHA Heart Failure Taskforce" or "XY Workshop Members"), which will be li...},
	language = {en-US},
	urldate = {2021-07-09},
	journal = {JMIR Publications},
	author = {{Editorial Director}},
	month = may,
	year = {2021},
}

@article{cronbach_construct_1955,
	title = {Construct validity in psychological tests.},
	volume = {52},
	issn = {1939-1455, 0033-2909},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0040957},
	doi = {10.1037/h0040957},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Psychological Bulletin},
	author = {Cronbach, Lee J. and Meehl, Paul E.},
	month = jul,
	year = {1955},
	pages = {281--302},
}

@article{smith_construct_2005,
	title = {On {Construct} {Validity}: {Issues} of {Method} and {Measurement}.},
	volume = {17},
	issn = {1939-134X, 1040-3590},
	shorttitle = {On {Construct} {Validity}},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1040-3590.17.4.396},
	doi = {10.1037/1040-3590.17.4.396},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Psychological Assessment},
	author = {Smith, Gregory T.},
	month = dec,
	year = {2005},
	pages = {396--408},
}

@book{shadish_experimental_2001,
	address = {Boston},
	title = {Experimental and quasi-experimental designs for generalized causal inference},
	isbn = {978-0-395-61556-0},
	publisher = {Houghton Mifflin},
	author = {Shadish, William R. and Cook, Thomas D. and Campbell, Donald T.},
	year = {2001},
	keywords = {Causation, Experiments},
}

@article{haynes_content_1995,
	title = {Content validity in psychological assessment: {A} functional approach to concepts and methods.},
	volume = {7},
	issn = {1939-134X, 1040-3590},
	shorttitle = {Content validity in psychological assessment},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1040-3590.7.3.238},
	doi = {10.1037/1040-3590.7.3.238},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Psychological Assessment},
	author = {Haynes, Stephen N. and Richard, David C. S. and Kubany, Edward S.},
	month = sep,
	year = {1995},
	pages = {238--247},
}

@article{brod_qualitative_2009,
	title = {Qualitative research and content validity: developing best practices based on science and experience},
	volume = {18},
	issn = {0962-9343, 1573-2649},
	shorttitle = {Qualitative research and content validity},
	url = {http://link.springer.com/10.1007/s11136-009-9540-9},
	doi = {10.1007/s11136-009-9540-9},
	language = {en},
	number = {9},
	urldate = {2021-07-09},
	journal = {Quality of Life Research},
	author = {Brod, Meryl and Tesler, Laura E. and Christensen, Torsten L.},
	month = nov,
	year = {2009},
	pages = {1263--1278},
}

@book{bollen_structural_1989,
	address = {New York},
	series = {Wiley series in probability and mathematical statistics},
	title = {Structural equations with latent variables},
	isbn = {978-0-471-01171-2},
	publisher = {Wiley},
	author = {Bollen, Kenneth A.},
	year = {1989},
	keywords = {Social sciences, Statistical methods, Latent variables, Structural equation modeling},
}

@article{drost_validity_2011,
	title = {Validity and reliability in social science research.},
	volume = {38},
	number = {1},
	journal = {Education Research and Perspectives},
	author = {Drost, E.A.},
	year = {2011},
	pages = {105--123},
}

@misc{noauthor_get_nodate,
	title = {Get {Involved} - {Creative} {Commons}},
	url = {https://creativecommons.org/about/get-involved/},
	urldate = {2021-07-09},
	journal = {Creative Commons},
}

@techreport{vazire_credibility_2020,
	type = {preprint},
	title = {Credibility {Beyond} {Replicability}: {Improving} the {Four} {Validities} in {Psychological} {Science}},
	shorttitle = {Credibility {Beyond} {Replicability}},
	url = {https://osf.io/bu4d3},
	abstract = {Psychological science has seen an explosion of metascientific work on improving research practices, especially in the area of replicability (reducing false positives). This movement, sometimes called the credibility revolution, has spread to address other problems afflicting psychological science. Here we focus on the “four validities” (Shadish et al., 2002) and highlight some of the most important developments aimed at improving these four validities in psychology research. We propose that the credibility revolution in psychology, while having its roots in replicability, has spurred major advances in validity more broadly, and much of this work has been led by early career researchers.},
	urldate = {2021-07-09},
	institution = {PsyArXiv},
	author = {Vazire, Simine and Schiavone, Sarah R. and Bottesini, Julia G.},
	month = oct,
	year = {2020},
	doi = {10.31234/osf.io/bu4d3},
}

@article{vazire_implications_2018,
	title = {Implications of the {Credibility} {Revolution} for {Productivity}, {Creativity}, and {Progress}},
	volume = {13},
	issn = {1745-6916, 1745-6924},
	url = {http://journals.sagepub.com/doi/10.1177/1745691617751884},
	doi = {10.1177/1745691617751884},
	abstract = {The credibility revolution (sometimes referred to as the “replicability crisis”) in psychology has brought about many changes in the standards by which psychological science is evaluated. These changes include (a) greater emphasis on transparency and openness, (b) a move toward preregistration of research, (c) more direct-replication studies, and (d) higher standards for the quality and quantity of evidence needed to make strong scientific claims. What are the implications of these changes for productivity, creativity, and progress in psychological science? These questions can and should be studied empirically, and I present my predictions here. The productivity of individual researchers is likely to decline, although some changes (e.g., greater collaboration, data sharing) may mitigate this effect. The effects of these changes on creativity are likely to be mixed: Researchers will be less likely to pursue risky questions; more likely to use a broad range of methods, designs, and populations; and less free to define their own best practices and standards of evidence. Finally, the rate of scientific progress—the most important shared goal of scientists—is likely to increase as a result of these changes, although one’s subjective experience of making progress will likely become rarer.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Vazire, Simine},
	month = jul,
	year = {2018},
	pages = {411--417},
}

@article{angrist_credibility_2010,
	title = {The {Credibility} {Revolution} in {Empirical} {Economics}: {How} {Better} {Research} {Design} is {Taking} the {Con} out of {Econometrics}},
	volume = {24},
	issn = {0895-3309},
	shorttitle = {The {Credibility} {Revolution} in {Empirical} {Economics}},
	url = {https://pubs.aeaweb.org/doi/10.1257/jep.24.2.3},
	doi = {10.1257/jep.24.2.3},
	abstract = {Since Edward Leamer's memorable 1983 paper, “Let's Take the Con out of Econometrics,” empirical microeconomics has experienced a credibility revolution. While Leamer's suggested remedy, sensitivity analysis, has played a role in this, we argue that the primary engine driving improvement has been a focus on the quality of empirical research designs. The advantages of a good research design are perhaps most easily apparent in research using random assignment. We begin with an overview of Leamer's 1983 critique and his proposed remedies. We then turn to the key factors we see contributing to improved empirical work, including the availability of more and better data, along with advances in theoretical econometric understanding, but especially the fact that research design has moved front and center in much of empirical micro. We offer a brief digression into macroeconomics and industrial organization, where progress—by our lights—is less dramatic, although there is work in both fields that we find encouraging. Finally, we discuss the view that the design pendulum has swung too far. Critics of design-driven studies argue that in pursuit of clean and credible research designs, researchers seek good answers instead of good questions. We briefly respond to this concern, which worries us little.},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Journal of Economic Perspectives},
	author = {Angrist, Joshua D and Pischke, Jörn-Steffen},
	month = may,
	year = {2010},
	pages = {3--30},
}

@misc{noauthor_credit_nodate,
	title = {{CRediT} - {Contributor} {Roles} {Taxonomy}},
	url = {https://casrai.org/credit/},
	urldate = {2021-07-09},
	journal = {Casrai},
}

@book{devellis_scale_2017,
	address = {Los Angeles},
	edition = {Fourth edition},
	title = {Scale development: theory and applications},
	isbn = {978-1-5063-4156-9},
	shorttitle = {Scale development},
	publisher = {SAGE},
	author = {DeVellis, Robert F.},
	year = {2017},
	keywords = {Scaling (Social sciences)},
}

@article{benoit_crowd-sourced_2016,
	title = {Crowd-sourced {Text} {Analysis}: {Reproducible} and {Agile} {Production} of {Political} {Data}},
	volume = {110},
	issn = {0003-0554, 1537-5943},
	shorttitle = {Crowd-sourced {Text} {Analysis}},
	url = {https://www.cambridge.org/core/product/identifier/S0003055416000058/type/journal_article},
	doi = {10.1017/S0003055416000058},
	abstract = {Empirical social science often relies on data that are not observed in the field, but are transformed into quantitative variables by expert researchers who analyze and interpret qualitative raw sources. While generally considered the most valid way to produce data, this expert-driven process is inherently difficult to replicate or to assess on grounds of reliability. Using crowd-sourcing to distribute text for reading and interpretation by massive numbers of nonexperts, we generate results comparable to those using experts to read and interpret the same texts, but do so far more quickly and flexibly. Crucially, the data we collect can be reproduced and extended transparently, making crowd-sourced datasets intrinsically reproducible. This focuses researchers’ attention on the fundamental scientific objective of specifying reliable and replicable methods for collecting the data needed, rather than on the content of any particular dataset. We also show that our approach works straightforwardly with different types of political text, written in different languages. While findings reported here concern text analysis, they have far-reaching implications for expert-generated data in the social sciences.},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {American Political Science Review},
	author = {Benoit, Kenneth and Conway, Drew and Lauderdale, Benjamin E. and Laver, Michael and Mikhaylov, Slava},
	month = may,
	year = {2016},
	pages = {278--295},
}

@techreport{breznau_observing_2021,
	type = {preprint},
	title = {Observing {Many} {Researchers} {Using} the {Same} {Data} and {Hypothesis} {Reveals} a {Hidden} {Universe} of {Uncertainty}},
	url = {https://osf.io/cd5j9},
	abstract = {How does noise generated by researcher decisions undermine the credibility of science? We test this by observing all decisions made among 73 research teams as they independently conduct studies on the same hypothesis with identical starting data. We find excessive variation of outcomes. When combined, the 107 observed research decisions taken across teams explained at most 2.6\% of the total variance in effect sizes and 10\% of the deviance in subjective conclusions. Expertise, prior beliefs and attitudes of the researchers explain even less. Each model deployed to test the hypothesis was unique, which highlights a vast universe of research design variability that is normally hidden from view and suggests humility when presenting and interpreting scientific findings.},
	urldate = {2021-07-09},
	institution = {MetaArXiv},
	author = {Breznau, Nate and Rinke, Eike Mark and Wuttke, Alexander and Adem, Muna and Adriaans, Jule and Alvarez-Benjumea, Amalia and Andersen, Henrik Kenneth and Auer, Daniel and Azevedo, Flavio and Bahnsen, Oke and Balzer, Dave and Bauer, Gerrit and Bauer, Paul and Baumann, Markus and Baute, Sharon and Benoit, Verena and Bernauer, Julian and Berning, Carl and Berthold, Anna and Bethke, Felix S. and Biegert, Thomas and Blinzler, Katharina and Blumenberg, Johannes and Bobzien, Licia and Bohman, Andrea and Bol, Thijs and Bostic, Amie and Brzozowska, Zuzanna and Burgdorf, Katharina and Burger, Kaspar and Busch, Kathrin and Castillo, Juan Carlos and Chan, Nathan and Christmann, Pablo and Connelly, Roxanne and Czymara, Christian S. and Damian, Elena and Ecker, Alejandro and Edelmann, Achim and Eger, Maureen A. and Ellerbrock, Simon and Forke, Anna and Forster, Andrea Gabriele and Gaasendam, Chris and Gavras, Konstantin and Gayle, Vernon and Gessler, Theresa and Gnambs, Timo and Godefroidt, Amélie and Grömping, Max and Groß, Martin and Gruber, Stefan and Gummer, Tobias and Hadjar, Andreas and Heisig, Jan Paul and Hellmeier, Sebastian and Heyne, Stefanie and Hirsch, Magdalena and Hjerm, Mikael and Hochman, Oshrat and Hövermann, Andreas and Hunger, Sophia and Hunkler, Christian and Huth, Nora and Ignacz, Zsofia and Jacobs, Laura and Jacobsen, Jannes and Jaeger, Bastian and Jungkunz, Sebastian and Jungmann, Nils and Kauff, Mathias and Kleinert, Manuel and Klinger, Julia and Kolb, Jan-Philipp and Kołczyńska, Marta and Kuk, John Seungmin and Kunißen, Katharina and Sinatra, Dafina Kurti and Greinert, Alexander and Lersch, Philipp M. and Löbel, Lea-Maria and Lutscher, Philipp and Mader, Matthias and Madia, Joan Eliel and Malancu, Natalia and Maldonado, Luis and Marahrens, Helge and Martin, Nicole and Martinez, Paul and Mayerl, Jochen and Mayorga, OSCAR Jose and McManus, Patricia and Wagner, Kyle and Meeusen, Cecil and Meierrieks, Daniel and Mellon, Jonathan and Merhout, Friedolin and Merk, Samuel and Meyer, Daniel and Micheli, Leticia and Mijs, Jonathan J.B. and Moya, Cristóbal and Neunhoeffer, Marcel and Nüst, Daniel and Nygård, Olav and Ochsenfeld, Fabian and Otte, Gunnar and Pechenkina, Anna and Prosser, Christopher and Raes, Louis and Ralston, Kevin and Ramos, Miguel and Roets, Arne and Rogers, Jonathan and Ropers, Guido and Samuel, Robin and Sand, Gergor and Schachter, Ariela and Schaeffer, Merlin and Schieferdecker, David and Schlueter, Elmar and Schmidt, Katja and Schmidt, Regine and Schmidt-Catran, Alexander and Schmiedeberg, Claudia and Schneider, Jürgen and Schoonvelde, Martijn and Schulte-Cloos, Julia and Schumann, Sandy and Schunck, Reinhard and Schupp, Juergen and Seuring, Julian and Silber, Henning and Sleegers, Willem W. A. and Sonntag, Nico and Staudt, Alexander and Steiber, Nadia and Steiner, Nils and Sternberg, Sebastian and Stiers, Dieter and Stojmenovska, Dragana and Storz, Nora and Striessnig, Erich and Stroppe, Anne-Kathrin and Teltemann, Janna and Tibajev, Andrey and Tung, Brian B. and Vagni, Giacomo and Van Assche, Jasper and van der Linden, Meta and van der Noll, Jolanda and Van Hootegem, Arno and Vogtenhuber, Stefan and Voicu, Bogdan and Wagemans, Fieke and Wehl, Nadja and Werner, Hannah and Wiernik, Brenton M. and Winter, Fabian and Wolf, Christof and Yamada, Yuki and Zhang, Nan and Ziller, Conrad and Zins, Stefan and Żółtak, Tomasz and Nguyen, Hung Hoang Viet},
	month = mar,
	year = {2021},
	doi = {10.31222/osf.io/cd5j9},
}

@article{franzoni_crowd_2014,
	title = {Crowd science: {The} organization of scientific research in open collaborative projects},
	volume = {43},
	issn = {00487333},
	shorttitle = {Crowd science},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0048733313001212},
	doi = {10.1016/j.respol.2013.07.005},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Research Policy},
	author = {Franzoni, Chiara and Sauermann, Henry},
	month = feb,
	year = {2014},
	pages = {1--20},
}

@article{klein_many_2018,
	title = {Many {Labs} 2: {Investigating} {Variation} in {Replicability} {Across} {Samples} and {Settings}},
	volume = {1},
	issn = {2515-2459, 2515-2467},
	shorttitle = {Many {Labs} 2},
	url = {http://journals.sagepub.com/doi/10.1177/2515245918810225},
	doi = {10.1177/2515245918810225},
	abstract = {We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings. Each protocol was administered to approximately half of 125 samples that comprised 15,305 participants from 36 countries and territories. Using the conventional criterion of statistical significance ( p {\textless} .05), we found that 15 (54\%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding. With a strict significance criterion ( p {\textless} .0001), 14 (50\%) of the replications still provided such evidence, a reflection of the extremely high-powered design. Seven (25\%) of the replications yielded effect sizes larger than the original ones, and 21 (75\%) yielded effect sizes smaller than the original ones. The median comparable Cohen’s ds were 0.60 for the original findings and 0.15 for the replications. The effect sizes were small ({\textless} 0.20) in 16 of the replications (57\%), and 9 effects (32\%) were in the direction opposite the direction of the original effect. Across settings, the Q statistic indicated significant heterogeneity in 11 (39\%) of the replication effects, and most of those were among the findings with the largest overall effect sizes; only 1 effect that was near zero in the aggregate showed significant heterogeneity according to this measure. Only 1 effect had a tau value greater than .20, an indication of moderate heterogeneity. Eight others had tau values near or slightly above .10, an indication of slight heterogeneity. Moderation tests indicated that very little heterogeneity was attributable to the order in which the tasks were performed or whether the tasks were administered in lab versus online. Exploratory comparisons revealed little heterogeneity between Western, educated, industrialized, rich, and democratic (WEIRD) cultures and less WEIRD cultures (i.e., cultures with relatively high and low WEIRDness scores, respectively). Cumulatively, variability in the observed effect sizes was attributable more to the effect being studied than to the sample or setting in which it was studied.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Klein, Richard A. and Vianello, Michelangelo and Hasselman, Fred and Adams, Byron G. and Adams, Reginald B. and Alper, Sinan and Aveyard, Mark and Axt, Jordan R. and Babalola, Mayowa T. and Bahník, Štěpán and Batra, Rishtee and Berkics, Mihály and Bernstein, Michael J. and Berry, Daniel R. and Bialobrzeska, Olga and Binan, Evans Dami and Bocian, Konrad and Brandt, Mark J. and Busching, Robert and Rédei, Anna Cabak and Cai, Huajian and Cambier, Fanny and Cantarero, Katarzyna and Carmichael, Cheryl L. and Ceric, Francisco and Chandler, Jesse and Chang, Jen-Ho and Chatard, Armand and Chen, Eva E. and Cheong, Winnee and Cicero, David C. and Coen, Sharon and Coleman, Jennifer A. and Collisson, Brian and Conway, Morgan A. and Corker, Katherine S. and Curran, Paul G. and Cushman, Fiery and Dagona, Zubairu K. and Dalgar, Ilker and Dalla Rosa, Anna and Davis, William E. and de Bruijn, Maaike and De Schutter, Leander and Devos, Thierry and de Vries, Marieke and Doğulu, Canay and Dozo, Nerisa and Dukes, Kristin Nicole and Dunham, Yarrow and Durrheim, Kevin and Ebersole, Charles R. and Edlund, John E. and Eller, Anja and English, Alexander Scott and Finck, Carolyn and Frankowska, Natalia and Freyre, Miguel-Ángel and Friedman, Mike and Galliani, Elisa Maria and Gandi, Joshua C. and Ghoshal, Tanuka and Giessner, Steffen R. and Gill, Tripat and Gnambs, Timo and Gómez, Ángel and González, Roberto and Graham, Jesse and Grahe, Jon E. and Grahek, Ivan and Green, Eva G. T. and Hai, Kakul and Haigh, Matthew and Haines, Elizabeth L. and Hall, Michael P. and Heffernan, Marie E. and Hicks, Joshua A. and Houdek, Petr and Huntsinger, Jeffrey R. and Huynh, Ho Phi and IJzerman, Hans and Inbar, Yoel and Innes-Ker, Åse H. and Jiménez-Leal, William and John, Melissa-Sue and Joy-Gaba, Jennifer A. and Kamiloğlu, Roza G. and Kappes, Heather Barry and Karabati, Serdar and Karick, Haruna and Keller, Victor N. and Kende, Anna and Kervyn, Nicolas and Knežević, Goran and Kovacs, Carrie and Krueger, Lacy E. and Kurapov, German and Kurtz, Jamie and Lakens, Daniël and Lazarević, Ljiljana B. and Levitan, Carmel A. and Lewis, Neil A. and Lins, Samuel and Lipsey, Nikolette P. and Losee, Joy E. and Maassen, Esther and Maitner, Angela T. and Malingumu, Winfrida and Mallett, Robyn K. and Marotta, Satia A. and Međedović, Janko and Mena-Pacheco, Fernando and Milfont, Taciano L. and Morris, Wendy L. and Murphy, Sean C. and Myachykov, Andriy and Neave, Nick and Neijenhuijs, Koen and Nelson, Anthony J. and Neto, Félix and Lee Nichols, Austin and Ocampo, Aaron and O’Donnell, Susan L. and Oikawa, Haruka and Oikawa, Masanori and Ong, Elsie and Orosz, Gábor and Osowiecka, Malgorzata and Packard, Grant and Pérez-Sánchez, Rolando and Petrović, Boban and Pilati, Ronaldo and Pinter, Brad and Podesta, Lysandra and Pogge, Gabrielle and Pollmann, Monique M. H. and Rutchick, Abraham M. and Saavedra, Patricio and Saeri, Alexander K. and Salomon, Erika and Schmidt, Kathleen and Schönbrodt, Felix D. and Sekerdej, Maciej B. and Sirlopú, David and Skorinko, Jeanine L. M. and Smith, Michael A. and Smith-Castro, Vanessa and Smolders, Karin C. H. J. and Sobkow, Agata and Sowden, Walter and Spachtholz, Philipp and Srivastava, Manini and Steiner, Troy G. and Stouten, Jeroen and Street, Chris N. H. and Sundfelt, Oskar K. and Szeto, Stephanie and Szumowska, Ewa and Tang, Andrew C. W. and Tanzer, Norbert and Tear, Morgan J. and Theriault, Jordan and Thomae, Manuela and Torres, David and Traczyk, Jakub and Tybur, Joshua M. and Ujhelyi, Adrienn and van Aert, Robbie C. M. and van Assen, Marcel A. L. M. and van der Hulst, Marije and van Lange, Paul A. M. and van ’t Veer, Anna Elisabeth and Vásquez- Echeverría, Alejandro and Ann Vaughn, Leigh and Vázquez, Alexandra and Vega, Luis Diego and Verniers, Catherine and Verschoor, Mark and Voermans, Ingrid P. J. and Vranka, Marek A. and Welch, Cheryl and Wichman, Aaron L. and Williams, Lisa A. and Wood, Michael and Woodzicka, Julie A. and Wronska, Marta K. and Young, Liane and Zelenski, John M. and Zhijia, Zeng and Nosek, Brian A.},
	month = dec,
	year = {2018},
	pages = {443--490},
}

@article{klein_investigating_2014,
	title = {Investigating {Variation} in {Replicability}: {A} “{Many} {Labs}” {Replication} {Project}},
	volume = {45},
	issn = {1864-9335, 2151-2590},
	shorttitle = {Investigating {Variation} in {Replicability}},
	url = {https://econtent.hogrefe.com/doi/10.1027/1864-9335/a000178},
	doi = {10.1027/1864-9335/a000178},
	abstract = {Although replication is a central tenet of science, direct replications are rare in psychology. This research tested variation in the replicability of 13 classic and contemporary effects across 36 independent samples totaling 6,344 participants. In the aggregate, 10 effects replicated consistently. One effect – imagined contact reducing prejudice – showed weak support for replicability. And two effects – flag priming influencing conservatism and currency priming influencing system justification – did not replicate. We compared whether the conditions such as lab versus online or US versus international sample predicted effect magnitudes. By and large they did not. The results of this small sample of effects suggest that replicability is more dependent on the effect itself than on the sample and setting used to investigate the effect.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Social Psychology},
	author = {Klein, Richard A. and Ratliff, Kate A. and Vianello, Michelangelo and Adams, Reginald B. and Bahník, Štěpán and Bernstein, Michael J. and Bocian, Konrad and Brandt, Mark J. and Brooks, Beach and Brumbaugh, Claudia Chloe and Cemalcilar, Zeynep and Chandler, Jesse and Cheong, Winnee and Davis, William E. and Devos, Thierry and Eisner, Matthew and Frankowska, Natalia and Furrow, David and Galliani, Elisa Maria and Hasselman, Fred and Hicks, Joshua A. and Hovermale, James F. and Hunt, S. Jane and Huntsinger, Jeffrey R. and IJzerman, Hans and John, Melissa-Sue and Joy-Gaba, Jennifer A. and Barry Kappes, Heather and Krueger, Lacy E. and Kurtz, Jaime and Levitan, Carmel A. and Mallett, Robyn K. and Morris, Wendy L. and Nelson, Anthony J. and Nier, Jason A. and Packard, Grant and Pilati, Ronaldo and Rutchick, Abraham M. and Schmidt, Kathleen and Skorinko, Jeanine L. and Smith, Robert and Steiner, Troy G. and Storbeck, Justin and Van Swol, Lyn M. and Thompson, Donna and van ‘t Veer, A. E. and Ann Vaughn, Leigh and Vranka, Marek and Wichman, Aaron L. and Woodzicka, Julie A. and Nosek, Brian A.},
	month = may,
	year = {2014},
	pages = {142--152},
}

@article{klein_practical_2018,
	title = {A {Practical} {Guide} for {Transparency} in {Psychological} {Science}},
	volume = {4},
	issn = {2474-7394},
	url = {https://online.ucpress.edu/collabra/article/4/1/20/112998/A-Practical-Guide-for-Transparency-in},
	doi = {10.1525/collabra.158},
	abstract = {The credibility of scientific claims depends upon the transparency of the research products upon which they are based (e.g., study protocols, data, materials, and analysis scripts). As psychology navigates a period of unprecedented introspection, user-friendly tools and services that support open science have flourished. However, the plethora of decisions and choices involved can be bewildering. Here we provide a practical guide to help researchers navigate the process of preparing and sharing the products of their research (e.g., choosing a repository, preparing their research products for sharing, structuring folders, etc.). Being an open scientist means adopting a few straightforward research management practices, which lead to less error prone, reproducible research workflows. Further, this adoption can be piecemeal – each incremental step towards complete transparency adds positive value. Transparent research practices not only improve the efficiency of individual researchers, they enhance the credibility of the knowledge generated by the scientific community.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Collabra: Psychology},
	author = {Klein, Olivier and Hardwicke, Tom E. and Aust, Frederik and Breuer, Johannes and Danielsson, Henrik and Mohr, Alicia Hofelich and IJzerman, Hans and Nilsonne, Gustav and Vanpaemel, Wolf and Frank, Michael C.},
	editor = {Nuijten, Michéle and Vazire, Simine},
	month = jan,
	year = {2018},
	pages = {20},
}

@article{moshontz_psychological_2018,
	title = {The {Psychological} {Science} {Accelerator}: {Advancing} {Psychology} {Through} a {Distributed} {Collaborative} {Network}},
	volume = {1},
	issn = {2515-2459, 2515-2467},
	shorttitle = {The {Psychological} {Science} {Accelerator}},
	url = {http://journals.sagepub.com/doi/10.1177/2515245918797607},
	doi = {10.1177/2515245918797607},
	abstract = {Concerns about the veracity of psychological research have been growing. Many findings in psychological science are based on studies with insufficient statistical power and nonrepresentative samples, or may otherwise be limited to specific, ungeneralizable settings or populations. Crowdsourced research, a type of large-scale collaboration in which one or more research projects are conducted across multiple lab sites, offers a pragmatic solution to these and other current methodological challenges. The Psychological Science Accelerator (PSA) is a distributed network of laboratories designed to enable and support crowdsourced research projects. These projects can focus on novel research questions or replicate prior research in large, diverse samples. The PSA’s mission is to accelerate the accumulation of reliable and generalizable evidence in psychological science. Here, we describe the background, structure, principles, procedures, benefits, and challenges of the PSA. In contrast to other crowdsourced research networks, the PSA is ongoing (as opposed to time limited), efficient (in that structures and principles are reused for different projects), decentralized, diverse (in both subjects and researchers), and inclusive (of proposals, contributions, and other relevant input from anyone inside or outside the network). The PSA and other approaches to crowdsourced psychological science will advance understanding of mental processes and behaviors by enabling rigorous research and systematic examination of its generalizability.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Moshontz, Hannah and Campbell, Lorne and Ebersole, Charles R. and IJzerman, Hans and Urry, Heather L. and Forscher, Patrick S. and Grahe, Jon E. and McCarthy, Randy J. and Musser, Erica D. and Antfolk, Jan and Castille, Christopher M. and Evans, Thomas Rhys and Fiedler, Susann and Flake, Jessica Kay and Forero, Diego A. and Janssen, Steve M. J. and Keene, Justin Robert and Protzko, John and Aczel, Balazs and Álvarez Solas, Sara and Ansari, Daniel and Awlia, Dana and Baskin, Ernest and Batres, Carlota and Borras-Guevara, Martha Lucia and Brick, Cameron and Chandel, Priyanka and Chatard, Armand and Chopik, William J. and Clarance, David and Coles, Nicholas A. and Corker, Katherine S. and Dixson, Barnaby James Wyld and Dranseika, Vilius and Dunham, Yarrow and Fox, Nicholas W. and Gardiner, Gwendolyn and Garrison, S. Mason and Gill, Tripat and Hahn, Amanda C. and Jaeger, Bastian and Kačmár, Pavol and Kaminski, Gwenaël and Kanske, Philipp and Kekecs, Zoltan and Kline, Melissa and Koehn, Monica A. and Kujur, Pratibha and Levitan, Carmel A. and Miller, Jeremy K. and Okan, Ceylan and Olsen, Jerome and Oviedo-Trespalacios, Oscar and Özdoğru, Asil Ali and Pande, Babita and Parganiha, Arti and Parveen, Noorshama and Pfuhl, Gerit and Pradhan, Sraddha and Ropovik, Ivan and Rule, Nicholas O. and Saunders, Blair and Schei, Vidar and Schmidt, Kathleen and Singh, Margaret Messiah and Sirota, Miroslav and Steltenpohl, Crystal N. and Stieger, Stefan and Storage, Daniel and Sullivan, Gavin Brent and Szabelska, Anna and Tamnes, Christian K. and Vadillo, Miguel A. and Valentova, Jaroslava V. and Vanpaemel, Wolf and Varella, Marco A. C. and Vergauwe, Evie and Verschoor, Mark and Vianello, Michelangelo and Voracek, Martin and Williams, Glenn P. and Wilson, John Paul and Zickfeld, Janis H. and Arnal, Jack D. and Aydin, Burak and Chen, Sau-Chin and DeBruine, Lisa M. and Fernandez, Ana Maria and Horstmann, Kai T. and Isager, Peder M. and Jones, Benedict and Kapucu, Aycan and Lin, Hause and Mensink, Michael C. and Navarrete, Gorka and Silan, Miguel A. and Chartier, Christopher R.},
	month = dec,
	year = {2018},
	pages = {501--515},
}

@article{peer_beyond_2017,
	title = {Beyond the {Turk}: {Alternative} platforms for crowdsourcing behavioral research},
	volume = {70},
	issn = {00221031},
	shorttitle = {Beyond the {Turk}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022103116303201},
	doi = {10.1016/j.jesp.2017.01.006},
	language = {en},
	urldate = {2021-07-09},
	journal = {Journal of Experimental Social Psychology},
	author = {Peer, Eyal and Brandimarte, Laura and Samat, Sonam and Acquisti, Alessandro},
	month = may,
	year = {2017},
	pages = {153--163},
}

@article{silberzahn_many_2018,
	title = {Many {Analysts}, {One} {Data} {Set}: {Making} {Transparent} {How} {Variations} in {Analytic} {Choices} {Affect} {Results}},
	volume = {1},
	issn = {2515-2459, 2515-2467},
	shorttitle = {Many {Analysts}, {One} {Data} {Set}},
	url = {http://journals.sagepub.com/doi/10.1177/2515245917747646},
	doi = {10.1177/2515245917747646},
	abstract = {Twenty-nine teams involving 61 analysts used the same data set to address the same research question: whether soccer referees are more likely to give red cards to dark-skin-toned players than to light-skin-toned players. Analytic approaches varied widely across the teams, and the estimated effect sizes ranged from 0.89 to 2.93 ( Mdn = 1.31) in odds-ratio units. Twenty teams (69\%) found a statistically significant positive effect, and 9 teams (31\%) did not observe a significant relationship. Overall, the 29 different analyses used 21 unique combinations of covariates. Neither analysts’ prior beliefs about the effect of interest nor their level of expertise readily explained the variation in the outcomes of the analyses. Peer ratings of the quality of the analyses also did not account for the variability. These findings suggest that significant variation in the results of analyses of complex data may be difficult to avoid, even by experts with honest intentions. Crowdsourcing data analysis, a strategy in which numerous research teams are recruited to simultaneously investigate the same research question, makes transparent how defensible, yet subjective, analytic choices influence research results.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Silberzahn, R. and Uhlmann, E. L. and Martin, D. P. and Anselmi, P. and Aust, F. and Awtrey, E. and Bahník, Š. and Bai, F. and Bannard, C. and Bonnier, E. and Carlsson, R. and Cheung, F. and Christensen, G. and Clay, R. and Craig, M. A. and Dalla Rosa, A. and Dam, L. and Evans, M. H. and Flores Cervantes, I. and Fong, N. and Gamez-Djokic, M. and Glenz, A. and Gordon-McKeon, S. and Heaton, T. J. and Hederos, K. and Heene, M. and Hofelich Mohr, A. J. and Högden, F. and Hui, K. and Johannesson, M. and Kalodimos, J. and Kaszubowski, E. and Kennedy, D. M. and Lei, R. and Lindsay, T. A. and Liverani, S. and Madan, C. R. and Molden, D. and Molleman, E. and Morey, R. D. and Mulder, L. B. and Nijstad, B. R. and Pope, N. G. and Pope, B. and Prenoveau, J. M. and Rink, F. and Robusto, E. and Roderique, H. and Sandberg, A. and Schlüter, E. and Schönbrodt, F. D. and Sherman, M. F. and Sommer, S. A. and Sotak, K. and Spain, S. and Spörlein, C. and Stafford, T. and Stefanutti, L. and Tauber, S. and Ullrich, J. and Vianello, M. and Wagenmakers, E.-J. and Witkowiak, M. and Yoon, S. and Nosek, B. A.},
	month = sep,
	year = {2018},
	pages = {337--356},
}

@article{uhlmann_scientific_2019,
	title = {Scientific {Utopia} {III}: {Crowdsourcing} {Science}},
	volume = {14},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Scientific {Utopia} {III}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691619850561},
	doi = {10.1177/1745691619850561},
	abstract = {Most scientific research is conducted by small teams of investigators who together formulate hypotheses, collect data, conduct analyses, and report novel findings. These teams operate independently as vertically integrated silos. Here we argue that scientific research that is horizontally distributed can provide substantial complementary value, aiming to maximize available resources, promote inclusiveness and transparency, and increase rigor and reliability. This alternative approach enables researchers to tackle ambitious projects that would not be possible under the standard model. Crowdsourced scientific initiatives vary in the degree of communication between project members from largely independent work curated by a coordination team to crowd collaboration on shared activities. The potential benefits and challenges of large-scale collaboration span the entire research process: ideation, study design, data collection, data analysis, reporting, and peer review. Complementing traditional small science with crowdsourced approaches can accelerate the progress of science and improve the quality of scientific research.},
	language = {en},
	number = {5},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Uhlmann, Eric Luis and Ebersole, Charles R. and Chartier, Christopher R. and Errington, Timothy M. and Kidwell, Mallory C. and Lai, Calvin K. and McCarthy, Randy J. and Riegelman, Amy and Silberzahn, Raphael and Nosek, Brian A.},
	month = sep,
	year = {2019},
	pages = {711--733},
}

@techreport{tennant_introducing_2019,
	type = {preprint},
	title = {Introducing {Massively} {Open} {Online} {Papers} ({MOOPs})},
	url = {https://osf.io/et8ak},
	abstract = {An enormous wealth of digital tools now exists for collaborating on scholarly research projects. In particular, it is now possible to collaboratively author research articles in an openly participatory and dynamic format. Here we describe and provide recommendations for a more open process of collaboration, and discuss the potential issues and pitfalls that come with managing large and diverse authoring communities. We summarize our personal experiences in a form of ‘ten simple rules’. Typically, these collaborative, online projects lead to the production of what we here identify as Massively Open Online Papers (MOOPs). We consider a MOOP to be distinct from a ‘traditional’ collaborative article in that it is defined by an openly participatory process, not bound within the constraints of a predefined contributors list. This is a method of organised creativity designed for the efficient generation and capture of ideas in order to produce new knowledge. Given the diversity of potential authors and projects that can be brought into this process, we do not expect that these tips will address every possible project. Rather, these tips are based on our own experiences and will be useful when different groups and communities can uptake different elements into their own workflows. We believe that creating inclusive, interdisciplinary, and dynamic environments is ultimately good for science, providing a way to exchange knowledge and ideas as a community. We hope that these rules will prove useful for others who might wish to explore this space.},
	urldate = {2021-07-09},
	institution = {MetaArXiv},
	author = {Tennant, Jonathan and Bielczyk, Natalia Z and Greshake Tzovaras, Bastian and Masuzzo, Paola and Steiner, Tobias},
	month = jul,
	year = {2019},
	doi = {10.31222/osf.io/et8ak},
}

@article{stewart_crowdsourcing_2017,
	title = {Crowdsourcing {Samples} in {Cognitive} {Science}},
	volume = {21},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661317301316},
	doi = {10.1016/j.tics.2017.06.007},
	language = {en},
	number = {10},
	urldate = {2021-07-09},
	journal = {Trends in Cognitive Sciences},
	author = {Stewart, Neil and Chandler, Jesse and Paolacci, Gabriele},
	month = oct,
	year = {2017},
	pages = {736--748},
}

@article{himmelstein_open_2019,
	title = {Open collaborative writing with {Manubot}},
	volume = {15},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1007128},
	doi = {10.1371/journal.pcbi.1007128},
	language = {en},
	number = {6},
	urldate = {2021-07-09},
	journal = {PLOS Computational Biology},
	author = {Himmelstein, Daniel S. and Rubinetti, Vincent and Slochower, David R. and Hu, Dongbo and Malladi, Venkat S. and Greene, Casey S. and Gitter, Anthony},
	editor = {Schneidman-Duhovny, Dina},
	month = jun,
	year = {2019},
	pages = {e1007128},
}

@misc{noauthor_what_2021,
	title = {What is {Crowdsourcing}?},
	url = {https://crowdsourcingweek.com/what-is-crowdsourcing/},
	abstract = {Crowdsourcing is the practice of engaging a ‘crowd’ or group for a common goal—often for innovation, problem solving, or efficiency.},
	language = {en-US},
	urldate = {2021-07-09},
	journal = {Crowdsourcing Week},
	month = apr,
	year = {2021},
}

@misc{noauthor_psychological_nodate,
	title = {Psychological {Science} {Accelerator}},
	url = {https://psysciacc.org/},
	abstract = {A Distributed Laboratory Network},
	language = {en-US},
	urldate = {2021-07-09},
	journal = {Psychological Science Accelerator},
}

@article{joseph_why_2011,
	title = {‘{Why} don't you get somebody new to do it?’ {Race} and cultural taxation in the academy},
	volume = {34},
	issn = {0141-9870, 1466-4356},
	shorttitle = {‘{Why} don't you get somebody new to do it?},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01419870.2010.496489},
	doi = {10.1080/01419870.2010.496489},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Ethnic and Racial Studies},
	author = {Joseph, Tiffany D. and Hirshfield, Laura E.},
	month = jan,
	year = {2011},
	pages = {121--141},
}

@techreport{ledgerwood_pandemic_2021,
	type = {preprint},
	title = {The {Pandemic} as a {Portal}: {Reimagining} {Psychological} {Science} as {Truly} {Open} and {Inclusive}},
	shorttitle = {The {Pandemic} as a {Portal}},
	url = {https://osf.io/gdzue},
	abstract = {Psychological science is at an inflection point: The COVID-19 pandemic has already begun to exacerbate inequalities that stem from our historically closed and exclusive culture. Meanwhile, reform efforts to change the future of our science are too narrow in focus to fully succeed. In this paper, we call on psychological scientists—focusing specifically on those who use quantitative methods in the United States as one context in which such a conversation can begin—to reimagine our discipline as fundamentally open and inclusive. First, we discuss who our discipline was designed to serve and how this history produced the inequitable reward and support systems we see today. Second, we highlight how current institutional responses to address worsening inequalities are inadequate, as well as how our disciplinary perspective may both help and hinder our ability to craft effective solutions. Third, we take a hard look in the mirror at the disconnect between what we ostensibly value as a field and what we actually practice. Fourth and finally, we lead readers through a roadmap for reimagining psychological science in whatever roles and spaces they occupy, from an informal discussion group in a department to a formal strategic planning retreat at a scientific society.},
	urldate = {2021-07-09},
	institution = {PsyArXiv},
	author = {Ledgerwood, Alison and Hudson, Sa-kiera Tiarra Jolynn and Lewis, Neil Anthony and Maddox, Keith Brian and Pickett, Cynthia and Remedios, Jessica D. and Cheryan, Sapna and Diekman, Amanda and Dutra, Natalia Bezerra and Goh, Jin X. and Goodwin, Stephanie and Munakata, Yuko and Navarro, Danielle and Onyeador, Ivuoma Ngozi and Srivastava, Sanjay and Wilkins, Clara L},
	month = jan,
	year = {2021},
	doi = {10.31234/osf.io/gdzue},
}

@article{padilla_research_1994,
	title = {Research news and {Comment}: {Ethnic} {Minority} {Scholars}; {Research}, and {Mentoring}: {Current} and {Future} {Issues}},
	volume = {23},
	issn = {0013-189X, 1935-102X},
	shorttitle = {Research news and {Comment}},
	url = {http://journals.sagepub.com/doi/10.3102/0013189X023004024},
	doi = {10.3102/0013189X023004024},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Educational Researcher},
	author = {Padilla, Amado M.},
	month = may,
	year = {1994},
	pages = {24--27},
}

@incollection{soler_is_2008,
	address = {Dordrecht},
	title = {Is {Science} {Cumulative}? a {Physicist} {Viewpoint}},
	isbn = {978-1-4020-6274-2 978-1-4020-6279-7},
	shorttitle = {Is {Science} {Cumulative}?},
	url = {http://link.springer.com/10.1007/978-1-4020-6279-7_10},
	language = {en},
	urldate = {2021-07-09},
	booktitle = {Rethinking {Scientific} {Change} and {Theory} {Comparison}},
	publisher = {Springer Netherlands},
	author = {d’Espagnat, Bernard},
	editor = {Soler, Léna and Sankey, Howard and Hoyningen-Huene, Paul},
	year = {2008},
	doi = {10.1007/978-1-4020-6279-7_10},
	pages = {145--151},
}

@article{carsey_making_2014,
	title = {Making {DA}-{RT} a {Reality}},
	volume = {47},
	issn = {1049-0965, 1537-5935},
	url = {http://www.journals.cambridge.org/abstract_S1049096513001753},
	doi = {10.1017/S1049096513001753},
	abstract = {Calls for greater data access and research transparency have emerged on many fronts within professional social science. For example, the American Political Science Association (APSA) recently adopted new guidelines for data access and research transparency. APSA has also appointed the Data Access and Research Transparency (DA-RT) ad hoc committee to continue exploring these issues. DA-RT sponsored this symposium. In addition, funding agencies like the National Institutes for Health (NIH) and the National Science Foundation (NSF) have expanded requirements for data management and data distribution. These pressures present challenges to researchers, but they also present opportunities.},
	language = {en},
	number = {01},
	urldate = {2021-07-09},
	journal = {PS: Political Science \& Politics},
	author = {Carsey, Thomas M.},
	month = jan,
	year = {2014},
	pages = {72--77},
}

@book{kuhn_structure_1996,
	address = {Chicago, IL},
	edition = {3rd ed},
	title = {The structure of scientific revolutions},
	isbn = {978-0-226-45807-6 978-0-226-45808-3},
	publisher = {University of Chicago Press},
	author = {Kuhn, Thomas S.},
	year = {1996},
	keywords = {History, Science, Philosophy},
}

@article{monroe_rush_2018,
	title = {The {Rush} to {Transparency}: {DA}-{RT} and the {Potential} {Dangers} for {Qualitative} {Research}},
	volume = {16},
	issn = {1537-5927, 1541-0986},
	shorttitle = {The {Rush} to {Transparency}},
	url = {https://www.cambridge.org/core/product/identifier/S153759271700336X/type/journal_article},
	doi = {10.1017/S153759271700336X},
	abstract = {What is the impact of the recent Data Access and Research Transparency (DA-RT) initiative and the Journal Editors Transparency Statement (JETS) on scholars working with qualitative data? Analysis finds DA-RT insufficiently sensitive to the needs of qualitative data and focuses on four inter-related reasons why DA-RT needs to be revised before being widely adopted by political science journals: (1) space constraints that hinder full journal presentation of the analysis of qualitative data; (2) ethical concerns about protecting human subjects, and the time needed to prepare such data before publicly sharing them; (3) costs of data collection and the right of first usage; and (4) a potentially chilling effect of DA-RT on certain types of research topics. Analysis of the author’s own journey from econometric and survey analysis to narrative interviews with people in vulnerable situations, facing moral dilemmas, illustrates why DA-RT needs additional safeguards for qualitative data and methods. Given the increasing importance of qualitative data, and its ability to lend insight into critical political topics, the author argues that implementing the current version of the DA-RT initiative could hinder political science’s ability to address important political questions. Thus DA-RT must be modified to address the special needs of qualitative data.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Perspectives on Politics},
	author = {Monroe, Kristen Renwick},
	month = mar,
	year = {2018},
	pages = {141--148},
}

@article{michener_ten_2015,
	title = {Ten {Simple} {Rules} for {Creating} a {Good} {Data} {Management} {Plan}},
	volume = {11},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1004525},
	doi = {10.1371/journal.pcbi.1004525},
	language = {en},
	number = {10},
	urldate = {2021-07-09},
	journal = {PLOS Computational Biology},
	author = {Michener, William K.},
	editor = {Bourne, Philip E.},
	month = oct,
	year = {2015},
	pages = {e1004525},
}

@misc{walker_rda-dmp-commonrda-dmp-common-standard_2019,
	title = {{RDA}-{DMP}-{Common}/{RDA}-{DMP}-{Common}-{Standard}},
	url = {https://github.com/RDA-DMP-Common/RDA-DMP-Common-Standard},
	abstract = {Official outputs from the RDA DMP Common Standards WG  - RDA-DMP-Common/RDA-DMP-Common-Standard},
	language = {en},
	urldate = {2021-07-09},
	journal = {GitHub},
	author = {Walker, Paul and Miksa, Tom},
	month = nov,
	year = {2019},
}

@article{university_of_illinois_at_urbana-champaign_plan_2016,
	title = {From {Plan} to {Action}: {Successful} {Data} {Management} {Plan} {Implementation} in a {Multidisciplinary} {Project}},
	volume = {5},
	issn = {21613974},
	shorttitle = {From {Plan} to {Action}},
	url = {http://escholarship.umassmed.edu/jeslib/vol5/iss1/6/},
	doi = {10.7191/jeslib.2016.1101},
	number = {1},
	urldate = {2021-07-09},
	journal = {Journal of eScience Librarianship},
	author = {{University of Illinois at Urbana-Champaign} and Burnette, Margaret and Williams, Sarah and {University of Illinois at Urbana-Champaign} and Imker, Heidi and {University of Illinois at Urbana-Champaign}},
	month = sep,
	year = {2016},
	pages = {e1101},
}

@misc{noauthor_data_nodate,
	title = {Data management plans {\textbar} {Stanford} {Libraries}},
	url = {https://library.stanford.edu/research/data-management-services/data-management-plans},
	urldate = {2021-07-09},
	journal = {Stanford Libraries},
}

@techreport{gollwitzer_data_2020,
	type = {preprint},
	title = {Data {Management} and {Data} {Sharing} in {Psychological} {Science}: {Revision} of the {DGPs} {Recommendations}},
	shorttitle = {Data {Management} and {Data} {Sharing} in {Psychological} {Science}},
	url = {https://osf.io/24ncs},
	abstract = {Providing access to research data collected as part of scientific publications and publicly funded research projects is now regarded as a central aspect of an open and transparent scientific practice and is increasingly being called for by funding institutions and scientific journals. To this end, researchers should strive to comply with the so-called FAIR principles (of scientific data management), that is, research data should be findable, accessible, interoperable, and reusable. Systematic data management supports these goals and, at the same time, makes it possible to achieve them efficiently. With these revised recommendations on data management and data sharing, which also draw on feedback from a 2018 survey of its members, the German Psychological Society (Deutsche Gesellschaft für Psychologie; DGPs) specifies important basic principles of data management in psychology. Initially, based on discipline-specific definitions of raw data, primary data, secondary data, and metadata, we provide recommendations on the degree of data processing necessary when publishing data. We then discuss data protection as well as aspects of copyright and data usage before defining the qualitative requirements for trustworthy research data repositories. This is followed by a detailed discussion of pragmatic aspects of data sharing, such as the differences between Type 1 and Type 2 data publications, restrictions on use (embargo period), the definition of "scientific use" by secondary users of shared data, and recommendations on how to resolve potential disputes. Particularly noteworthy is the new recommendation of distinct "access categories" for data, each with different requirements in terms of data protection or research ethics. These range from completely open data without usage restrictions ("access category 0") to data shared under a set of standardized conditions (e.g., reuse restricted to scientific purposes; "access category 1"), individualized usage agreements ("access category 2"), and secure data access under strictly controlled conditions (e.g., in a research data center; “access category 3"). The practical implementation of this important innovation, however, will require data repositories to provide the necessary technical functionalities. In summary, the revised recommendations aim to present pragmatic guidelines for researchers to handle psychological research data in an open and transparent manner, while addressing structural challenges to data sharing solutions that are beneficial for all involved parties.},
	urldate = {2021-07-09},
	institution = {PsyArXiv},
	author = {Gollwitzer, Mario and Abele-Brehm, Andrea and Fiebach, Christian and Ramthun, Roland and Scheel, Anne M. and Schönbrodt, Felix D. and Steinberg, Ulf},
	month = sep,
	year = {2020},
	doi = {10.31234/osf.io/24ncs},
}

@article{abele-brehm_attitudes_2019,
	title = {Attitudes {Toward} {Open} {Science} and {Public} {Data} {Sharing}: {A} {Survey} {Among} {Members} of the {German} {Psychological} {Society}},
	volume = {50},
	issn = {1864-9335, 2151-2590},
	shorttitle = {Attitudes {Toward} {Open} {Science} and {Public} {Data} {Sharing}},
	url = {https://econtent.hogrefe.com/doi/10.1027/1864-9335/a000384},
	doi = {10.1027/1864-9335/a000384},
	abstract = {Abstract. Central values of science are, among others, transparency, verifiability, replicability, and openness. The currently very prominent Open Science (OS) movement supports these values. Among its most important principles are open methodology (comprehensive and useful documentation of methods and materials used), open access to published research output, and open data (making collected data available for re-analyses). We here present a survey conducted among members of the German Psychological Society ( N = 337), in which we applied a mixed-methods approach (quantitative and qualitative data) to assess attitudes toward OS in general and toward data sharing more specifically. Attitudes toward OS were distinguished into positive expectations (“hopes”) and negative expectations (“fears”). These were un-correlated. There were generally more hopes associated with OS and data sharing than fears. Both hopes and fears were highest among early career researchers and lowest among professors. The analysis of the open answers revealed that generally positive attitudes toward data sharing (especially sharing of data related to a published article) are somewhat diminished by cost/benefit considerations. The results are discussed with respect to individual researchers’ behavior and with respect to structural changes in the research system.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Social Psychology},
	author = {Abele-Brehm, Andrea E. and Gollwitzer, Mario and Steinberg, Ulf and Schönbrodt, Felix D.},
	month = jul,
	year = {2019},
	pages = {252--260},
}

@book{tufte_visual_2001,
	address = {Cheshire, Conn},
	edition = {2nd ed},
	title = {The visual display of quantitative information},
	isbn = {978-0-9613921-4-7},
	publisher = {Graphics Press},
	author = {Tufte, Edward R.},
	year = {2001},
	keywords = {Statistics, Graphic methods},
}

@book{healy_data_2018,
	address = {Princeton, NJ},
	title = {Data visualization: a practical introduction},
	isbn = {978-0-691-18161-5 978-0-691-18162-2},
	shorttitle = {Data visualization},
	publisher = {Princeton University Press},
	author = {Healy, Kieran},
	year = {2018},
}

@misc{albayrak-aydemir_hidden_2020,
	title = {"{The} hidden costs of being a scholar from the {Global} {South}" is locked {The} hidden costs of being a scholar from the {Global} {South}},
	url = {https://blogs.lse.ac.uk/highereducation/2020/02/20/the-hidden-costs-of-being-a-scholar-from-the-global-south/},
	abstract = {passport privelege, Global South, The invisible burden on career, international scholars},
	language = {"en-US"},
	urldate = {2021-07-09},
	journal = {LSE Higher Education},
	author = {Albayrak-Aydemir, Nihan},
	month = feb,
	year = {2020},
}

@misc{albayrak-aydemir_academics_2018,
	title = {Academics’ role on the future of higher education: {Important} but unrecognised},
	shorttitle = {Academics’ role on the future of higher education},
	url = {https://lsepgcertcitl.wordpress.com/2018/11/29/academics-role-on-the-future-of-higher-education-important-but-unrecognised/},
	abstract = {In whose hands, does the future of higher education lie?, Celestin Okoroji asks as a PhD student and answers as the following: “We cannot entrust the future of higher education to future aca…},
	language = {en},
	urldate = {2021-07-09},
	journal = {Contemporary Issues in Teaching and Learning},
	author = {Albayrak-Aydemir, Nihan},
	month = nov,
	year = {2018},
}

@misc{albayrak-aydemir_diversity_2018,
	title = {Diversity helps but decolonisation is the key to equality in higher education},
	url = {https://lsepgcertcitl.wordpress.com/2018/04/16/diversity-helps-but-decolonisation-is-the-key-to-equality-in-higher-education/},
	abstract = {Equality in higher education has become a hot topic in recent years and there have been many ongoing discussions being made around it. After the revelation of some shocking reports about the experi…},
	language = {en},
	urldate = {2021-07-09},
	journal = {Contemporary Issues in Teaching and Learning},
	author = {Albayrak-Aydemir, Nihan},
	month = apr,
	year = {2018},
}

@techreport{albayrak-aydemir_facing_nodate,
	address = {UK},
	title = {Facing the challenges of postgraduate study as a minority student},
	institution = {The British Psychological Society},
	author = {Albayrak-Aydemir, Nihan and Okoroji, Celeste},
	editor = {Walton, Holly and Aquino, Maria Raisa Jessica and Talbot, Catherine V. and Melia, Claire},
	pages = {63--66},
}

@misc{bilder_dois_2013,
	type = {website},
	title = {{DOIs} unambiguously and persistently identify published, trustworthy, citable online scholarly literature. {Right}?},
	copyright = {CC BY 4.0},
	url = {https://www.crossref.org/blog/dois-unambiguously-and-persistently-identify-published-trustworthy-citable-online-scholarly-literature-right/},
	abstract = {The South Park movie , “Bigger, Longer \& Uncut” has a DOI:
a) http://dx.doi.org/10.5240/B1FA-0EEC-C316-3316-3A73-L
So does the pornographic movie, “Young Sex Crazed Nurses”:
b) http://dx.doi.org/10.5240/4CF3-57AB-2481-651D-D53D-Q
And the following DOI points to a fake article on a “Google-Based Alien Detector”:
c) http://dx.doi.org/10.6084/m9.figshare.93964
And the following DOI refers to an infamous fake article on literary theory:
d) http://dx.doi.org/10.2307/466856
This scholarly article discusses the entirely fictitious Australian “Drop Bear”:
e) http://dx.doi.org/10.1080/00049182.2012.731307
The following two DOIs point to the same article- the first DOI points to the final author version, and the second DOI points to the final published version:},
	language = {en},
	urldate = {2021-07-09},
	journal = {Crossref},
	author = {Bilder, Geoffrey},
	month = sep,
	year = {2013},
}

@article{morgan_doi_1998,
	title = {The {DOI} ({Digital} {Object} {Identifier})},
	volume = {11},
	issn = {0953-0460},
	url = {http://serials.uksg.org/articles/10.1629/1147},
	doi = {10.1629/1147},
	number = {1},
	urldate = {2021-07-09},
	journal = {Serials: The Journal for the Serials Community},
	author = {Morgan, Cliff},
	month = mar,
	year = {1998},
	pages = {47--51},
}

@incollection{largent_blind_2016,
	title = {Blind {Peer} {Review} by {Academic} {Journals}},
	isbn = {978-0-12-802460-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B978012802460700005X},
	language = {en},
	urldate = {2021-07-09},
	booktitle = {Blinding as a {Solution} to {Bias}},
	publisher = {Elsevier},
	author = {Largent, Emily A. and Snodgrass, Richard T.},
	year = {2016},
	doi = {10.1016/B978-0-12-802460-7.00005-X},
	pages = {75--95},
}

@book{du_bois_souls_2018,
	title = {The souls of {Black} folk: essays and sketches},
	isbn = {978-0-342-19482-7},
	shorttitle = {The souls of {Black} folk},
	language = {English},
	author = {Du Bois, W. E. B},
	year = {2018},
	note = {OCLC: 1257426070},
}

@book{gilroy_black_2002,
	address = {London},
	edition = {3. impr., reprint},
	title = {The black {Atlantic}: modernity and double consciousness},
	isbn = {978-0-86091-675-8 978-0-86091-401-3},
	shorttitle = {The black {Atlantic}},
	language = {eng},
	publisher = {Verso},
	author = {Gilroy, Paul},
	year = {2002},
}

@misc{noauthor_declaration_nodate,
	title = {Declaration on {Research} {Assessment}},
	url = {https://www.hrb.ie/funding/funding-schemes/before-you-apply/how-we-assess-applications/declaration-on-research-assessment/},
	language = {en},
	urldate = {2021-07-09},
	journal = {Health Research Board},
}

@misc{noauthor_digital_nodate,
	title = {Digital {Object} {Identifier} {System} {Handbook}},
	url = {https://www.doi.org/hb.html},
	urldate = {2021-07-09},
	journal = {DOI},
}

@article{schwarz_does_nodate,
	title = {Does merely going through the same moves make for a “direct” replication? {Concepts}, contexts, and operationalizations.},
	volume = {45},
	number = {4},
	journal = {Social Psychology},
	author = {Schwarz, N. and Strack, F.},
	pages = {305--306},
}

@article{bazeley_defining_2003,
	title = {Defining '{Early} {Career}' in {Research}.},
	volume = {45},
	issn = {00181560},
	url = {http://link.springer.com/10.1023/A:1022698529612},
	doi = {10.1023/A:1022698529612},
	number = {3},
	urldate = {2021-07-09},
	journal = {Higher Education},
	author = {Bazeley, Pat},
	year = {2003},
	pages = {257--279},
}

@book{eley_becoming_2012,
	address = {London ; New York},
	title = {Becoming a successful early career researcher},
	isbn = {978-0-415-67248-1 978-0-415-67247-4 978-0-203-11307-3},
	publisher = {Routledge},
	editor = {Eley, Adrian R.},
	year = {2012},
	keywords = {Research, College teachers, EDUCATION / Adult \& Continuing Education, EDUCATION / General, EDUCATION / Higher, Universities and colleges, Vocational guidance},
}

@article{laakso_delayed_2013,
	title = {Delayed open access: {An} overlooked high-impact category of openly available scientific literature},
	volume = {64},
	issn = {15322882},
	shorttitle = {Delayed open access},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/asi.22856},
	doi = {10.1002/asi.22856},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {Journal of the American Society for Information Science and Technology},
	author = {Laakso, Mikael and Björk, Bo-Christer},
	month = jul,
	year = {2013},
	pages = {1323--1329},
}

@misc{noauthor_embargo_2021,
	title = {Embargo (academic publishing)},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Embargo_(academic_publishing)&oldid=1016895567},
	abstract = {In academic publishing, an embargo is a period during which access to academic journals is not allowed to users who have not paid for access (or have access through their institution). The purpose of this is to ensure publishers have revenue to support their activities, although the impact of embargoes on publishers is hotly debated, with some studies finding no impact while publisher experience suggests otherwise. A 2012 survey of libraries by the Association of Learned, Professional, and Society Publishers on the likelihood of journal cancellations in cases where most of the content was made freely accessible after six months suggests there would be a major negative impact on subscriptions, but this result has been debated.
Various types exist: 

A 'moving wall' is a fixed period of months or years.
A fixed date is a particular time point that does not change.
A current year (or other period) is setting a time point on Jan. 1 of the current year, so that all material earlier than that is available. Although fixed during the year, it will change each year.},
	language = {en},
	urldate = {2021-07-09},
	journal = {Wikipedia},
	month = apr,
	year = {2021},
	note = {Page Version ID: 1016895567},
}

@incollection{steup_epistemology_2020,
	edition = {Fall 2020},
	title = {Epistemology},
	url = {https://plato.stanford.edu/archives/fall2020/entries/epistemology/},
	abstract = {The term “epistemology” comes from the Greek words“episteme” and “logos”. “Episteme”can be translated as “knowledge” or“understanding” or “acquaintance”, while“logos” can be translated as “account” or“argument” or “reason”. Just as each of thesedifferent translations captures some facet of the meaning of theseGreek terms, so too does each translation capture a different facet ofepistemology itself. Although the term “epistemology” isno more than a couple of centuries old, the field of epistemology isat least as old as any in  philosophy.[1]  In different parts of its extensive history, different facets ofepistemology have attracted attention.  Plato’s epistemology wasan attempt to understand what it was to know, and how knowledge(unlike mere true opinion) is good for the knower. Locke’sepistemology was an attempt to understand the operations of humanunderstanding, Kant’s epistemology was an attempt to understandthe conditions of the possibility of human understanding, andRussell’s epistemology was an attempt to understand how modernscience could be justified by appeal to sensory experience. Muchrecent work in formal epistemology is an attempt to understand how ourdegrees of confidence are rationally constrained by our evidence, andmuch recent work in feminist epistemology is an attempt to understandthe ways in which interests affect our evidence, and affect ourrational constraints more generally. In all these cases, epistemologyseeks to understand one or another kind ofcognitive success (or, correspondingly, cognitivefailure). This entry surveys the varieties of cognitivesuccess, and some recent efforts to understand some of thosevarieties.},
	urldate = {2021-07-09},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Steup, Matthias and Neta, Ram},
	editor = {Zalta, Edward N.},
	year = {2020},
}

@book{posselt_equity_2020,
	address = {Stanford, California},
	title = {Equity in science: representation, culture, and the dynamics of change in graduate education},
	isbn = {978-1-5036-1272-3},
	shorttitle = {Equity in science},
	abstract = {"Across the country, there has been a resounding call to increase diversity in science fields-met with disillusionment from students and activists who watch, year after year, as unequal representation persists. By exploring this paradox, Julie Posselt provides readers-the scientific community and those who study, support, and aspire to it-with a nuanced understanding of the subtle ways that exclusion and inclusion operate in disciplinary contexts"--},
	publisher = {Stanford University Press},
	author = {Posselt, Julie R.},
	year = {2020},
	keywords = {United States, Science, Diversity in the workplace, Education (Graduate) Social aspects, Minorities, Minorities in science, Study and teaching (Graduate) Social aspects},
}

@techreport{heathers_recovering_2018,
	type = {preprint},
	title = {Recovering data from summary statistics: {Sample} {Parameter} {Reconstruction} via {Iterative} {TEchniques} ({SPRITE})},
	shorttitle = {Recovering data from summary statistics},
	url = {https://peerj.com/preprints/26968v1},
	abstract = {Scientific publications have not traditionally been accompanied by data, either during the peer review process or when published. Concern has arisen that the literature in many fields may contain inaccuracies or errors that cannot be detected without inspecting the original data. Here, we introduce SPRITE (Sample Parameter Reconstruction via Interative TEchniques), a heuristic method for reconstructing plausible samples from descriptive statistics of granular data, allowing reviewers, editors, readers, and future researchers to gain insights into the possible distributions of item values in the original data set. This paper presents the principles of operation of SPRITE, as well as worked examples of its practical use for error detection in real published work. Full source code for three software implementations of SPRITE (in MATLAB, R, and Python) and two web-based implementations requiring no local installation (1, 2) are available for readers.},
	language = {en},
	urldate = {2021-07-09},
	institution = {PeerJ Preprints},
	author = {Heathers, James A and Anaya, Jordan and van der Zee, Tim and Brown, Nicholas JL},
	month = may,
	year = {2018},
	doi = {10.7287/peerj.preprints.26968v1},
}

@article{brown_grim_2017,
	title = {The {GRIM} {Test}: {A} {Simple} {Technique} {Detects} {Numerous} {Anomalies} in the {Reporting} of {Results} in {Psychology}},
	volume = {8},
	issn = {1948-5506, 1948-5514},
	shorttitle = {The {GRIM} {Test}},
	url = {http://journals.sagepub.com/doi/10.1177/1948550616673876},
	doi = {10.1177/1948550616673876},
	abstract = {We present a simple mathematical technique that we call granularity-related inconsistency of means (GRIM) for verifying the summary statistics of research reports in psychology. This technique evaluates whether the reported means of integer data such as Likert-type scales are consistent with the given sample size and number of items. We tested this technique with a sample of 260 recent empirical articles in leading journals. Of the articles that we could test with the GRIM technique ( N = 71), around half ( N = 36) appeared to contain at least one inconsistent mean, and more than 20\% ( N = 16) contained multiple such inconsistencies. We requested the data sets corresponding to 21 of these articles, receiving positive responses in 9 cases. We confirmed the presence of at least one reporting error in all cases, with three articles requiring extensive corrections. The implications for the reliability and replicability of empirical psychology are discussed.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Social Psychological and Personality Science},
	author = {Brown, Nicholas J. L. and Heathers, James A. J.},
	month = may,
	year = {2017},
	pages = {363--369},
}

@article{bik_prevalence_2016,
	title = {The {Prevalence} of {Inappropriate} {Image} {Duplication} in {Biomedical} {Research} {Publications}},
	volume = {7},
	issn = {2161-2129, 2150-7511},
	url = {https://journals.asm.org/doi/10.1128/mBio.00809-16},
	doi = {10.1128/mBio.00809-16},
	abstract = {ABSTRACT
            Inaccurate data in scientific papers can result from honest error or intentional falsification. This study attempted to determine the percentage of published papers that contain inappropriate image duplication, a specific type of inaccurate data. The images from a total of 20,621 papers published in 40 scientific journals from 1995 to 2014 were visually screened. Overall, 3.8\% of published papers contained problematic figures, with at least half exhibiting features suggestive of deliberate manipulation. The prevalence of papers with problematic images has risen markedly during the past decade. Additional papers written by authors of papers with problematic images had an increased likelihood of containing problematic images as well. As this analysis focused only on one type of data, it is likely that the actual prevalence of inaccurate data in the published literature is higher. The marked variation in the frequency of problematic images among journals suggests that journal practices, such as prepublication image screening, influence the quality of the scientific literature.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {mBio},
	author = {Bik, Elisabeth M. and Casadevall, Arturo and Fang, Ferric C.},
	editor = {Sibley, L. David},
	month = jul,
	year = {2016},
}

@article{nuijten_prevalence_2016,
	title = {The prevalence of statistical reporting errors in psychology (1985–2013)},
	volume = {48},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-015-0664-2},
	doi = {10.3758/s13428-015-0664-2},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Behavior Research Methods},
	author = {Nuijten, Michèle B. and Hartgerink, Chris H. J. and van Assen, Marcel A. L. M. and Epskamp, Sacha and Wicherts, Jelte M.},
	month = dec,
	year = {2016},
	pages = {1205--1226},
}

@misc{noauthor_retraction_nodate,
	title = {Retraction {Watch}},
	url = {https://retractionwatch.com/},
	abstract = {Tracking retractions as a window into the scientific process},
	language = {en-US},
	urldate = {2021-07-09},
	journal = {Retraction Watch},
}

@article{ferson_summary_2004,
	title = {Summary from the epistemic uncertainty workshop: consensus amid diversity},
	volume = {85},
	issn = {09518320},
	shorttitle = {Summary from the epistemic uncertainty workshop},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0951832004000729},
	doi = {10.1016/j.ress.2004.03.023},
	language = {en},
	number = {1-3},
	urldate = {2021-07-09},
	journal = {Reliability Engineering \& System Safety},
	author = {Ferson, Scott and Joslyn, Cliff A. and Helton, Jon C. and Oberkampf, William L. and Sentz, Kari},
	month = jul,
	year = {2004},
	pages = {355--369},
}

@article{behrens_principles_1997,
	title = {Principles and procedures of exploratory data analysis.},
	volume = {2},
	issn = {1082-989X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1082-989X.2.2.131},
	doi = {10.1037/1082-989X.2.2.131},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Psychological Methods},
	author = {Behrens, John T.},
	year = {1997},
	pages = {131--160},
}

@book{cook_quasi-experimentation_1979,
	address = {Chicago},
	title = {Quasi-experimentation: design \& analysis issues for field settings},
	isbn = {978-0-528-62053-9},
	shorttitle = {Quasi-experimentation},
	publisher = {Rand McNally College Pub. Co},
	author = {Cook, Thomas D. and Campbell, Donald T.},
	year = {1979},
	keywords = {Social sciences, Research, Fieldwork},
}

@article{lynch_jr_external_1982,
	title = {On the {External} {Validity} of {Experiments} in {Consumer} {Research}},
	volume = {9},
	issn = {0093-5301, 1537-5277},
	url = {https://academic.oup.com/jcr/article-lookup/doi/10.1086/208919},
	doi = {10.1086/208919},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Journal of Consumer Research},
	author = {Lynch, Jr., John G.},
	month = dec,
	year = {1982},
	pages = {225},
}

@article{lakens_improving_2020,
	title = {Improving {Inferences} {About} {Null} {Effects} {With} {Bayes} {Factors} and {Equivalence} {Tests}},
	volume = {75},
	issn = {1079-5014, 1758-5368},
	url = {https://academic.oup.com/psychsocgerontology/article/75/1/45/5033832},
	doi = {10.1093/geronb/gby065},
	abstract = {Abstract
            Researchers often conclude an effect is absent when a null-hypothesis significance test yields a nonsignificant p value. However, it is neither logically nor statistically correct to conclude an effect is absent when a hypothesis test is not significant. We present two methods to evaluate the presence or absence of effects: Equivalence testing (based on frequentist statistics) and Bayes factors (based on Bayesian statistics). In four examples from the gerontology literature, we illustrate different ways to specify alternative models that can be used to reject the presence of a meaningful or predicted effect in hypothesis tests. We provide detailed explanations of how to calculate, report, and interpret Bayes factors and equivalence tests. We also discuss how to design informative studies that can provide support for a null model or for the absence of a meaningful effect. The conceptual differences between Bayes factors and equivalence tests are discussed, and we also note when and why they might lead to similar or different inferences in practice. It is important that researchers are able to falsify predictions or can quantify the support for predicted null effects. Bayes factors and equivalence tests provide useful statistical tools to improve inferences about null effects.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {The Journals of Gerontology: Series B},
	author = {Lakens, Daniël and McLatchie, Neil and Isager, Peder M and Scheel, Anne M and Dienes, Zoltan},
	editor = {Isaacowitz, Derek},
	month = jan,
	year = {2020},
	pages = {45--57},
}

@article{lakens_equivalence_2018,
	title = {Equivalence {Testing} for {Psychological} {Research}: {A} {Tutorial}},
	volume = {1},
	issn = {2515-2459, 2515-2467},
	shorttitle = {Equivalence {Testing} for {Psychological} {Research}},
	url = {http://journals.sagepub.com/doi/10.1177/2515245918770963},
	doi = {10.1177/2515245918770963},
	abstract = {Psychologists must be able to test both for the presence of an effect and for the absence of an effect. In addition to testing against zero, researchers can use the two one-sided tests (TOST) procedure to test for equivalence and reject the presence of a smallest effect size of interest (SESOI). The TOST procedure can be used to determine if an observed effect is surprisingly small, given that a true effect at least as extreme as the SESOI exists. We explain a range of approaches to determine the SESOI in psychological science and provide detailed examples of how equivalence tests should be performed and reported. Equivalence tests are an important extension of the statistical tools psychologists currently use and enable researchers to falsify predictions about the presence, and declare the absence, of meaningful effects.},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Lakens, Daniël and Scheel, Anne M. and Isager, Peder M.},
	month = jun,
	year = {2018},
	pages = {259--269},
}

@techreport{lakens_sample_2021,
	type = {preprint},
	title = {Sample {Size} {Justification}},
	url = {https://osf.io/9d3yf},
	abstract = {An important step when designing a study is to justify the sample size that will be collected. The key aim of a sample size justification is to explain how the collected data is expected to provide valuable information given the inferential goals of the researcher. In this overview article six approaches are discussed to justify the sample size in a quantitative empirical study: 1) collecting data from (an)almost) the entire population, 2) choosing a sample size based on resource constraints, 3) performing an a-priori power analysis, 4) planning for a desired accuracy, 5) using heuristics, or 6) explicitly acknowledging the absence of a justification. An important question to consider when justifying sample sizes is which effect sizes are deemed interesting, and the extent to which the data that is collected informs inferences about these effect sizes. Depending on the sample size justification chosen, researchers could consider 1) what the smallest effect size of interest is, 2) which minimal effect size will be statistically significant, 3) which effect sizes they expect (and what they base these expectations on), 4) which effect sizes would be rejected based on a confidence interval around the effect size, 5) which ranges of effects a study has sufficient power to detect based on a sensitivity power analysis, and 6) which effect sizes are plausible in a specific research area. Researchers can use the guidelines presented in this article to improve their sample size justification, and hopefully, align the informational value of a study with their inferential goals.},
	urldate = {2021-07-09},
	institution = {PsyArXiv},
	author = {Lakens, Daniel},
	month = jan,
	year = {2021},
	doi = {10.31234/osf.io/9d3yf},
}

@article{lakens_performing_2014,
	title = {Performing high-powered studies efficiently with sequential analyses: {Sequential} analyses},
	volume = {44},
	issn = {00462772},
	shorttitle = {Performing high-powered studies efficiently with sequential analyses},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/ejsp.2023},
	doi = {10.1002/ejsp.2023},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {European Journal of Social Psychology},
	author = {Lakens, Daniël},
	month = dec,
	year = {2014},
	pages = {701--710},
}

@article{lakens_pandemic_2020,
	title = {Pandemic researchers — recruit your own best critics},
	volume = {581},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/d41586-020-01392-8},
	doi = {10.1038/d41586-020-01392-8},
	language = {en},
	number = {7807},
	urldate = {2021-07-09},
	journal = {Nature},
	author = {Lakens, Daniël},
	month = may,
	year = {2020},
	pages = {121--121},
}

@article{siddaway_how_2019,
	title = {How to {Do} a {Systematic} {Review}: {A} {Best} {Practice} {Guide} for {Conducting} and {Reporting} {Narrative} {Reviews}, {Meta}-{Analyses}, and {Meta}-{Syntheses}},
	volume = {70},
	issn = {0066-4308, 1545-2085},
	shorttitle = {How to {Do} a {Systematic} {Review}},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-psych-010418-102803},
	doi = {10.1146/annurev-psych-010418-102803},
	abstract = {Systematic reviews are characterized by a methodical and replicable methodology and presentation. They involve a comprehensive search to locate all relevant published and unpublished work on a subject; a systematic integration of search results; and a critique of the extent, nature, and quality of evidence in relation to a particular research question. The best reviews synthesize studies to draw broad theoretical conclusions about what a literature means, linking theory to evidence and evidence to theory. This guide describes how to plan, conduct, organize, and present a systematic review of quantitative (meta-analysis) or qualitative (narrative review, meta-synthesis) information. We outline core standards and principles and describe commonly encountered problems. Although this guide targets psychological scientists, its high level of abstraction makes it potentially relevant to any subject area or discipline. We argue that systematic reviews are a key methodology for clarifying whether and how research findings replicate and for explaining possible inconsistencies, and we call for researchers to conduct systematic reviews to help elucidate whether there is a replication crisis.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Annual Review of Psychology},
	author = {Siddaway, Andy P. and Wood, Alex M. and Hedges, Larry V.},
	month = jan,
	year = {2019},
	pages = {747--770},
}

@article{james_methodology_2016,
	title = {A methodology for systematic mapping in environmental sciences},
	volume = {5},
	issn = {2047-2382},
	url = {http://environmentalevidencejournal.biomedcentral.com/articles/10.1186/s13750-016-0059-6},
	doi = {10.1186/s13750-016-0059-6},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Environmental Evidence},
	author = {James, Katy L. and Randall, Nicola P. and Haddaway, Neal R.},
	month = dec,
	year = {2016},
	pages = {7},
}

@misc{noauthor_evidence_nodate,
	title = {Evidence {Synthesis}},
	url = {https://www.lshtm.ac.uk/research/centres/centre-evaluation/evidence-synthesis},
	language = {en},
	urldate = {2021-07-09},
	journal = {LSHTM},
}

@incollection{weiner_face_2010,
	address = {Hoboken, NJ, USA},
	title = {Face {Validity}},
	isbn = {978-0-470-47921-6},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/9780470479216.corpsy0341},
	language = {en},
	urldate = {2021-07-09},
	booktitle = {The {Corsini} {Encyclopedia} of {Psychology}},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Holden, Ronald R.},
	editor = {Weiner, Irving B. and Craighead, W. Edward},
	month = jan,
	year = {2010},
	doi = {10.1002/9780470479216.corpsy0341},
	pages = {corpsy0341},
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/sdata201618},
	doi = {10.1038/sdata.2016.18},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Scientific Data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J.G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A.C and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	month = dec,
	year = {2016},
	pages = {160018},
}

@article{eagly_feminism_2014,
	title = {Feminism and psychology: {Critiques} of methods and epistemology.},
	volume = {69},
	issn = {1935-990X, 0003-066X},
	shorttitle = {Feminism and psychology},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0037372},
	doi = {10.1037/a0037372},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {American Psychologist},
	author = {Eagly, Alice H. and Riger, Stephanie},
	month = oct,
	year = {2014},
	pages = {685--702},
}

@article{grzanka_intersectionality_2020,
	title = {Intersectionality in psychology: {Translational} science for social justice.},
	volume = {6},
	issn = {2332-2179, 2332-2136},
	shorttitle = {Intersectionality in psychology},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/tps0000276},
	doi = {10.1037/tps0000276},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Translational Issues in Psychological Science},
	author = {Grzanka, Patrick R. and Flores, Mirella J. and VanDaalen, Rachel A. and Velez, Gabriel},
	month = dec,
	year = {2020},
	pages = {304--313},
}

@article{tscharntke_author_2007,
	title = {Author {Sequence} and {Credit} for {Contributions} in {Multiauthored} {Publications}},
	volume = {5},
	issn = {1545-7885},
	url = {https://dx.plos.org/10.1371/journal.pbio.0050018},
	doi = {10.1371/journal.pbio.0050018},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {PLoS Biology},
	author = {Tscharntke, Teja and Hochberg, Michael E and Rand, Tatyana A and Resh, Vincent H and Krauss, Jochen},
	month = jan,
	year = {2007},
	pages = {e18},
}

@misc{noauthor_forrt_nodate,
	title = {{FORRT} - {Framework} for {Open} and {Reproducible} {Research} {Training}},
	url = {https://forrt.org/},
	urldate = {2021-07-09},
	journal = {FORRT},
}

@techreport{forrt_introducing_2019,
	type = {preprint},
	title = {Introducing a {Framework} for {Open} and {Reproducible} {Research} {Training} ({FORRT})},
	url = {https://osf.io/bnh7p},
	abstract = {Current norms for the teaching and mentoring of higher education are rooted in obsolete practices of bygone eras. Improving the transparency and rigor of science is the responsibility of all who engage in it. Ongoing attempts to improve research credibility have, however, neglected an essential aspect of the academic cycle: the training of researchers and consumers of research. Principled teaching and mentoring involve imparting students with an understanding of research findings in light of epistemic uncertainty, and moreover, an appreciation of best practices in the production of knowledge. We introduce a Framework for Open and Reproducible Research Training (FORRT). Its main goal is to provide educators with a pathway towards the incremental adoption of principled teaching and mentoring practices, including open and reproducible research. FORRT will act as an initiative to support instructors, collating existing teaching pedagogies and materials to be reused and adapted for use within new and existing courses. Moreover, FORRT can be used as a tool to benchmark the current level of training students receive across six clusters of open and reproducible research practices: ‘reproducibility and replicability knowledge’, ‘conceptual and statistical knowledge’, ‘reproducible analyses’, ‘preregistration’, ‘open data and materials’, and ‘replication research’. FORRT will strive to be an advocate for the establishment of principled teaching and mentorship as a fourth pillar of a true scientific utopia.[working document here: https://tinyurl.com/FORRTworkingDOC]},
	urldate = {2021-07-09},
	institution = {Open Science Framework},
	author = {{Forrt}},
	month = dec,
	year = {2019},
	doi = {10.31219/osf.io/bnh7p},
}

@misc{free_our_knowledge_about_nodate,
	title = {About},
	url = {https://freeourknowledge.org/about/},
	abstract = {We're building a platform to help researchers organise collective action in support of open and reproducible research practices},
	language = {en},
	urldate = {2021-07-09},
	journal = {Free Our Knowledge},
	author = {{Free Our Knowledge}},
}

@article{faul_statistical_2009,
	title = {Statistical power analyses using {G}*{Power} 3.1: {Tests} for correlation and regression analyses},
	volume = {41},
	issn = {1554-351X, 1554-3528},
	shorttitle = {Statistical power analyses using {G}*{Power} 3.1},
	url = {http://link.springer.com/10.3758/BRM.41.4.1149},
	doi = {10.3758/BRM.41.4.1149},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Behavior Research Methods},
	author = {Faul, Franz and Erdfelder, Edgar and Buchner, Axel and Lang, Albert-Georg},
	month = nov,
	year = {2009},
	pages = {1149--1160},
}

@article{faul_gpower_2007,
	title = {G*{Power} 3: {A} flexible statistical power analysis program for the social, behavioral, and biomedical sciences},
	volume = {39},
	issn = {1554-351X, 1554-3528},
	shorttitle = {G*{Power} 3},
	url = {http://link.springer.com/10.3758/BF03193146},
	doi = {10.3758/BF03193146},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Behavior Research Methods},
	author = {Faul, Franz and Erdfelder, Edgar and Lang, Albert-Georg and Buchner, Axel},
	month = may,
	year = {2007},
	pages = {175--191},
}

@article{moher_assessing_2018,
	title = {Assessing scientists for hiring, promotion, and tenure},
	volume = {16},
	issn = {1545-7885},
	url = {https://dx.plos.org/10.1371/journal.pbio.2004089},
	doi = {10.1371/journal.pbio.2004089},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {PLOS Biology},
	author = {Moher, David and Naudet, Florian and Cristea, Ioana A. and Miedema, Frank and Ioannidis, John P. A. and Goodman, Steven N.},
	month = mar,
	year = {2018},
	pages = {e2004089},
}

@article{moher_preferred_2009,
	title = {Preferred {Reporting} {Items} for {Systematic} {Reviews} and {Meta}-{Analyses}: {The} {PRISMA} {Statement}},
	volume = {6},
	issn = {1549-1676},
	shorttitle = {Preferred {Reporting} {Items} for {Systematic} {Reviews} and {Meta}-{Analyses}},
	url = {https://dx.plos.org/10.1371/journal.pmed.1000097},
	doi = {10.1371/journal.pmed.1000097},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {PLoS Medicine},
	author = {Moher, David and Liberati, Alessandro and Tetzlaff, Jennifer and Altman, Douglas G. and {The PRISMA Group}},
	month = jul,
	year = {2009},
	pages = {e1000097},
}

@misc{naudet_six_2018,
	title = {Six principles for assessing scientists for hiring, promotion, and tenure},
	url = {http://eprints.lse.ac.uk/90753/},
	journal = {Impact of Social Sciences Blog},
	author = {Naudet, Florian and Ioannidis, John P. A. and Miedema, Frank and Cristea, Ioana A. and Goodman, Steven N., Jonathan and Moher, David},
	month = jun,
	year = {2018},
}

@phdthesis{gelman_garden_2013,
	address = {New York, NY},
	type = {Doctoral dissertation},
	title = {The garden of forking paths: {Why} multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research hypothesis was posited ahead of time},
	url = {http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf},
	language = {English},
	school = {Columbia University},
	author = {Gelman, A. and Loken, E.},
	year = {2013},
}

@misc{noauthor_data_nodate-1,
	type = {Text},
	title = {Data protection},
	url = {https://ec.europa.eu/info/law/law-topic/data-protection_en},
	abstract = {Overview of the right to protection of personal data, reform of rules and the data protection regulation and directive.},
	language = {en},
	urldate = {2021-07-09},
	journal = {European Commission - European Commission},
}

@misc{noauthor_guide_2021,
	title = {Guide to the {UK} {General} {Data} {Protection} {Regulation} ({UK} {GDPR})},
	url = {https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/},
	abstract = {The Guide to the UK GDPR explains the provisions of the GDPR to help organisations comply with its requirements. It is for those who have day-to-day responsibility for data protection.},
	language = {en},
	urldate = {2021-07-09},
	month = jul,
	year = {2021},
	note = {Publisher: ICO},
}

@article{crutzen_why_2019,
	title = {Why and how we should care about the {General} {Data} {Protection} {Regulation}},
	volume = {34},
	issn = {0887-0446, 1476-8321},
	url = {https://www.tandfonline.com/doi/full/10.1080/08870446.2019.1606222},
	doi = {10.1080/08870446.2019.1606222},
	language = {en},
	number = {11},
	urldate = {2021-07-09},
	journal = {Psychology \& Health},
	author = {Crutzen, Rik and Ygram Peters, Gjalt-Jorn and Mondschein, Christopher},
	month = nov,
	year = {2019},
	pages = {1347--1357},
}

@article{kukull_generalizability_2012,
	title = {Generalizability: {The} trees, the forest, and the low-hanging fruit},
	volume = {78},
	issn = {0028-3878, 1526-632X},
	shorttitle = {Generalizability},
	url = {http://www.neurology.org/cgi/doi/10.1212/WNL.0b013e318258f812},
	doi = {10.1212/WNL.0b013e318258f812},
	language = {en},
	number = {23},
	urldate = {2021-07-09},
	journal = {Neurology},
	author = {Kukull, W. A. and Ganguli, M.},
	month = jun,
	year = {2012},
	pages = {1886--1891},
}

@techreport{esterling_necessity_2021,
	type = {preprint},
	title = {The {Necessity} of {Construct} and {External} {Validity} for {Generalized} {Causal} {Claims}},
	url = {https://osf.io/2s8w5},
	abstract = {By advancing causal identification, the credibility revolution has facilitated tremendous progress in political science. The ensuing emphasis on internal validity however has led to the neglect of construct and external validity. This article develops a framework we call causal specification. The framework formally demonstrates the joint necessity of internal, construct and external validity for causal generalization. Indeed, the lack of any of the three types of validity undermines the credibility revolution's own goal to understand causality deductively. Without construct, one cannot accurately label the cause or outcome. Without external, one cannot understand the conditions enabling the cause to have an effect. Our framework clarifies the assumptions necessary for each of the three. We show why internal validity should not have lexical priority, and advocate for equally valuing construct and external validity. Political scientists should use causal specification, not just causal identification, as a framework for the goal of causal generalization.},
	urldate = {2021-07-09},
	institution = {Open Science Framework},
	author = {Esterling, Kevin and Brady, David and Schwitzgebel, Eric},
	month = jan,
	year = {2021},
	doi = {10.31219/osf.io/2s8w5},
}

@incollection{frey_generalizability_2018,
	address = {2455 Teller Road, Thousand Oaks, California 91320},
	title = {Generalizability},
	isbn = {978-1-5063-2615-3 978-1-5063-2613-9},
	url = {https://methods.sagepub.com/reference/the-sage-encyclopedia-of-educational-research-measurement-and-evaluation/i9692.xml},
	urldate = {2021-07-09},
	booktitle = {The {SAGE} {Encyclopedia} of {Educational} {Research}, {Measurement}, and 					{Evaluation}},
	publisher = {SAGE Publications, Inc.},
	collaborator = {Frey, Bruce B.},
	year = {2018},
	doi = {10.4135/9781506326139.n284},
}

@article{bhopal_vexed_1997,
	title = {The vexed question of authorship: views of researchers in a {British} medical faculty},
	volume = {314},
	issn = {0959-8138, 1468-5833},
	shorttitle = {The vexed question of authorship},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.314.7086.1009},
	doi = {10.1136/bmj.314.7086.1009},
	language = {en},
	number = {7086},
	urldate = {2021-07-09},
	journal = {BMJ},
	author = {Bhopal, R. and Rankin, J. and McColl, E. and Thomas, L. and Kaner, E. and Stacy, R. and Pearson, P. and Vernon, B. and Rodgers, H.},
	month = apr,
	year = {1997},
	pages = {1009--1009},
}

@article{vuorre_curating_2018,
	title = {Curating {Research} {Assets}: {A} {Tutorial} on the {Git} {Version} {Control} {System}},
	volume = {1},
	issn = {2515-2459, 2515-2467},
	shorttitle = {Curating {Research} {Assets}},
	url = {http://journals.sagepub.com/doi/10.1177/2515245918754826},
	doi = {10.1177/2515245918754826},
	abstract = {Recent calls for improving reproducibility have increased attention to the ways in which researchers curate, share, and collaborate on their research assets. In this Tutorial, we explain how version control systems, such as the popular Git program, support these functions and then show how to use Git with a graphical interface in the RStudio program. This Tutorial is written for researchers with no previous experience using version control systems and covers both single-user and collaborative workflows. The online Supplemental Material provides information on advanced Git command-line functions. Git presents an elegant solution to specific challenges to curating, sharing, and collaborating on research assets and can be implemented in common workflows with little extra effort.},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Vuorre, Matti and Curley, James P.},
	month = jun,
	year = {2018},
	pages = {219--236},
}

@article{strathern_improving_1997,
	title = {‘{Improving} ratings’: audit in the {British} {University} system},
	volume = {5},
	doi = {https://doi.org/10.1002/(SICI)1234-981X(199707)5:3<305::AID-EURO184>3.0.CO;2-4},
	number = {3},
	journal = {European Review},
	author = {Strathern, Marilyn},
	year = {1997},
	pages = {305--321},
}

@misc{epskamp_statcheck_2018,
	title = {statcheck: {Extract} {Statistics} from {Articles} and {Recompute} p {Values}},
	copyright = {GPL-2},
	shorttitle = {statcheck},
	url = {https://CRAN.R-project.org/package=statcheck},
	urldate = {2021-07-09},
	author = {Epskamp, Sacha and Nuijten, Michele B.},
	month = may,
	year = {2018},
}

@article{kienzler_learning_2017,
	title = {Learning through inquiry: a {Global} {Health} {Hackathon}},
	volume = {22},
	issn = {1356-2517, 1470-1294},
	shorttitle = {Learning through inquiry},
	url = {https://www.tandfonline.com/doi/full/10.1080/13562517.2016.1221805},
	doi = {10.1080/13562517.2016.1221805},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Teaching in Higher Education},
	author = {Kienzler, Hanna and Fontanesi, Carolyn},
	month = feb,
	year = {2017},
	pages = {129--142},
}

@article{wendl_h-index_2007,
	title = {H-index: however ranked, citations need context},
	volume = {449},
	issn = {0028-0836, 1476-4687},
	shorttitle = {H-index},
	url = {http://www.nature.com/articles/449403b},
	doi = {10.1038/449403b},
	language = {en},
	number = {7161},
	urldate = {2021-07-09},
	journal = {Nature},
	author = {Wendl, Michael C.},
	month = sep,
	year = {2007},
	pages = {403--403},
}

@article{hirsch_index_2005,
	title = {An index to quantify an individual's scientific research output},
	volume = {102},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0507655102},
	doi = {10.1073/pnas.0507655102},
	language = {en},
	number = {46},
	urldate = {2021-07-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Hirsch, J. E.},
	month = nov,
	year = {2005},
	pages = {16569--16572},
}

@article{zwaan_making_2018,
	title = {Making replication mainstream},
	volume = {41},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X17001972/type/journal_article},
	doi = {10.1017/S0140525X17001972},
	abstract = {Abstract
            Many philosophers of science and methodologists have argued that the ability to repeat studies and obtain similar results is an essential component of science. A finding is elevated from single observation to scientific evidence when the procedures that were used to obtain it can be reproduced and the finding itself can be replicated. Recent replication attempts show that some high profile results – most notably in psychology, but in many other disciplines as well – cannot be replicated consistently. These replication attempts have generated a considerable amount of controversy, and the issue of whether direct replications have value has, in particular, proven to be contentious. However, much of this discussion has occurred in published commentaries and social media outlets, resulting in a fragmented discourse. To address the need for an integrative summary, we review various types of replication studies and then discuss the most commonly voiced concerns about direct replication. We provide detailed responses to these concerns and consider different statistical ways to evaluate replications. We conclude there are no theoretical or statistical obstacles to making direct replication a routine aspect of psychological science.},
	language = {en},
	urldate = {2021-07-09},
	journal = {Behavioral and Brain Sciences},
	author = {Zwaan, Rolf A. and Etz, Alexander and Lucas, Richard E. and Donnellan, M. Brent},
	year = {2018},
	pages = {e120},
}

@article{beller_theory_2017,
	title = {Theory, the {Final} {Frontier}? {A} {Corpus}-{Based} {Analysis} of the {Role} of {Theory} in {Psychological} {Articles}},
	volume = {8},
	issn = {1664-1078},
	shorttitle = {Theory, the {Final} {Frontier}?},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2017.00951/full},
	doi = {10.3389/fpsyg.2017.00951},
	urldate = {2021-07-09},
	journal = {Frontiers in Psychology},
	author = {Beller, Sieghard and Bender, Andrea},
	month = jun,
	year = {2017},
	pages = {951},
}

@article{glass_brief_2008,
	title = {A {Brief} {History} of the {Hypothesis}},
	volume = {134},
	issn = {00928674},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867408009537},
	doi = {10.1016/j.cell.2008.07.033},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Cell},
	author = {Glass, David J. and Hall, Ned},
	month = aug,
	year = {2008},
	pages = {378--381},
}

@book{popper_logic_2010,
	address = {London},
	edition = {Special Indian Edition},
	title = {The logic of scientific discovery},
	isbn = {978-0-415-27844-7},
	language = {eng},
	publisher = {Routledge},
	author = {Popper, Karl},
	year = {2010},
}

@book{longino_science_1990,
	address = {Princeton, N.J},
	title = {Science as social knowledge: values and objectivity in scientific inquiry},
	isbn = {978-0-691-07342-2 978-0-691-02051-8},
	shorttitle = {Science as social knowledge},
	publisher = {Princeton University Press},
	author = {Longino, Helen E.},
	year = {1990},
	keywords = {Methodology, Science, Women's studies},
}

@article{longino_taking_1992,
	title = {Taking {Gender} {Seriously} in {Philosophy} of {Science}},
	volume = {1992},
	issn = {0270-8647},
	url = {https://www.journals.uchicago.edu/doi/abs/10.1086/psaprocbienmeetp.1992.2.192847},
	doi = {10.1086/psaprocbienmeetp.1992.2.192847},
	abstract = {Using the author's social analysis of scientific knowledge, two ways of understanding the importance of gender to the philosophy of science are offered. Given a requirement of openness to multiple critical perspectives, the gender, race and class structure of a scientific community are an important ingredient of its epistemic reliability. Secondly, one can ask whether a gender sensitive scientific community might prefer certain evaluative criteria (or virtues of theory or practice) to others. Six such criteria (several of which are at odds with criteria accepted in mainstream science) are discussed. Their articulation prompts a series of philosophical questions, the answering of which would constitute one program (or more) of a gender sensitive philosophy of science.},
	number = {2},
	urldate = {2021-07-09},
	journal = {PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association},
	author = {Longino, Helen E.},
	month = jan,
	year = {1992},
	note = {Publisher: The University of Chicago Press},
	pages = {333--340},
}

@misc{eldermire_libguides_nodate,
	title = {{LibGuides}: {Measuring} your research impact: i10-{Index}},
	copyright = {Copyright Cornell University 2021},
	shorttitle = {{LibGuides}},
	url = {https://guides.library.cornell.edu/impact/author-impact-10},
	abstract = {This guide provides an introduction to the various metrics used to measure researcher and journal impact.},
	language = {en},
	urldate = {2021-07-09},
	author = {Eldermire, Erin},
}

@misc{noauthor_initial_nodate,
	title = {Initial revision of "git", the information manager from hell · git/git@e83c516},
	url = {https://github.com/git/git/commit/e83c5163316f89bfbde7d9ab23ca2e25604af290},
	abstract = {Git Source Code Mirror - This is a publish-only repository and all pull requests are ignored. Please follow Documentation/SubmittingPatches procedure for any of your improvements. - git/git},
	language = {en},
	urldate = {2021-07-09},
	journal = {GitHub},
}

@inproceedings{kalliamvakou_promises_2014,
	address = {Hyderabad, India},
	title = {The promises and perils of mining {GitHub}},
	isbn = {978-1-4503-2863-0},
	url = {http://dl.acm.org/citation.cfm?doid=2597073.2597074},
	doi = {10.1145/2597073.2597074},
	language = {en},
	urldate = {2021-07-09},
	booktitle = {Proceedings of the 11th {Working} {Conference} on {Mining} {Software} {Repositories} - {MSR} 2014},
	publisher = {ACM Press},
	author = {Kalliamvakou, Eirini and Gousios, Georgios and Blincoe, Kelly and Singer, Leif and German, Daniel M. and Damian, Daniela},
	year = {2014},
	pages = {92--101},
}

@misc{noauthor_how_nodate,
	title = {How to {Make} {Inclusivity} {More} {Than} {Just} an {Office} {Buzzword}},
	url = {https://insight.kellogg.northwestern.edu/article/how-to-make-inclusivity-more-than-just-an-office-buzzword},
	abstract = {Tips for turning good intentions into actions.},
	language = {en},
	urldate = {2021-07-09},
	journal = {Kellogg Insight},
}

@article{martinez-acosta_discussion_2018,
	title = {A {Discussion} of {Diversity} and {Inclusivity} at the {Institutional} {Level}: {The} {Need} for a {Strategic} {Plan}},
	volume = {16},
	issn = {1544-2896},
	shorttitle = {A {Discussion} of {Diversity} and {Inclusivity} at the {Institutional} {Level}},
	abstract = {A wider discussion is taking place nationally regarding how universities can make 'real' change in the old way of academic business. These changes include a hard look at the inclusive nature of the institutional environment as a whole. Lack of diversity is most noticeable within higher administrative levels of universities across the country. We have now reached a point where true reflection and assessment of inclusive practices on our campuses must be carried out so that we fully serve the needs of all of our students. In this breakout session participants will share best practices currently in place or strategic planning at your institutions, which not only promote diversity and inclusion in the classroom but describe strategies for institutional buy-in at all levels and provide examples of accountability measures that further promote diversity and inclusion at higher administrative levels.},
	language = {eng},
	number = {3},
	journal = {Journal of undergraduate neuroscience education: JUNE: a publication of FUN, Faculty for Undergraduate Neuroscience},
	author = {Martinez-Acosta, Veronica G. and Favero, Carlita B.},
	year = {2018},
	pmid = {30254540},
	pmcid = {PMC6153014},
	keywords = {diversity, inclusion, administration, best practices, implicit bias},
	pages = {A252--A260},
}

@article{koole_rewarding_2012,
	title = {Rewarding {Replications}: {A} {Sure} and {Simple} {Way} to {Improve} {Psychological} {Science}},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Rewarding {Replications}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691612462586},
	doi = {10.1177/1745691612462586},
	abstract = {Although replications are vital to scientific progress, psychologists rarely engage in systematic replication efforts. In this article, we consider psychologists’ narrative approach to scientific publications as an underlying reason for this neglect and propose an incentive structure for replications within psychology. First, researchers need accessible outlets for publishing replications. To accomplish this, psychology journals could publish replication reports in files that are electronically linked to reports of the original research. Second, replications should get cited. This can be achieved by cociting replications along with original research reports. Third, replications should become a valued collaborative effort. This can be realized by incorporating replications in teaching programs and by stimulating adversarial collaborations. The proposed incentive structure for replications can be developed in a relatively simple and cost-effective manner. By promoting replications, this incentive structure may greatly enhance the dependability of psychology’s knowledge base.},
	language = {en},
	number = {6},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Koole, Sander L. and Lakens, Daniël},
	month = nov,
	year = {2012},
	pages = {608--614},
}

@article{schonbrodt_training_2019,
	title = {Training students for the {Open} {Science} future},
	volume = {3},
	issn = {2397-3374},
	url = {http://www.nature.com/articles/s41562-019-0726-z},
	doi = {10.1038/s41562-019-0726-z},
	language = {en},
	number = {10},
	urldate = {2021-07-09},
	journal = {Nature Human Behaviour},
	author = {Schönbrodt, Felix},
	month = oct,
	year = {2019},
	pages = {1031--1031},
}

@article{schonbrodt_sequential_2017,
	title = {Sequential hypothesis testing with {Bayes} factors: {Efficiently} testing mean differences.},
	volume = {22},
	issn = {1939-1463, 1082-989X},
	shorttitle = {Sequential hypothesis testing with {Bayes} factors},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000061},
	doi = {10.1037/met0000061},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Psychological Methods},
	author = {Schönbrodt, Felix D. and Wagenmakers, Eric-Jan and Zehetleitner, Michael and Perugini, Marco},
	month = jun,
	year = {2017},
	pages = {322--339},
}

@article{smaldino_natural_2016,
	title = {The natural selection of bad science},
	volume = {3},
	issn = {2054-5703},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.160384},
	doi = {10.1098/rsos.160384},
	abstract = {Poor research design and data analysis encourage false-positive findings. Such poor methods persist despite perennial calls for improvement, suggesting that they result from something more than just misunderstanding. The persistence of poor methods results partly from incentives that favour them, leading to the natural selection of bad science. This dynamic requires no conscious strategizing—no deliberate cheating nor loafing—by scientists, only that publication is a principal factor for career advancement. Some normative methods of analysis have almost certainly been selected to further publication instead of discovery. In order to improve the culture of science, a shift must be made away from correcting misunderstandings and towards rewarding understanding. We support this argument with empirical evidence and computational modelling. We first present a 60-year meta-analysis of statistical power in the behavioural sciences and show that power has not improved despite repeated demonstrations of the necessity of increasing power. To demonstrate the logical consequences of structural incentives, we then present a dynamic model of scientific communities in which competing laboratories investigate novel or previously published hypotheses using culturally transmitted research methods. As in the real world, successful labs produce more ‘progeny,’ such that their methods are more often copied and their students are more likely to start labs of their own. Selection for high output leads to poorer methods and increasingly high false discovery rates. We additionally show that replication slows but does not stop the process of methodological deterioration. Improving the quality of research requires change at the institutional level.},
	language = {en},
	number = {9},
	urldate = {2021-07-09},
	journal = {Royal Society Open Science},
	author = {Smaldino, Paul E. and McElreath, Richard},
	month = sep,
	year = {2016},
	pages = {160384},
}

@article{nosek_preregistration_2018,
	title = {The preregistration revolution},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1708274114},
	doi = {10.1073/pnas.1708274114},
	abstract = {Progress in science relies in part on generating hypotheses with existing observations and testing hypotheses with new observations. This distinction between postdiction and prediction is appreciated conceptually but is not respected in practice. Mistaking generation of postdictions with testing of predictions reduces the credibility of research findings. However, ordinary biases in human reasoning, such as hindsight bias, make it hard to avoid this mistake. An effective solution is to define the research questions and analysis plan before observing the research outcomes—a process called preregistration. Preregistration distinguishes analyses and outcomes that result from predictions from those that result from postdictions. A variety of practical strategies are available to make the best possible use of preregistration in circumstances that fall short of the ideal application, such as when the data are preexisting. Services are now available for preregistration across all disciplines, facilitating a rapid increase in the practice. Widespread adoption of preregistration will increase distinctiveness between hypothesis generation and hypothesis testing and will improve the credibility of research findings.},
	language = {en},
	number = {11},
	urldate = {2021-07-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Nosek, Brian A. and Ebersole, Charles R. and DeHaven, Alexander C. and Mellor, David T.},
	month = mar,
	year = {2018},
	pages = {2600--2606},
}

@article{nosek_scientific_2012-1,
	title = {Scientific {Utopia}: {II}. {Restructuring} {Incentives} and {Practices} to {Promote} {Truth} {Over} {Publishability}},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Scientific {Utopia}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691612459058},
	doi = {10.1177/1745691612459058},
	abstract = {An academic scientist’s professional success depends on publishing. Publishing norms emphasize novel, positive results. As such, disciplinary incentives encourage design, analysis, and reporting decisions that elicit positive results and ignore negative results. Prior reports demonstrate how these incentives inflate the rate of false effects in published science. When incentives favor novelty over replication, false results persist in the literature unchallenged, reducing efficiency in knowledge accumulation. Previous suggestions to address this problem are unlikely to be effective. For example, a journal of negative results publishes otherwise unpublishable reports. This enshrines the low status of the journal and its content. The persistence of false findings can be meliorated with strategies that make the fundamental but abstract accuracy motive—getting it right—competitive with the more tangible and concrete incentive—getting it published. This article develops strategies for improving scientific practices and knowledge accumulation that account for ordinary human motivations and biases.},
	language = {en},
	number = {6},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Nosek, Brian A. and Spies, Jeffrey R. and Motyl, Matt},
	month = nov,
	year = {2012},
	pages = {615--631},
}

@article{gelman_difference_2006,
	title = {The {Difference} {Between} “{Significant}” and “{Not} {Significant}” is not {Itself} {Statistically} {Significant}},
	volume = {60},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1198/000313006X152649},
	doi = {10.1198/000313006X152649},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {The American Statistician},
	author = {Gelman, Andrew and Stern, Hal},
	month = nov,
	year = {2006},
	pages = {328--331},
}

@article{gelman_beyond_2014,
	title = {Beyond {Power} {Calculations}: {Assessing} {Type} {S} ({Sign}) and {Type} {M} ({Magnitude}) {Errors}},
	volume = {9},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Beyond {Power} {Calculations}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691614551642},
	doi = {10.1177/1745691614551642},
	abstract = {Statistical power analysis provides the conventional approach to assess error rates when designing a research study. However, power analysis is flawed in that a narrow emphasis on statistical significance is placed as the primary focus of study design. In noisy, small-sample settings, statistically significant results can often be misleading. To help researchers address this problem in the context of their own studies, we recommend design calculations in which (a) the probability of an estimate being in the wrong direction ( Type S [ sign] error) and (b) the factor by which the magnitude of an effect might be overestimated ( Type M [ magnitude] error or exaggeration ratio) are estimated. We illustrate with examples from recent published research and discuss the largest challenge in a design calculation: coming up with reasonable estimates of plausible effect sizes based on external information.},
	language = {en},
	number = {6},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Gelman, Andrew and Carlin, John},
	month = nov,
	year = {2014},
	pages = {641--651},
}

@article{nieuwenhuis_erroneous_2011,
	title = {Erroneous analyses of interactions in neuroscience: a problem of significance},
	volume = {14},
	issn = {1097-6256, 1546-1726},
	shorttitle = {Erroneous analyses of interactions in neuroscience},
	url = {http://www.nature.com/articles/nn.2886},
	doi = {10.1038/nn.2886},
	language = {en},
	number = {9},
	urldate = {2021-07-09},
	journal = {Nature Neuroscience},
	author = {Nieuwenhuis, Sander and Forstmann, Birte U and Wagenmakers, Eric-Jan},
	month = sep,
	year = {2011},
	pages = {1105--1107},
}

@article{morabia_interaction_1997,
	title = {Interaction {Fallacy}},
	volume = {50},
	issn = {08954356},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S089543569700053X},
	doi = {10.1016/S0895-4356(97)00053-X},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {Journal of Clinical Epidemiology},
	author = {Morabia, Alfredo and Have, Tom Ten and Landis, J.Richard},
	month = jul,
	year = {1997},
	pages = {809--812},
}

@book{campbell_experimental_2011,
	address = {Belomt, CA},
	title = {Experimental and quasi-experimental designs for research},
	isbn = {978-0-395-30787-8},
	language = {eng},
	publisher = {Wadsworth},
	author = {Campbell, Donald T. and Stanley, Julian C.},
	year = {2011},
}

@misc{noauthor_jabref_nodate,
	title = {{JabRef} - {Free} {Reference} {Manager} - {Stay} on top of your {Literature}},
	url = {https://www.jabref.org/},
	abstract = {JabRef is a free reference manager that helps you to discover, collect, organize and cite your scholarly literature and research in an efficient way.},
	urldate = {2021-07-09},
	journal = {JabRef},
}

@misc{noauthor_jamovi_nodate,
	title = {jamovi - {Stats}. {Open}. {Now}.},
	url = {https://www.jamovi.org/},
	urldate = {2021-07-09},
	journal = {jamovi},
}

@misc{noauthor_download_nodate,
	title = {Download {JASP}},
	url = {https://jasp-stats.org/download/},
	abstract = {Download JASP Entirely for free, no strings attached. Windows Windows 64bit Windows 32bit The pre-installed 64-bit or 32-bit version can be used if the msi fails. Please note that JASP0.14 is not available for Windows 7.   MacOS Catalina \&… Continue reading →},
	language = {en-US},
	urldate = {2021-07-09},
	journal = {JASP - Free and User-Friendly Statistical Software},
}

@article{brembs_deep_2013,
	title = {Deep impact: unintended consequences of journal rank},
	volume = {7},
	issn = {1662-5161},
	shorttitle = {Deep impact},
	url = {http://journal.frontiersin.org/article/10.3389/fnhum.2013.00291/abstract},
	doi = {10.3389/fnhum.2013.00291},
	urldate = {2021-07-09},
	journal = {Frontiers in Human Neuroscience},
	author = {Brembs, Björn and Button, Katherine and Munafò, Marcus},
	year = {2013},
}

@misc{curry_sick_2012,
	title = {Sick of {Impact} {Factors} {\textbar} {Reciprocal} {Space}},
	url = {http://occamstypewriter.org/scurry/2012/08/13/sick-of-impact-factors/},
	urldate = {2021-07-09},
	journal = {Reciprocal Space},
	author = {Curry, Stephen},
	month = aug,
	year = {2012},
}

@article{sharma_journal_2014,
	title = {Journal {Impact} {Factor}: {Its} {Use}, {Significance} and {Limitations}},
	volume = {13},
	issn = {1450-1147},
	shorttitle = {Journal {Impact} {Factor}},
	url = {http://www.wjnm.org/text.asp?2014/13/2/146/139151},
	doi = {10.4103/1450-1147.139151},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {World Journal of Nuclear Medicine},
	author = {Sharma, Mohit and Sarin, Anurag and Gupta, Priyanka and Sachdeva, Shobhit and Desai, AnkurV},
	year = {2014},
	pages = {146},
}

@article{rossner_show_2007,
	title = {Show me the data},
	volume = {179},
	issn = {1540-8140, 0021-9525},
	url = {https://rupress.org/jcb/article/179/6/1091/54138/Show-me-the-data},
	doi = {10.1083/jcb.200711140},
	language = {en},
	number = {6},
	urldate = {2021-07-09},
	journal = {Journal of Cell Biology},
	author = {Rossner, Mike and Van Epps, Heather and Hill, Emma},
	month = dec,
	year = {2007},
	pages = {1091--1092},
}

@misc{bids_modality_2020,
	title = {Modality agnostic files - {Brain} {Imaging} {Data} {Structure} v1.6.0},
	url = {https://bids-specification.readthedocs.io/en/stable/03-modality-agnostic-files.html},
	urldate = {2021-07-09},
	journal = {Brain Imaging Data Structure},
	author = {{BIDS}},
	year = {2020},
}

@book{brule_knowledge_1989,
	address = {New York},
	series = {Artificial intelligence series},
	title = {Knowledge acquisition},
	isbn = {978-0-07-008600-5},
	publisher = {McGraw-Hill},
	author = {Brulé, James F. and Blount, Alexander},
	year = {1989},
	keywords = {Expert systems (Computer science), Knowledge acquisition (Expert systems)},
}

@article{hogg_data_2010,
	title = {Data analysis recipes: {Fitting} a model to data},
	shorttitle = {Data analysis recipes},
	url = {http://arxiv.org/abs/1008.4686},
	abstract = {We go through the many considerations involved in fitting a model to data, using as an example the fit of a straight line to a set of points in a two-dimensional plane. Standard weighted least-squares fitting is only appropriate when there is a dimension along which the data points have negligible uncertainties, and another along which all the uncertainties can be described by Gaussians of known variance; these conditions are rarely met in practice. We consider cases of general, heterogeneous, and arbitrarily covariant two-dimensional uncertainties, and situations in which there are bad data (large outliers), unknown uncertainties, and unknown but expected intrinsic scatter in the linear relationship being fit. Above all we emphasize the importance of having a "generative model" for the data, even an approximate one. Once there is a generative model, the subsequent fitting is non-arbitrary because the model permits direct computation of the likelihood of the parameters or the posterior probability distribution. Construction of a posterior probability distribution is indispensible if there are "nuisance parameters" to marginalize away.},
	urldate = {2021-07-09},
	journal = {arXiv:1008.4686 [astro-ph, physics:physics]},
	author = {Hogg, David W. and Bovy, Jo and Lang, Dustin},
	month = aug,
	year = {2010},
	note = {arXiv: 1008.4686},
	keywords = {Physics - Data Analysis, Statistics and Probability, Astrophysics - Instrumentation and Methods for Astrophysics},
}

@article{van_de_schoot_bayesian_2021,
	title = {Bayesian statistics and modelling},
	volume = {1},
	issn = {2662-8449},
	url = {http://www.nature.com/articles/s43586-020-00001-2},
	doi = {10.1038/s43586-020-00001-2},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Nature Reviews Methods Primers},
	author = {van de Schoot, Rens and Depaoli, Sarah and King, Ruth and Kramer, Bianca and Märtens, Kaspar and Tadesse, Mahlet G. and Vannucci, Marina and Gelman, Andrew and Veen, Duco and Willemsen, Joukje and Yau, Christopher},
	month = dec,
	year = {2021},
	pages = {1},
}

@misc{huber_stata_2016,
	title = {The {Stata} {Blog} » {Introduction} to {Bayesian} statistics, part 1: {The} basic concepts},
	url = {https://blog.stata.com/2016/11/01/introduction-to-bayesian-statistics-part-1-the-basic-concepts/},
	language = {English},
	urldate = {2021-07-09},
	journal = {The Stata Blog},
	author = {Huber, Chuck},
	month = nov,
	year = {2016},
}

@techreport{huelin_whats_2015,
	title = {What's in a {Name}? {Systematic} and {Non}-{Systematic} {Literature} {Reviews}, and {Why} the {Distinction} {Matters} - {Evidera}},
	url = {https://www.evidera.com/resource/whats-in-a-name-systematic-and-non-systematic-literature-reviews-and-why-the-distinction-matters/},
	urldate = {2021-07-09},
	author = {Huelin, Rachel and Iheanacho, Ike and Payne, Krista and Sandman, Karen},
	year = {2015},
	pages = {34--37},
}

@article{munn_systematic_2018,
	title = {Systematic review or scoping review? {Guidance} for authors when choosing between a systematic or scoping review approach},
	volume = {18},
	issn = {1471-2288},
	shorttitle = {Systematic review or scoping review?},
	url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-018-0611-x},
	doi = {10.1186/s12874-018-0611-x},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {BMC Medical Research Methodology},
	author = {Munn, Zachary and Peters, Micah D. J. and Stern, Cindy and Tufanaru, Catalin and McArthur, Alexa and Aromataris, Edoardo},
	month = dec,
	year = {2018},
	pages = {143},
}

@article{pautasso_ten_2013,
	title = {Ten {Simple} {Rules} for {Writing} a {Literature} {Review}},
	volume = {9},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1003149},
	doi = {10.1371/journal.pcbi.1003149},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {PLoS Computational Biology},
	author = {Pautasso, Marco},
	editor = {Bourne, Philip E.},
	month = jul,
	year = {2013},
	pages = {e1003149},
}

@techreport{breznau_how_2021,
	type = {preprint},
	title = {How {Many} {Replicators} {Does} {It} {Take} to {Achieve} {Reliability}? {Investigating} {Researcher} {Variability} in a {Crowdsourced} {Replication}},
	shorttitle = {How {Many} {Replicators} {Does} {It} {Take} to {Achieve} {Reliability}?},
	url = {https://osf.io/j7qta},
	abstract = {The paper reports findings from a crowdsourced replication. Eighty-four replicator teams attempted to verify results reported in an original study by running the same models with the same data. The replication involved an experimental condition. A “transparent” group received the original study and code, and an “opaque” group received the same underlying study but with only a methods section and description of the regression coefficients without size or significance, and no code. The transparent group mostly verified the original study (95.5\%), while the opaque group had less success (89.4\%). Qualitative investigation of the replicators’ workflows reveals many causes of non-verification. Two categories of these causes are hypothesized, routine and non-routine. After correcting non-routine errors in the research process to ensure that the results reflect a level of quality that should be present in ‘real-world’ research, the rate of verification was 96.1\% in the transparent group and 92.4\% in the opaque group. Two conclusions follow: (1) Although high, the verification rate suggests that it would take a minimum of three replicators per study to achieve replication reliability of at least 95\% confidence assuming ecological validity in this controlled setting, and (2) like any type of scientific research, replication is prone to errors that derive from routine and undeliberate actions in the research process. The latter suggests that idiosyncratic researcher variability might provide a key to understanding part of the “reliability crisis” in social and behavioral science and is a reminder of the importance of transparent and well documented workflows.},
	urldate = {2021-07-09},
	institution = {SocArXiv},
	author = {Breznau, Nate and Rinke, Eike Mark and Wuttke, Alexander and Nguyen, Hung Hoang Viet and Adem, Muna and Adriaans, Jule and Akdeniz, Esra and Alvarez-Benjumea, Amalia and Andersen, Henrik Kenneth and Auer, Daniel and Azevedo, Flavio and Bahnsen, Oke and Bai, Ling and Balzer, Dave and Bauer, Gerrit and Bauer, Paul and Baumann, Markus and Baute, Sharon and Benoit, Verena and Bernauer, Julian and Berning, Carl and Berthold, Anna and Bethke, Felix S. and Biegert, Thomas and Blinzler, Katharina and Blumenberg, Johannes and Bobzien, Licia and Bohman, Andrea and Bol, Thijs and Bostic, Amie and Brzozowska, Zuzanna and Burgdorf, Katharina and Burger, Kaspar and Busch, Kathrin and Castillo, Juan Carlos and Chan, Nathan and Christmann, Pablo and Connelly, Roxanne and Czymara, Christian S. and Damian, Elena and de Rooij, Eline and Ecker, Alejandro and Edelmann, Achim and Eder, Christina and Eger, Maureen A. and Ellerbrock, Simon and Forke, Anna and Forster, Andrea Gabriele and Freire, Danilo and Gaasendam, Chris and Gavras, Konstantin and Gayle, Vernon and Gessler, Theresa and Gnambs, Timo and Godefroidt, Amélie and Grömping, Max and Groß, Martin and Gruber, Stefan and Gummer, Tobias and Hadjar, Andreas and Halbherr, Verena and Heisig, Jan Paul and Hellmeier, Sebastian and Heyne, Stefanie and Hirsch, Magdalena and Hjerm, Mikael and Hochman, Oshrat and Höffler, Jan H. and Hövermann, Andreas and Hunger, Sophia and Hunkler, Christian and Huth, Nora and Ignacz, Zsofia and Israel, Sabine and Jacobs, Laura and Jacobsen, Jannes and Jaeger, Bastian and Jungkunz, Sebastian and Jungmann, Nils and Kanjana, Jennifer and Kauff, Mathias and Khan, Salman and Khatua, Sayak and Kleinert, Manuel and Klinger, Julia and Kolb, Jan-Philipp and Kołczyńska, Marta and Kuk, John Seungmin and Kunißen, Katharina and Sinatra, Dafina Kurti and Greinert, Alexander and Lee, Robin C. and Lersch, Philipp M. and Liu, David and Löbel, Lea-Maria and Lutscher, Philipp and Mader, Matthias and Madia, Joan Eliel and Malancu, Natalia and Maldonado, Luis and Marahrens, Helge and Martin, Nicole and Martinez, Paul and Mayerl, Jochen and Mayorga, OSCAR Jose and McDonnell, Robert Myles and McManus, Patricia and Wagner, Kyle and Meeusen, Cecil and Meierrieks, Daniel and Mellon, Jonathan and Merhout, Friedolin and Merk, Samuel and Meyer, Daniel and Micheli, Leticia and Mijs, Jonathan J.B. and Moya, Cristóbal and Neunhoeffer, Marcel and Nüst, Daniel and Nygård, Olav and Ochsenfeld, Fabian and Otte, Gunnar and Pechenkina, Anna and Pickup, Mark and Prosser, Christopher and Raes, Louis and Ralston, Kevin and Ramos, Miguel and Reichert, Frank and Roets, Arne and Rogers, Jonathan and Ropers, Guido and Samuel, Robin and Sand, Gergor and Petrarca, Constanza Sanhueza and Schachter, Ariela and Schaeffer, Merlin and Schieferdecker, David and Schlueter, Elmar and Schmidt, Katja and Schmidt, Regine and Schmidt-Catran, Alexander and Schmiedeberg, Claudia and Schneider, Jürgen and Schoonvelde, Martijn and Schulte-Cloos, Julia and Schumann, Sandy and Schunck, Reinhard and Schupp, Juergen and Seuring, Julian and Silber, Henning and Sleegers, Willem W. A. and Sonntag, Nico and Staudt, Alexander and Steiber, Nadia and Steiner, Nils and Sternberg, Sebastian and Stiers, Dieter and Stojmenovska, Dragana and Storz, Nora and Striessnig, Erich and Stroppe, Anne-Kathrin and Suchow, Jordan and Teltemann, Janna and Tibajev, Andrey and Tung, Brian B. and Vagni, Giacomo and Van Assche, Jasper and van der Linden, Meta and van der Noll, Jolanda and Van Hootegem, Arno and Vogtenhuber, Stefan and Voicu, Bogdan and Wagemans, Fieke and Wehl, Nadja and Werner, Hannah and Wiernik, Brenton M. and Winter, Fabian and Wolf, Christof and Wu, Cary and Yamada, Yuki and Zakula, Björn and Zhang, Nan and Ziller, Conrad and Zins, Stefan and Żółtak, Tomasz},
	month = may,
	year = {2021},
	doi = {10.31235/osf.io/j7qta},
}

@article{crenshaw_demarginalizing_1989,
	title = {Demarginalizing the {Intersection} of {Race} and {Sex}: {A} {Black} {Feminist} {Critique} of {Antidiscrimination} {Doctrine}, {Feminist} {Theory} and {Antiracist} {Politics}},
	volume = {1989},
	issn = {0892-5593},
	shorttitle = {Demarginalizing the {Intersection} of {Race} and {Sex}},
	url = {https://chicagounbound.uchicago.edu/uclf/vol1989/iss1/8},
	abstract = {By Kimberle Crenshaw, Published on 12/07/15},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {University of Chicago Legal Forum},
	author = {Crenshaw, Kimberle},
	year = {1989},
	pages = {8},
}

@techreport{masur_understanding_2020,
	type = {preprint},
	title = {Understanding the {Effects} of {Analytical} {Choices} on {Finding} the {Privacy} {Paradox}: {A} {Specification} {Curve} {Analysis} of {Large}-{Scale} {Survey} {Data}},
	url = {https://osf.io/m72gb/},
	abstract = {The privacy paradox suggests that privacy concerns do not relate to privacy-related behavior. Although it has inspired numerous studies, findings remain inconclusive. Some of the inconsistencies in published findings may be explained by a strong heterogeneity in the conceptual and analytical choices that researchers implement when investigating the privacy paradox. Based on representative survey data of the 27 EU states (2011: n = 8,962; 2015: n = 10,526; 2019: n = 11,428), I investigated the effect of conceptual and analytical decisions on ‘finding’ the privacy paradox. Specification curve analyses revealed that the magnitude and statistical significance of the relationship between privacy concerns and information disclosure is contingent on the operationalization of the independent variable, the inclusion of covariates, and the age of the studied population. The relationship between online privacy concerns and using social media privacy settings, in contrast, was less influenced by analytical decisions and overall inconsistent with the privacy paradox. Yet, the relationship was stronger in younger people and increased over time. The findings call for more transparency in analyzing research data. Evaluating the implications of analytical choices will help to establish best practices and advance cumulative knowledge creation in privacy research.},
	institution = {Open Science Framework},
	author = {Masur, P.K.},
	month = jan,
	year = {2020},
}

@techreport{geyer_maximum_2003,
	type = {preprint},
	title = {Maximum {Likelihood} in {R}},
	institution = {Open Science Framework},
	author = {Geyer, J., Charles},
	month = sep,
	year = {2003},
	pages = {1--9},
}

@techreport{geyer_stat_2007,
	type = {preprint},
	title = {Stat 5102 {Notes}: {Maximum} {Likelihood}},
	institution = {Open Science Framework},
	author = {Geyer, J., Charles},
	month = feb,
	year = {2007},
	pages = {1--8},
}

@article{goodman_what_2016,
	title = {What does research reproducibility mean?},
	volume = {8},
	issn = {1946-6234, 1946-6242},
	url = {https://stm.sciencemag.org/lookup/doi/10.1126/scitranslmed.aaf5027},
	doi = {10.1126/scitranslmed.aaf5027},
	language = {en},
	number = {341},
	urldate = {2021-07-09},
	journal = {Science Translational Medicine},
	author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
	month = jun,
	year = {2016},
	pages = {341ps12--341ps12},
}

@article{bouvy_all-male_2019,
	title = {All-{Male} {Panels} and {Gender} {Diversity} of {Issue} {Panels} and {Plenary} {Sessions} at {ISPOR} {Europe}},
	volume = {3},
	issn = {2509-4262, 2509-4254},
	url = {http://link.springer.com/10.1007/s41669-019-0153-0},
	doi = {10.1007/s41669-019-0153-0},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {PharmacoEconomics - Open},
	author = {Bouvy, Jacoline C. and Mujoomdar, Michelle},
	month = sep,
	year = {2019},
	pages = {419--422},
}

@article{nittrouer_gender_2018,
	title = {Gender disparities in colloquium speakers at top universities},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1708414115},
	doi = {10.1073/pnas.1708414115},
	abstract = {Colloquium talks at prestigious universities both create and reflect academic researchers’ reputations. Gender disparities in colloquium talks can arise through a variety of mechanisms. The current study examines gender differences in colloquium speakers at 50 prestigious US colleges and universities in 2013–2014. Using archival data, we analyzed 3,652 talks in six academic disciplines. Men were more likely than women to be colloquium speakers even after controlling for the gender and rank of the available speakers. Eliminating alternative explanations (e.g., women declining invitations more often than men), our follow-up data revealed that female and male faculty at top universities reported no differences in the extent to which they (
              i
              ) valued and (
              ii
              ) turned down speaking engagements. Additional data revealed that the presence of women as colloquium chairs (and potentially on colloquium committees) increased the likelihood of women appearing as colloquium speakers. Our data suggest that those who invite and schedule speakers serve as gender gatekeepers with the power to create or reduce gender differences in academic reputations.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Nittrouer, Christine L. and Hebl, Michelle R. and Ashburn-Nardo, Leslie and Trump-Steele, Rachel C. E. and Lane, David M. and Valian, Virginia},
	month = jan,
	year = {2018},
	pages = {104--108},
}

@article{goodman_gender_2019,
	title = {Gender {Representation} and {Strategies} for {Panel} {Diversity}: {Lessons} from the {APSA} {Annual} {Meeting}},
	volume = {52},
	issn = {1049-0965, 1537-5935},
	shorttitle = {Gender {Representation} and {Strategies} for {Panel} {Diversity}},
	url = {https://www.cambridge.org/core/product/identifier/S1049096519000908/type/journal_article},
	doi = {10.1017/S1049096519000908},
	abstract = {ABSTRACT
            Gender representation is a pervasive problem in political science. We draw on evidence from the 2017 and 2018 American Political Science Association (APSA) Annual Meeting programs to discuss diversity and representation in large political science disciplinary conferences. APSA program divisions differ substantially in their gender representation: although some are representative of their organized-section membership, others are not, and some sections are particularly likely to feature “manels.” We present representation data by organized section, with discussions of what representation looks like and identifying different types of representation goals. We conclude by offering guidelines for increasing gender representation, for both future submitters and program chairs.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {PS: Political Science \& Politics},
	author = {Goodman, Sara Wallace and Pepinsky, Thomas B.},
	month = oct,
	year = {2019},
	pages = {669--676},
}

@misc{guenther_whats_2020,
	title = {What’s wrong with 'manels' and what can we do about them},
	url = {http://theconversation.com/whats-wrong-with-manels-and-what-can-we-do-about-them-148068},
	abstract = {Homogenous, male-only panels remain prevalent, despite growing numbers of women experts in multiple fields.},
	language = {en},
	urldate = {2021-07-09},
	journal = {The Conversation},
	author = {Guenther, Elisabeth Anna and Rodriguez, Jenny K.},
	month = oct,
	year = {2020},
}

@article{cronin_hyperauthorship_2001,
	title = {Hyperauthorship: {A} postmodern perversion or evidence of a structural shift in scholarly communication practices?},
	volume = {52},
	issn = {1532-2882, 1532-2890},
	shorttitle = {Hyperauthorship},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/asi.1097},
	doi = {10.1002/asi.1097},
	language = {en},
	number = {7},
	urldate = {2021-07-09},
	journal = {Journal of the American Society for Information Science and Technology},
	author = {Cronin, Blaise},
	year = {2001},
	pages = {558--569},
}

@article{moshontz_guide_2021,
	title = {A guide for many authors: {Writing} manuscripts in large collaborations},
	volume = {15},
	issn = {1751-9004, 1751-9004},
	shorttitle = {A guide for many authors},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/spc3.12590},
	doi = {10.1111/spc3.12590},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Social and Personality Psychology Compass},
	author = {Moshontz, Hannah and Ebersole, Charles R. and Weston, Sara J. and Klein, Richard A.},
	month = apr,
	year = {2021},
}

@article{ebersole_many_2016,
	title = {Many {Labs} 3: {Evaluating} participant pool quality across the academic semester via replication},
	volume = {67},
	issn = {00221031},
	shorttitle = {Many {Labs} 3},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022103115300123},
	doi = {10.1016/j.jesp.2015.10.012},
	language = {en},
	urldate = {2021-07-09},
	journal = {Journal of Experimental Social Psychology},
	author = {Ebersole, Charles R. and Atherton, Olivia E. and Belanger, Aimee L. and Skulborstad, Hayley M. and Allen, Jill M. and Banks, Jonathan B. and Baranski, Erica and Bernstein, Michael J. and Bonfiglio, Diane B.V. and Boucher, Leanne and Brown, Elizabeth R. and Budiman, Nancy I. and Cairo, Athena H. and Capaldi, Colin A. and Chartier, Christopher R. and Chung, Joanne M. and Cicero, David C. and Coleman, Jennifer A. and Conway, John G. and Davis, William E. and Devos, Thierry and Fletcher, Melody M. and German, Komi and Grahe, Jon E. and Hermann, Anthony D. and Hicks, Joshua A. and Honeycutt, Nathan and Humphrey, Brandon and Janus, Matthew and Johnson, David J. and Joy-Gaba, Jennifer A. and Juzeler, Hannah and Keres, Ashley and Kinney, Diana and Kirshenbaum, Jacqeline and Klein, Richard A. and Lucas, Richard E. and Lustgraaf, Christopher J.N. and Martin, Daniel and Menon, Madhavi and Metzger, Mitchell and Moloney, Jaclyn M. and Morse, Patrick J. and Prislin, Radmila and Razza, Timothy and Re, Daniel E. and Rule, Nicholas O. and Sacco, Donald F. and Sauerberger, Kyle and Shrider, Emily and Shultz, Megan and Siemsen, Courtney and Sobocko, Karin and Weylin Sternglanz, R. and Summerville, Amy and Tskhay, Konstantin O. and van Allen, Zack and Vaughn, Leigh Ann and Walker, Ryan J. and Weinberg, Ashley and Wilson, John Paul and Wirth, James H. and Wortman, Jessica and Nosek, Brian A.},
	month = nov,
	year = {2016},
	pages = {68--82},
}

@article{wuchty_increasing_2007,
	title = {The {Increasing} {Dominance} of {Teams} in {Production} of {Knowledge}},
	volume = {316},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.1136099},
	doi = {10.1126/science.1136099},
	language = {en},
	number = {5827},
	urldate = {2021-07-09},
	journal = {Science},
	author = {Wuchty, S. and Jones, B. F. and Uzzi, B.},
	month = may,
	year = {2007},
	pages = {1036--1039},
}

@article{frank_collaborative_2017,
	title = {A {Collaborative} {Approach} to {Infant} {Research}: {Promoting} {Reproducibility}, {Best} {Practices}, and {Theory}-{Building}},
	volume = {22},
	issn = {15250008},
	shorttitle = {A {Collaborative} {Approach} to {Infant} {Research}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/infa.12182},
	doi = {10.1111/infa.12182},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Infancy},
	author = {Frank, Michael C. and Bergelson, Elika and Bergmann, Christina and Cristia, Alejandrina and Floccia, Caroline and Gervain, Judit and Hamlin, J. Kiley and Hannon, Erin E. and Kline, Melissa and Levelt, Claartje and Lew-Williams, Casey and Nazzi, Thierry and Panneton, Robin and Rabagliati, Hugh and Soderstrom, Melanie and Sullivan, Jessica and Waxman, Sandra and Yurovsky, Daniel},
	month = jul,
	year = {2017},
	pages = {421--435},
}

@article{baturay_overview_2015,
	title = {An {Overview} of the {World} of {MOOCs}},
	volume = {174},
	issn = {18770428},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877042815007363},
	doi = {10.1016/j.sbspro.2015.01.685},
	language = {en},
	urldate = {2021-07-09},
	journal = {Procedia - Social and Behavioral Sciences},
	author = {Baturay, Meltem Huri},
	month = feb,
	year = {2015},
	pages = {427--433},
}

@techreport{pavlov_eegmanylabs_2020,
	type = {preprint},
	title = {\#{EEGManyLabs}: {Investigating} the {Replicability} of {Influential} {EEG} {Experiments}},
	shorttitle = {\#{EEGManyLabs}},
	url = {https://osf.io/528nr},
	abstract = {There is growing awareness across the neuroscience community that the replicability of findings on the relationship between brain activity and cognitive phenomena can be improved by conducting studies with high statistical power that adhere to well-defined and standardized analysis pipelines. Inspired by efforts from the psychological sciences, and with the desire to examine some of the foundational findings using electroencephalography (EEG), we have launched \#EEGManyLabs, a large-scale international collaborative replication effort. Since its discovery in the early 20th century, EEG has had a profound influence on our understanding of human cognition, but there is limited evidence on the replicability of some of the most highly cited discoveries. After a systematic search and selection process, we have identified 27 of the most influential and continually cited studies in the field. We plan to directly test the replicability of key findings from 20 of these studies in teams of at least three independent laboratories. The design and protocol of each replication effort will be submitted as a Registered Report and peer-reviewed prior to data collection. Prediction markets, open to all EEG researchers, will be used as a forecasting tool to examine which findings the community expects to replicate. This project will update our confidence in some of the most influential EEG findings and generate a large open access database that can be used to inform future research practices. Finally, through this international effort, we hope to create a cultural shift towards inclusive, high-powered multi-laboratory collaborations.},
	urldate = {2021-07-09},
	institution = {PsyArXiv},
	author = {Pavlov, Yuri G. and Adamian, Nika and Appelhoff, Stefan and Arvaneh, Mahnaz and Benwell, Christopher and Beste, Christian and Bland, Amy and Bradford, Daniel E. and Bublatzky, Florian and Busch, Niko and Clayson, Peter E and Cruse, Damian and Czeszumski, Artur and Dreber, Anna and Dumas, Guillaume and Ehinger, Benedikt Valerian and Ganis, Giorgio and He, Xun and Hinojosa, José Antonio and Huber-Huber, Christoph and Inzlicht, Michael and Jack, Bradley N and Johannesson, Magnus and Jones, Rhiannon and Kalenkovich, Evgenii and Kaltwasser, Laura and Karimi-Rouzbahani, Hamid and Keil, Andreas and König, Peter and Kouara, Layla and Kulke, Louisa and Ladouceur, Cecile and Langer, Nicolas and Liesefeld, Heinrich René and Luque, David and MacNamara, Annmarie and Mudrik, Liad and Muthuraman, Muthuraman and Neal, Lauren Browning and Nilsonne, Gustav and Niso, Guiomar and Ocklenburg, Sebastian and Oostenveld, Robert and Pernet, Cyril R and Pourtois, Gilles and Ruzzoli, Manuela and Sass, Sarah and Schaefer, Alexandre and Senderecka, Magdalena and Snyder, Joel S. and Tamnes, Christian K. and Tognoli, Emmanuelle and van Vugt, Marieke K. and Verona, Edelyn and Vloeberghs, Robin and Welke, Dominik and Wessel, Jan and Zakharov, Ilya and Mushtaq, Faisal},
	month = nov,
	year = {2020},
	doi = {10.31234/osf.io/528nr},
}

@misc{noauthor_homepage_nodate,
	title = {Homepage},
	url = {https://opensciencemooc.eu/},
	language = {en},
	urldate = {2021-07-09},
	journal = {Open Science MOOC},
}

@article{bornmann_does_2019,
	title = {Does the \$h\_{\textbackslash}alpha\$ index reinforce the {Matthew} effect in science? {Agent}-based simulations using {Stata} and {R}},
	shorttitle = {Does the \$h\_{\textbackslash}alpha\$ index reinforce the {Matthew} effect in science?},
	url = {http://arxiv.org/abs/1905.11052},
	abstract = {Recently, Hirsch (2019a) proposed a new variant of the h index called the \$h\_{\textbackslash}alpha\$ index. He formulated as follows: "we define the \$h\_{\textbackslash}alpha\$ index of a scientist as the number of papers in the h-core of the scientist (i.e. the set of papers that contribute to the h-index of the scientist) where this scientist is the \${\textbackslash}alpha\$-author" (p. 673). The \$h\_{\textbackslash}alpha\$ index was criticized by Leydesdorff, Bornmann, and Opthof (2019). One of their most important points is that the index reinforces the Matthew effect in science. We address this point in the current study using a recently developed Stata command (h\_index) and R package (hindex), which can be used to simulate h index and \$h\_{\textbackslash}alpha\$index applications in research evaluation. The user can investigate under which conditions \$h\_{\textbackslash}alpha\$ reinforces the Matthew effect. The results of our study confirm what Leydesdorff et al. (2019) expected: the \$h\_{\textbackslash}alpha\$ index reinforces the Matthew effect. This effect can be intensified if strategic behavior of the publishing scientists and cumulative advantage effects are additionally considered in the simulation.},
	urldate = {2021-07-09},
	journal = {arXiv:1905.11052 [physics]},
	author = {Bornmann, Lutz and Ganser, Christian and Tekles, Alexander and Leydesdorff, Loet},
	month = may,
	year = {2019},
	note = {arXiv: 1905.11052},
	keywords = {Physics - Physics and Society, Computer Science - Digital Libraries},
}

@article{bol_matthew_2018,
	title = {The {Matthew} effect in science funding},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1719557115},
	doi = {10.1073/pnas.1719557115},
	abstract = {A classic thesis is that scientific achievement exhibits a “Matthew effect”: Scientists who have previously been successful are more likely to succeed again, producing increasing distinction. We investigate to what extent the Matthew effect drives the allocation of research funds. To this end, we assembled a dataset containing all review scores and funding decisions of grant proposals submitted by recent PhDs in a €2 billion granting program. Analyses of review scores reveal that early funding success introduces a growing rift, with winners just above the funding threshold accumulating more than twice as much research funding (€180,000) during the following eight years as nonwinners just below it. We find no evidence that winners’ improved funding chances in subsequent competitions are due to achievements enabled by the preceding grant, which suggests that early funding itself is an asset for acquiring later funding. Surprisingly, however, the emergent funding gap is partly created by applicants, who, after failing to win one grant, apply for another grant less often.},
	language = {en},
	number = {19},
	urldate = {2021-07-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Bol, Thijs and de Vaan, Mathijs and van de Rijt, Arnout},
	month = may,
	year = {2018},
	pages = {4887--4890},
}

@book{borenstein_introduction_2009,
	address = {Chichester, U.K},
	title = {Introduction to meta-analysis},
	isbn = {978-0-470-05724-7},
	abstract = {This text provides a concise and clearly presented discussion of all the elements in a meta-analysis. It is illustrated with worked examples throughout, with visual explanations, using screenshots from Excel spreadsheets and computer programs such as Comprehensive Meta-Analysis (CMA) or Strata},
	publisher = {John Wiley \& Sons},
	editor = {Borenstein, Michael},
	year = {2009},
	note = {OCLC: ocn263294996},
	keywords = {Meta-analysis, Meta-Analysis as Topic},
}

@techreport{yeung_experimental_nodate,
	type = {preprint},
	title = {Experimental {Studies} {Meta}-{Analysis}  {Registered} {Report} template: {Main} manuscript},
	url = {https://docs.google.com/document/d/1z3QBDYr86S9FxGjptZP94jJnZeeN4aQaBQP3VVT89Ec/edit#},
	institution = {Hong Kong University},
	author = {Yeung, Siu Kit and Feldman, Gilad and Fillon, Adrien and Protzko, John and Elsherif, Mahmoud M. and Xiao, Qinyu and Pickering, Jade},
}

@misc{noauthor_datacite_nodate,
	title = {Datacite {Metadata} {Schema}},
	url = {https://schema.datacite.org/},
	urldate = {2021-07-09},
	journal = {DataCite Schema},
}

@techreport{peterson_metascience_2020,
	type = {preprint},
	title = {Metascience as a scientific social movement},
	url = {https://osf.io/4dsqa},
	abstract = {Emerging out of the “reproducibility crisis” in science, metascientists have become central players in debates about research integrity, scholarly communication, and science policy. The goal of this article is to introduce metascience to STS scholars, detail the scientific ideology that is apparent in its articles, strategy statements, and research projects, and discuss its institutional and intellectual future. Put simply, metascience is a scientific social movement that seeks to use the tools of science- especially, quantification and experimentation- to diagnose problems in research practice and improve efficiency. It draws together data scientists, experimental and statistical methodologists, and open science activists into a project with both intellectual and policy dimensions. Metascientists have been remarkably successful at winning grants, motivating news coverage, and changing policies at science agencies, journals, and universities. Moreover, metascience represents the apotheosis of several trends in research practice, scientific communication, and science governance including increased attention to methodological and statistical criticism of scientific practice, the promotion of “open science” by science funders and journals, the growing importance of both preprint and data repositories for scientific communication, and the new prominence of data scientists as research makes a turn toward Big Science.},
	urldate = {2021-07-09},
	institution = {SocArXiv},
	author = {Peterson, David and Panofsky, Aaron},
	month = aug,
	year = {2020},
	doi = {10.31235/osf.io/4dsqa},
}

@article{ioannidis_why_2005,
	title = {Why {Most} {Published} {Research} {Findings} {Are} {False}},
	volume = {2},
	issn = {1549-1676},
	url = {https://dx.plos.org/10.1371/journal.pmed.0020124},
	doi = {10.1371/journal.pmed.0020124},
	language = {en},
	number = {8},
	urldate = {2021-07-09},
	journal = {PLoS Medicine},
	author = {Ioannidis, John P. A.},
	month = aug,
	year = {2005},
	pages = {e124},
}

@article{ioannidis_meta-research_2015,
	title = {Meta-research: {Evaluation} and {Improvement} of {Research} {Methods} and {Practices}},
	volume = {13},
	issn = {1545-7885},
	shorttitle = {Meta-research},
	url = {https://dx.plos.org/10.1371/journal.pbio.1002264},
	doi = {10.1371/journal.pbio.1002264},
	language = {en},
	number = {10},
	urldate = {2021-07-09},
	journal = {PLOS Biology},
	author = {Ioannidis, John P. A. and Fanelli, Daniele and Dunne, Debbie Drake and Goodman, Steven N.},
	month = oct,
	year = {2015},
	pages = {e1002264},
}

@article{doll_mortality_1954,
	title = {The {Mortality} of {Doctors} in {Relation} to {Their} {Smoking} {Habits}},
	volume = {1},
	issn = {0959-8138, 1468-5833},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.1.4877.1451},
	doi = {10.1136/bmj.1.4877.1451},
	language = {en},
	number = {4877},
	urldate = {2021-07-09},
	journal = {BMJ},
	author = {Doll, R. and Hill, A. B.},
	month = jun,
	year = {1954},
	pages = {1451--1455},
}

@article{wilson_ten_2019,
	title = {Ten simple rules for the computational modeling of behavioral data},
	volume = {8},
	issn = {2050-084X},
	url = {https://elifesciences.org/articles/49547},
	doi = {10.7554/eLife.49547},
	abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
	language = {en},
	urldate = {2021-07-09},
	journal = {eLife},
	author = {Wilson, Robert C and Collins, Anne GE},
	month = nov,
	year = {2019},
	pages = {e49547},
}

@incollection{frigg_models_2020,
	edition = {Spring 2020},
	title = {Models in {Science}},
	url = {https://plato.stanford.edu/archives/spr2020/entries/models-science/},
	abstract = {Models are of central importance in many scientific contexts. Thecentrality of models such as inflationary models in cosmology,general-circulation models of the global climate, the double-helixmodel of DNA, evolutionary models in biology, agent-based models inthe social sciences, and general-equilibrium models of markets intheir respective domains is a case in point (the Other Internet Resources section at the end of this entry contains links to online resourcesthat discuss these models). Scientists spend significant amounts oftime building, testing, comparing, and revising models, and muchjournal space is dedicated to interpreting and discussing theimplications of models., As a result, models have attracted philosophers’ attention andthere are now sizable bodies of literature about various aspects ofscientific modeling. A tangible result of philosophical engagementwith models is a proliferation of model types recognized in thephilosophical literature. Probing models,phenomenological models, computational models,developmental models, explanatory models,impoverished models, testing models, idealizedmodels, theoretical models, scale models,heuristic models, caricature models, exploratorymodels, didactic models, fantasy models,minimal models, toy models, imaginarymodels, mathematical models, mechanisticmodels, substitute models, iconic models,formal models, analogue models, and instrumentalmodels are but some of the notions that are used to categorizemodels. While at first glance this abundance is overwhelming, it canbe brought under control by recognizing that these notions pertain todifferent problems that arise in connection with models. Models raisequestions in semantics (how, if at all, do models represent?),ontology (what kind of things are models?), epistemology (how do welearn and explain with models?), and, of course, in other domainswithin philosophy of science.},
	urldate = {2021-07-09},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Frigg, Roman and Hartmann, Stephan},
	editor = {Zalta, Edward N.},
	year = {2020},
}

@article{aczel_consensus-based_2020,
	title = {A consensus-based transparency checklist},
	volume = {4},
	issn = {2397-3374},
	url = {http://www.nature.com/articles/s41562-019-0772-6},
	doi = {10.1038/s41562-019-0772-6},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Nature Human Behaviour},
	author = {Aczel, Balazs and Szaszi, Barnabas and Sarafoglou, Alexandra and Kekecs, Zoltan and Kucharský, Šimon and Benjamin, Daniel and Chambers, Christopher D. and Fisher, Agneta and Gelman, Andrew and Gernsbacher, Morton A. and Ioannidis, John P. and Johnson, Eric and Jonas, Kai and Kousta, Stavroula and Lilienfeld, Scott O. and Lindsay, D. Stephen and Morey, Candice C. and Munafò, Marcus and Newell, Benjamin R. and Pashler, Harold and Shanks, David R. and Simons, Daniel J. and Wicherts, Jelte M. and Albarracin, Dolores and Anderson, Nicole D. and Antonakis, John and Arkes, Hal R. and Back, Mitja D. and Banks, George C. and Beevers, Christopher and Bennett, Andrew A. and Bleidorn, Wiebke and Boyer, Ty W. and Cacciari, Cristina and Carter, Alice S. and Cesario, Joseph and Clifton, Charles and Conroy, Ronán M. and Cortese, Mike and Cosci, Fiammetta and Cowan, Nelson and Crawford, Jarret and Crone, Eveline A. and Curtin, John and Engle, Randall and Farrell, Simon and Fearon, Pasco and Fichman, Mark and Frankenhuis, Willem and Freund, Alexandra M. and Gaskell, M. Gareth and Giner-Sorolla, Roger and Green, Don P. and Greene, Robert L. and Harlow, Lisa L. and de la Guardia, Fernando Hoces and Isaacowitz, Derek and Kolodner, Janet and Lieberman, Debra and Logan, Gordon D. and Mendes, Wendy B. and Moersdorf, Lea and Nyhan, Brendan and Pollack, Jeffrey and Sullivan, Christopher and Vazire, Simine and Wagenmakers, Eric-Jan},
	month = jan,
	year = {2020},
	pages = {4--6},
}

@techreport{aczel_guidance_2021,
	type = {preprint},
	title = {Guidance for conducting and reporting multi-analyst studies},
	url = {https://osf.io/5ecnh},
	abstract = {We present consensus-based guidance for conducting and documenting multi-analyst studies. We discuss why broader adoption of the multi-analyst approach will strengthen the robustness of results and conclusions in empirical sciences.},
	urldate = {2021-07-09},
	institution = {MetaArXiv},
	author = {Aczel, Balazs and Szaszi, Barnabas and Nilsonne, Gustav and Van den Akker, Olmo and Albers, Casper J and van Assen, Marcel A. L. M. and Bastiaansen, Jojanneke A. and Benjamin, Daniel Jacob and Boehm, Udo and Botvinik-Nezer, Rotem and Bringmann, Laura Francina and Busch, Niko and Caruyer, Emmanuel and Cataldo, Andrea Michael and Cowan, Nelson and Delios, Andrew and van Dongen, Noah N'Djaye Nikolai and Donkin, Chris and van Doorn, Johnny and Dreber, Anna and Dutilh, Gilles and Egan, Gary F. and Gernsbacher, Morton Ann and Hoekstra, Rink and Hoffmann, Sabine and Holzmeister, Felix and Johannesson, Magnus and Jonas, Kai and Kindel, Alexander and Kirchler, Michael and Kunkels, Yoram Kevin and Lindsay, D. Stephen and Mangin, Jan-Francois and Matzke, Dora and Munafo, Marcus Robert and Newell, Ben R and Nosek, Brian A. and Poldrack, Russell and van Ravenzwaaij, Don and Rieskamp, Jörg and Salganik, Matthew and Sarafoglou, Alexandra and Schonberg, Tom and Schweinsberg, Martin and Shanks, David and Silberzahn, Raphael and Simons, Daniel J. and Spellman, Bobbie and Starns, Jeffrey Joseph and St-Jean, Samuel and Uhlmann, Eric Luis and Wicherts, Jelte M. and Wagenmakers, Eric-Jan},
	month = apr,
	year = {2021},
	doi = {10.31222/osf.io/5ecnh},
}

@article{schulz_multiplicity_2005,
	title = {Multiplicity in randomised trials {I}: endpoints and treatments},
	volume = {365},
	issn = {01406736},
	shorttitle = {Multiplicity in randomised trials {I}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0140673605664616},
	doi = {10.1016/S0140-6736(05)66461-6},
	language = {en},
	number = {9470},
	urldate = {2021-07-09},
	journal = {The Lancet},
	author = {Schulz, Kenneth F and Grimes, David A},
	month = apr,
	year = {2005},
	pages = {1591--1595},
}

@article{sato_type_1996,
	title = {Type {I} and {Type} {II} {Error} in {Multiple} {Comparisons}},
	volume = {130},
	issn = {0022-3980, 1940-1019},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00223980.1996.9915010},
	doi = {10.1080/00223980.1996.9915010},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {The Journal of Psychology},
	author = {Sato, Toru},
	month = may,
	year = {1996},
	pages = {293--302},
}

@article{steegen_increasing_2016,
	title = {Increasing {Transparency} {Through} a {Multiverse} {Analysis}},
	volume = {11},
	issn = {1745-6916, 1745-6924},
	url = {http://journals.sagepub.com/doi/10.1177/1745691616658637},
	doi = {10.1177/1745691616658637},
	abstract = {Empirical research inevitably includes constructing a data set by processing raw data into a form ready for statistical analysis. Data processing often involves choices among several reasonable options for excluding, transforming, and coding data. We suggest that instead of performing only one analysis, researchers could perform a multiverse analysis, which involves performing all analyses across the whole set of alternatively processed data sets corresponding to a large set of reasonable scenarios. Using an example focusing on the effect of fertility on religiosity and political attitudes, we show that analyzing a single data set can be misleading and propose a multiverse analysis as an alternative practice. A multiverse analysis offers an idea of how much the conclusions change because of arbitrary choices in data construction and gives pointers as to which choices are most consequential in the fragility of the result.},
	language = {en},
	number = {5},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew and Vanpaemel, Wolf},
	month = sep,
	year = {2016},
	pages = {702--712},
}

@article{del_giudice_travelers_2021,
	title = {A {Traveler}’s {Guide} to the {Multiverse}: {Promises}, {Pitfalls}, and a {Framework} for the {Evaluation} of {Analytic} {Decisions}},
	volume = {4},
	issn = {2515-2459, 2515-2467},
	shorttitle = {A {Traveler}’s {Guide} to the {Multiverse}},
	url = {http://journals.sagepub.com/doi/10.1177/2515245920954925},
	doi = {10.1177/2515245920954925},
	abstract = {Decisions made by researchers while analyzing data (e.g., how to measure variables, how to handle outliers) are sometimes arbitrary, without an objective justification for choosing one alternative over another. Multiverse-style methods (e.g., specification curve, vibration of effects) estimate an effect across an entire set of possible specifications to expose the impact of hidden degrees of freedom and/or obtain robust, less biased estimates of the effect of interest. However, if specifications are not truly arbitrary, multiverse-style analyses can produce misleading results, potentially hiding meaningful effects within a mass of poorly justified alternatives. So far, a key question has received scant attention: How does one decide whether alternatives are arbitrary? We offer a framework and conceptual tools for doing so. We discuss three kinds of a priori nonequivalence among alternatives—measurement nonequivalence, effect nonequivalence, and power/precision nonequivalence. The criteria we review lead to three decision scenarios: Type E decisions (principled equivalence), Type N decisions (principled nonequivalence), and Type U decisions (uncertainty). In uncertain scenarios, multiverse-style analysis should be conducted in a deliberately exploratory fashion. The framework is discussed with reference to published examples and illustrated with the help of a simulated data set. Our framework will help researchers reap the benefits of multiverse-style methods while avoiding their pitfalls.},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Del Giudice, Marco and Gangestad, Steven W.},
	month = jan,
	year = {2021},
	pages = {251524592095492},
}

@misc{wilson_open_2012,
	title = {Open {Researcher} \&amp; {Contributor} {ID} ({ORCID}): {Solving} the {Name} {Ambiguity} {Problem}},
	shorttitle = {Open {Researcher} \&amp; {Contributor} {ID} ({ORCID})},
	url = {https://er.educause.edu/articles/2012/5/open-researcher--contributor-id-orcid-solving-the-name-ambiguity-problem},
	abstract = {Brian Wilson is Head of Architecture for the Intellectual Property \&amp; Science business of Thomson Reuters and chairs the ORCID Technical Working Group.},
	language = {en},
	urldate = {2021-07-09},
	author = {Wilson, Brian and Fenner, Martin},
	month = may,
	year = {2012},
}

@techreport{kleinberg_netanos_2017,
	type = {preprint},
	title = {{NETANOS} - {Named} entity-based {Text} {Anonymization} for {Open} {Science}},
	url = {https://osf.io/w9nhb},
	abstract = {Background: The shift towards open science, implies that researchers should share their data. Often there is a dilemma between publicly sharing data and protecting their subjects' confidentiality. Moreover, the case of unstructured text data (e.g. stories) poses an additional dilemma: anonymizing texts without deteriorating their content for secondary research. Existing text anonymization systems either deteriorate the content of the original or have not been tested empirically. We propose and empirically evaluate NETANOS: named entity-based text anonymization for open science. NETANOS is an open-source context-preserving anonymization system that identifies and modifies named entities (e.g. persons, locations, times, dates). The aim is to assist researchers in sharing their raw text data.Method \&amp; Results: NETANOS anonymizes critical, contextual information through a stepwise named entity recognition (NER) implementation: it identifies contextual information (e.g. "Munich") and then replaces them with a context-preserving category label (e.g. "Location\_1"). We assessed how good participants were in re-identifying several travel stories (e.g. locations, names) that were presented in the original (“Max”), human anonymized (“Max” → “Person1”), NETANOS (”Max” → “Person1”), and in a context-deteriorating state (“Max” → “XXX”). Bayesian testing revealed that the NETANOS anonymization was practically equivalent to the human baseline anonymization.Conclusions: Named entity recognition can be applied to the anonymization of critical, identifiable information in text data. The proposed stepwise anonymization procedure provides a fully automated, fast system for text anonymization. NETANOS might be an important step to address researchers' dilemmas when sharing text data within the open science movement.},
	urldate = {2021-07-09},
	institution = {Open Science Framework},
	author = {Kleinberg, Bennett and Mozes, Maximilian and van der Toolen, Yaloe and Verschuere, Bruno},
	month = jun,
	year = {2017},
	doi = {10.31219/osf.io/w9nhb},
}

@techreport{topor_integrative_2020,
	type = {preprint},
	title = {An integrative framework for planning and conducting {Non}-{Intervention}, {Reproducible}, and {Open} {Systematic} {Reviews} ({NIRO}-{SR})},
	url = {https://osf.io/8gu5z},
	abstract = {Mounting evidence indicates issues with low adherence to existing consensus-based guidelines for conducting systematic reviews (SRs), meaning that SRs can be subject to selective or misreporting practices. This problem arises in part from scarce guidance for reproducible reporting practices. This is compounded by the fact that existing guidelines are mainly applicable to interventional research designs, with systematic reviewers of non-interventional studies resorting to customised tools that deviate from best practice. Here, we present the development of the first comprehensive tool for conducting and reporting Non-Interventional, Reproducible, and Open Systematic Reviews (NIRO-SR). NIRO-SR is a 68-item checklist composed of two parts that provide itemised guidance on the preparation of a protocol for pre-registration (Part A) and reporting the review (Part B) in a reproducible and transparent manner. This paper, the tool, and an open repository (https://osf.io/f3brw/) provide a comprehensive resource for anyone who aims to conduct a high quality SR of non-interventional studies.},
	urldate = {2021-07-09},
	institution = {MetaArXiv},
	author = {Topor, Marta and Pickering, Jade Samantha and Barbosa Mendes, Ana and Bishop, Dorothy Vera Margaret and Büttner, Fionn Cléirigh and Elsherif, Mahmoud Medhat and Evans, Thomas Rhys and Henderson, Emma Louise and Kalandadze, Tamara and Nitschke, Faye Terese and Staaks, Janneke and Van den Akker, Olmo and Yeung, Siu Kit and Zaneva, Mirela and Lam, Alison and Madan, Christopher R and Moreau, David and O'Mahony, Aoife and Parker, Adam James and Riegelman, Amy and Testerman, Meghan M. and Westwood, Samuel James},
	month = dec,
	year = {2020},
	doi = {10.31222/osf.io/8gu5z},
}

@article{spence_concise_2018,
	title = {Concise, {Simple}, and {Not} {Wrong}: {In} {Search} of a {Short}-{Hand} {Interpretation} of {Statistical} {Significance}},
	volume = {9},
	issn = {1664-1078},
	shorttitle = {Concise, {Simple}, and {Not} {Wrong}},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2018.02185/full},
	doi = {10.3389/fpsyg.2018.02185},
	urldate = {2021-07-09},
	journal = {Frontiers in Psychology},
	author = {Spence, Jeffrey R. and Stanley, David J.},
	month = nov,
	year = {2018},
	pages = {2185},
}

@article{macfarlane_communism_2008,
	title = {Communism, {Universalism} and {Disinterestedness}: {Re}-examining {Contemporary} {Support} among {Academics} for {Merton}’s {Scientific} {Norms}},
	volume = {6},
	issn = {1570-1727, 1572-8544},
	shorttitle = {Communism, {Universalism} and {Disinterestedness}},
	url = {http://link.springer.com/10.1007/s10805-008-9055-y},
	doi = {10.1007/s10805-008-9055-y},
	language = {en},
	number = {1},
	urldate = {2021-07-09},
	journal = {Journal of Academic Ethics},
	author = {Macfarlane, Bruce and Cheng, Ming},
	month = mar,
	year = {2008},
	pages = {67--78},
}

@misc{noauthor_budapest_2002,
	title = {Budapest {Open} {Access} {Initiative} {\textbar} {Read} the {Budapest} {Open} {Access} {Initiative}},
	url = {https://www.budapestopenaccessinitiative.org/read},
	urldate = {2021-07-09},
	month = feb,
	year = {2002},
}

@article{easterbrook_open_2014,
	title = {Open code for open science?},
	volume = {7},
	issn = {1752-0894, 1752-0908},
	url = {http://www.nature.com/articles/ngeo2283},
	doi = {10.1038/ngeo2283},
	language = {en},
	number = {11},
	urldate = {2021-07-09},
	journal = {Nature Geoscience},
	author = {Easterbrook, Steve M.},
	month = nov,
	year = {2014},
	pages = {779--781},
}

@misc{noauthor_what_nodate-2,
	title = {What is {Open} {Data}?},
	url = {https://opendatahandbook.org/guide/en/what-is-open-data/},
	urldate = {2021-07-09},
	journal = {Open Data Handbook},
}

@misc{noauthor_open_nodate,
	title = {The {Open} {Definition} - {Open} {Definition} - {Defining} {Open} in {Open} {Data}, {Open} {Content} and {Open} {Knowledge}},
	url = {https://opendefinition.org/},
	urldate = {2021-07-09},
	journal = {Open Knowledge Foundation},
}

@misc{noauthor_open_2017,
	title = {Open {Educational} {Resources} ({OER})},
	url = {https://en.unesco.org/themes/building-knowledge-societies/oer},
	language = {en},
	urldate = {2021-07-09},
	journal = {UNESCO},
	month = jul,
	year = {2017},
}

@misc{noauthor_what_nodate-3,
	title = {What is open education?},
	url = {https://opensource.com/resources/what-open-education},
	abstract = {What is open education?},
	language = {en},
	urldate = {2021-07-09},
	journal = {Opensource.com},
}

@misc{noauthor_oer_nodate,
	title = {{OER} {Commons}},
	url = {https://www.oercommons.org/},
	urldate = {2021-07-09},
	journal = {OER Commons},
}

@misc{noauthor_licenses_nodate,
	title = {Licenses \& {Standards} {\textbar} {Open} {Source} {Initiative}},
	url = {https://opensource.org/licenses},
	urldate = {2021-07-09},
	journal = {Open Source Initative},
}

@article{poldrack_toward_2013,
	title = {Toward open sharing of task-based {fMRI} data: the {OpenfMRI} project},
	volume = {7},
	issn = {1662-5196},
	shorttitle = {Toward open sharing of task-based {fMRI} data},
	url = {http://journal.frontiersin.org/article/10.3389/fninf.2013.00012/abstract},
	doi = {10.3389/fninf.2013.00012},
	urldate = {2021-07-09},
	journal = {Frontiers in Neuroinformatics},
	author = {Poldrack, Russell A. and Barch, Deanna M. and Mitchell, Jason P. and Wager, Tor D. and Wagner, Anthony D. and Devlin, Joseph T. and Cumba, Chad and Koyejo, Oluwasanmi and Milham, Michael P.},
	year = {2013},
}

@article{poldrack_making_2014,
	title = {Making big data open: data sharing in neuroimaging},
	volume = {17},
	issn = {1097-6256, 1546-1726},
	shorttitle = {Making big data open},
	url = {http://www.nature.com/articles/nn.3818},
	doi = {10.1038/nn.3818},
	language = {en},
	number = {11},
	urldate = {2021-07-09},
	journal = {Nature Neuroscience},
	author = {Poldrack, Russell A and Gorgolewski, Krzysztof J},
	month = nov,
	year = {2014},
	pages = {1510--1517},
}

@misc{noauthor_free_nodate,
	title = {A free and open platform for sharing {MRI}, {MEG}, {EEG}, {iEEG}, {ECoG}, {ASL}, and {PET} data - {OpenNeuro}},
	url = {https://openneuro.org/},
	urldate = {2021-07-09},
	journal = {OpenNeuro},
}

@article{ross-hellauer_what_2017,
	title = {What is open peer review? {A} systematic review},
	volume = {6},
	issn = {2046-1402},
	shorttitle = {What is open peer review?},
	url = {https://f1000research.com/articles/6-588/v2},
	doi = {10.12688/f1000research.11369.2},
	abstract = {Background
              : “Open peer review” (OPR), despite being a major pillar of Open Science, has neither a standardized definition nor an agreed schema of its features and implementations. The literature reflects this, with numerous overlapping and contradictory definitions. While for some the term refers to peer review where the identities of both author and reviewer are disclosed to each other, for others it signifies systems where reviewer reports are published alongside articles. For others it signifies both of these conditions, and for yet others it describes systems where not only “invited experts” are able to comment. For still others, it includes a variety of combinations of these and other novel methods.
            
            
              Methods
              : Recognising the absence of a consensus view on what open peer review is, this article undertakes a systematic review of definitions of “open peer review” or “open review”, to create a corpus of 122 definitions. These definitions are systematically analysed to build a coherent typology of the various innovations in peer review signified by the term, and hence provide the precise technical definition currently lacking.
            
            
              Results
              : This quantifiable data yields rich information on the range and extent of differing definitions over time and by broad subject area. Quantifying definitions in this way allows us to accurately portray exactly how ambiguously the phrase “open peer review” has been used thus far, for the literature offers 22 distinct configurations of seven traits, effectively meaning that there are 22 different definitions of OPR in the literature reviewed.
            
            
              Conclusions
              : I propose a pragmatic definition of open peer review as an umbrella term for a number of overlapping ways that peer review models can be adapted in line with the aims of Open Science, including making reviewer and author identities open, publishing review reports and enabling greater participation in the peer review process.},
	language = {en},
	urldate = {2021-07-09},
	journal = {F1000Research},
	author = {Ross-Hellauer, Tony},
	month = aug,
	year = {2017},
	pages = {588},
}

@techreport{tennant_foundations_2019,
	type = {preprint},
	title = {Foundations for {Open} {Scholarship} {Strategy} {Development}},
	url = {https://osf.io/b4v8p},
	abstract = {This document aims to agree on a broad, international strategy for the implementation of open scholarship that meets the needs of different national and regional communities but works globally.Scholarly research can be idealised as an inspirational process for advancing our collective knowledge to the benefit of all humankind. However, current research practices often struggle with a range of tensions, in part due to the fact that this collective (or “commons”) ideal conflicts with the competitive system in which most scholars work, and in part because much of the infrastructure of the scholarly world is becoming largely digital. What is broadly termed as Open Scholarship is an attempt to realign modern research practices with this ideal. We do not propose a definition of Open Scholarship, but recognise that it is a holistic term that encompasses many disciplines, practices, and principles, sometimes also referred to as Open Science or Open Research. We choose the term Open Scholarship to be more inclusive of these other terms. When we refer to science in this document, we do so historically and use it as shorthand for more general scholarship.The purpose of this document is to provide a concise analysis of where the global Open Scholarship movement currently stands: what the common threads and strengths are, where the greatest opportunities and challenges lie, and how we can more effectively work together as a global community to recognise and address the top strategic priorities. This document was inspired by the Foundations for OER Strategy Development and work in the FORCE11 Scholarly Commons Working Group, and developed by an open contribution working group.Our hope is that this document will serve as a foundational resource for continuing discussions and initiatives about implementing effective strategies to help streamline the integration of Open Scholarship practices into a modern, digital research culture. Through this, we hope to extend the reach and impact of Open Scholarship into a global context, making sure that it is truly open for all. We also hope that this document will evolve as the conversations around Open Scholarship progress, and help to provide useful insight for both global co-ordination and local action. We believe this is a step forward in making Open Scholarship the norm.Ultimately, we expect the impact of widespread adoption of Open Scholarship to be diverse. We expect novel research practices to accelerate the pace of innovation, and therefore stimulate critical industries around the world. We could also expect to see an increase in public trust of science and scholarship, as transparency becomes more normative. As such, we expect interest in Open Scholarship to increase at multiple levels, due to its inherent influence on society and global economics.},
	urldate = {2021-07-09},
	institution = {MetaArXiv},
	author = {Tennant, Jonathan and Beamer, Jennifer Elizabeth and Bosman, Jeroen and Brembs, Björn and Chung, Neo Christopher and Clement, Gail and Crick, Tom and Dugan, Jonathan and Dunning, Alastair and Eccles, David and Enkhbayar, Asura and Graziotin, Daniel and Harding, Rachel and Havemann, Johanna and Katz, Daniel S. and Khanal, Kshitiz and Kjaer, Jesper Norgaard and Koder, Tim and Macklin, Paul and Madan, Christopher R and Masuzzo, Paola and Matthias, Lisa and Mayer, Katja and Nichols, David and Papadopoulou, Elli and Pasquier, Thomas and Ross-Hellauer, Tony and Schulte-Mecklenbeck, Michael and Sholler, Dan and Steiner, Tobias and Szczesny, Pawel and Turner, Andy},
	month = jan,
	year = {2019},
	doi = {10.31222/osf.io/b4v8p},
}

@misc{noauthor_open_nodate-1,
	title = {Open {Scholarship} {Knowledge} {Base} {\textbar} {OER} {Commons}},
	url = {https://www.oercommons.org/hubs/OSKB},
	urldate = {2021-07-09},
	journal = {OER Commons},
}

@article{woelfle_open_2011,
	title = {Open science is a research accelerator},
	volume = {3},
	issn = {1755-4330, 1755-4349},
	url = {http://www.nature.com/articles/nchem.1149},
	doi = {10.1038/nchem.1149},
	language = {en},
	number = {10},
	urldate = {2021-07-09},
	journal = {Nature Chemistry},
	author = {Woelfle, Michael and Olliaro, Piero and Todd, Matthew H.},
	month = oct,
	year = {2011},
	pages = {745--748},
}

@techreport{syed_open_2019,
	type = {preprint},
	title = {The {Open} {Science} {Movement} is {For} {All} of {Us}},
	url = {https://osf.io/cteyb},
	abstract = {The open science movement has been gaining steam in numerous scientific disciplines (e.g., ecology, cancer biology, economics) as well as sub-disciplines of psychology (e.g., social, personality). These issues, however, are still not widely understood nor seen as applicable to all types of research. This presentation will include an overview of core issues in the open science movement and how they apply to all types of psychological research (any sub-discipline, any method). Emphasis will be placed on how incorporating open science principles can improve both theoretical and empirical work in psychology.},
	urldate = {2021-07-09},
	institution = {PsyArXiv},
	author = {Syed, Moin},
	month = apr,
	year = {2019},
	doi = {10.31234/osf.io/cteyb},
}

@article{foster_msls_open_2017,
	title = {Open {Science} {Framework} ({OSF})},
	volume = {105},
	issn = {1558-9439, 1536-5050},
	url = {http://jmla.pitt.edu/ojs/jmla/article/view/88},
	doi = {10.5195/JMLA.2017.88},
	abstract = {The Open Science Framework (OSF) is a free, open source, research workflow web application developed and maintained by the Center for Open Science (COS).},
	number = {2},
	urldate = {2021-07-09},
	journal = {Journal of the Medical Library Association},
	author = {Foster, MSLS, Erin D. and Deardorff, MLIS, Ariel},
	month = apr,
	year = {2017},
}

@misc{noauthor_open_nodate-2,
	title = {The {Open} {Source} {Definition} {\textbar} {Open} {Source} {Initiative}},
	url = {https://opensource.org/osd},
	urldate = {2021-07-09},
	journal = {Open Source Initative},
}

@misc{noauthor_osf_nodate,
	title = {{OSF}},
	url = {https://osf.io/},
	urldate = {2021-07-09},
	journal = {Open Science Framework},
}

@misc{villum_open-washing_2014,
	title = {“{Open}-washing” – {The} difference between opening your data and simply making them available – {Open} {Knowledge} {Foundation} blog},
	url = {https://blog.okfn.org/2014/03/10/open-washing-the-difference-between-opening-your-data-and-simply-making-them-available/},
	urldate = {2021-07-09},
	journal = {Open Knowledge Foundation},
	author = {Villum, Christian},
	month = mar,
	year = {2014},
}

@article{vlaeminck_journals_2017,
	title = {Journals in {Economic} {Sciences}: {Paying} {Lip} {Service} to {Reproducible} {Research}?},
	volume = {41},
	issn = {0739-1137, 0739-1137},
	shorttitle = {Journals in {Economic} {Sciences}},
	url = {https://www.iassistquarterly.com/index.php/iassist/article/view/6},
	doi = {10.29173/iq6},
	abstract = {The findings of numerous replication studies in economics have raised serious concerns regarding the credibility and reliability of published applied economic research. Literature suggests that economic research often is not replicable because (i) only a small proportion of journals in the field have implemented functional policies on the disclosure of employed datasets and program code, (ii) authors frequently do not comply with these data policies and (iii) editorial offices do not ensure that these policies are enforced. In this paper, we focus on the aspect last mentioned. We empirically evaluate 599 articles published in 37 journals with a data availability policy. We present the share of articles that fall under a data policy, because replication data is needed to verify the published results. Afterwards, we check the journal data archives and supplemental information section of each article for the availability of replication files. For a reduced sub-sample of 245 data-based articles, we check in depth whether the replication files we found are compliant with the requirements of the journal’s respective data policy. Thereby, we are able to determine how much journals in economic sciences enforce their data policies. Our findings suggest a mixed picture: While some journals achieve high compliance rates, a significant share of journals only sporadically provides replication files for data-based research papers. Overall, 47.5\% of all articles analysed honour the data policy of the respective journal. Our findings also provide evidence that voluntary data policies are not effective in fostering replicable research.},
	number = {1-4},
	urldate = {2021-07-09},
	journal = {IASSIST Quarterly},
	author = {Vlaeminck, Sven and Podkrajac, Felix},
	month = dec,
	year = {2017},
	pages = {16},
}

@article{farrow_open_2017,
	title = {Open education and critical pedagogy},
	volume = {42},
	issn = {1743-9884, 1743-9892},
	url = {https://www.tandfonline.com/doi/full/10.1080/17439884.2016.1113991},
	doi = {10.1080/17439884.2016.1113991},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Learning, Media and Technology},
	author = {Farrow, Robert},
	month = apr,
	year = {2017},
	pages = {130--146},
}

@misc{moretti_beyond_2020,
	title = {Beyond {Open}-washing: {Are} {Narratives} the {Future} of {Open} {Data} {Portals}? {\textbar} by matteo moretti {\textbar} {Nightingale} {\textbar} {Medium}},
	url = {https://medium.com/nightingale/beyond-open-washing-are-stories-and-narratives-the-future-of-open-data-portals-93228d8882f3},
	urldate = {2021-07-09},
	journal = {Nightingale},
	author = {Moretti, Matteo},
	month = aug,
	year = {2020},
}

@article{sagarin_ethical_2014,
	title = {An {Ethical} {Approach} to {Peeking} at {Data}},
	volume = {9},
	issn = {1745-6916, 1745-6924},
	url = {http://journals.sagepub.com/doi/10.1177/1745691614528214},
	doi = {10.1177/1745691614528214},
	abstract = {When data analyses produce encouraging but nonsignificant results, researchers often respond by collecting more data. This may transform a disappointing dataset into a publishable study, but it does so at the cost of increasing the Type I error rate. How big of a problem is this, and what can we do about it? To answer the first question, we estimate the Type I error inflation based on the initial sample size, the number of participants used to augment the dataset, the critical value for determining significance (typically .05), and the maximum p value within the initial sample such that the dataset would be augmented. With one round of augmentation, Type I error inflation maximizes at .0975 with typical values from .0564 to .0883. To answer the second question, we review methods of adjusting the critical value to allow augmentation while maintaining p {\textless} .05, but we note that such methods must be applied a priori. For the common occurrence of post-hoc dataset augmentation, we develop a new statistic, p
              augmented
              , that represents the magnitude of the resulting Type I error inflation. We argue that the disclosure of post-hoc dataset augmentation via p
              augmented
              elevates such augmentation from a questionable research practice to an ethical research decision.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Sagarin, Brad J. and Ambler, James K. and Lee, Ellen M.},
	month = may,
	year = {2014},
	pages = {293--304},
}

@article{beffara_bret_fully_2021,
	title = {A fully automated, transparent, reproducible, and blind protocol for sequential analyses},
	volume = {5},
	issn = {2003-2714},
	url = {https://open.lnu.se/index.php/metapsychology/article/view/869},
	doi = {10.15626/MP.2018.869},
	abstract = {Despite many cultural, methodological, and technical improvements, one of the major obstacle to results reproducibility remains the pervasive low statistical power. In response to this problem, a lot of attention has recently been drawn to sequential analyses. This type of procedure has been shown to be more efficient (to require less observations and therefore less resources) than classical fixed-N procedures. However, these procedures are submitted to both intrapersonal and interpersonal biases during data collection and data analysis. In this tutorial, we explain how automation can be used to prevent these biases. We show how to synchronise open and free experiment software programs with the Open Science Framework and how to automate sequential data analyses in R. This tutorial is intended to researchers with beginner experience with R but no previous experience with sequential analyses is required.},
	urldate = {2021-07-09},
	journal = {Meta-Psychology},
	author = {Beffara Bret, Brice and Beffara Bret, Amélie and Nalborczyk, Ladislas},
	month = may,
	year = {2021},
}

@article{haak_orcid_2012,
	title = {{ORCID}: a system to uniquely identify researchers},
	volume = {25},
	issn = {09531513, 17414857},
	shorttitle = {{ORCID}},
	url = {http://doi.wiley.com/10.1087/20120404},
	doi = {10.1087/20120404},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Learned Publishing},
	author = {Haak, Laurel L. and Fenner, Martin and Paglione, Laura and Pentz, Ed and Ratner, Howard},
	month = oct,
	year = {2012},
	pages = {259--264},
}

@misc{noauthor_orcid_nodate,
	title = {{ORCID}},
	url = {https://orcid.org/},
	urldate = {2021-07-09},
	journal = {ORCID},
}

@article{ginsparg_winners_1997,
	title = {Winners and {Losers} in the {Global} {Research} {Village}},
	volume = {30},
	issn = {0361-526X, 1541-1095},
	url = {http://www.tandfonline.com/doi/abs/10.1300/J123v30n03_13},
	doi = {10.1300/J123v30n03_13},
	language = {en},
	number = {3-4},
	urldate = {2021-07-09},
	journal = {The Serials Librarian},
	author = {Ginsparg, Paul},
	month = may,
	year = {1997},
	pages = {83--95},
}

@misc{ginsparg_creating_2001,
	title = {Creating a global knowledge network},
	url = {http://www.cs.cornell.edu/~ginsparg/physics/blurb/pg01unesco.html},
	urldate = {2021-07-09},
	journal = {Cornell University},
	author = {Ginsparg, Paul},
	month = feb,
	year = {2001},
}

@article{bruns_p-curve_2016,
	title = {p-{Curve} and p-{Hacking} in {Observational} {Research}},
	volume = {11},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0149144},
	doi = {10.1371/journal.pone.0149144},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {PLOS ONE},
	author = {Bruns, Stephan B. and Ioannidis, John P. A.},
	editor = {Marinazzo, Daniele},
	month = feb,
	year = {2016},
	pages = {e0149144},
}

@article{simonsohn_p-curve_2014,
	title = {P-curve: {A} key to the file-drawer.},
	volume = {143},
	issn = {1939-2222, 0096-3445},
	shorttitle = {P-curve},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0033242},
	doi = {10.1037/a0033242},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {Journal of Experimental Psychology: General},
	author = {Simonsohn, Uri and Nelson, Leif D. and Simmons, Joseph P.},
	year = {2014},
	pages = {534--547},
}

@article{simonsohn_specification_2020,
	title = {Specification curve analysis},
	volume = {4},
	issn = {2397-3374},
	url = {http://www.nature.com/articles/s41562-020-0912-z},
	doi = {10.1038/s41562-020-0912-z},
	language = {en},
	number = {11},
	urldate = {2021-07-09},
	journal = {Nature Human Behaviour},
	author = {Simonsohn, Uri and Simmons, Joseph P. and Nelson, Leif D.},
	month = nov,
	year = {2020},
	pages = {1208--1214},
}

@article{simonsohn_p-curve_2019,
	title = {P-curve won’t do your laundry, but it will distinguish replicable from non-replicable findings in observational research: {Comment} on {Bruns} \& {Ioannidis} (2016)},
	volume = {14},
	issn = {1932-6203},
	shorttitle = {P-curve won’t do your laundry, but it will distinguish replicable from non-replicable findings in observational research},
	url = {https://dx.plos.org/10.1371/journal.pone.0213454},
	doi = {10.1371/journal.pone.0213454},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {PLOS ONE},
	author = {Simonsohn, Uri and Nelson, Leif D. and Simmons, Joseph P.},
	editor = {Puebla, Iratxe},
	month = mar,
	year = {2019},
	pages = {e0213454},
}

@article{simonsohn_p_2014,
	title = {\textit{p} -{Curve} and {Effect} {Size}: {Correcting} for {Publication} {Bias} {Using} {Only} {Significant} {Results}},
	volume = {9},
	issn = {1745-6916, 1745-6924},
	shorttitle = {\textit{p} -{Curve} and {Effect} {Size}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691614553988},
	doi = {10.1177/1745691614553988},
	abstract = {Journals tend to publish only statistically significant evidence, creating a scientific record that markedly overstates the size of effects. We provide a new tool that corrects for this bias without requiring access to nonsignificant results. It capitalizes on the fact that the distribution of significant p values, p-curve, is a function of the true underlying effect. Researchers armed only with sample sizes and test results of the published findings can correct for publication bias. We validate the technique with simulations and by reanalyzing data from the Many-Labs Replication project. We demonstrate that p-curve can arrive at conclusions opposite that of existing tools by reanalyzing the meta-analysis of the “choice overload” literature.},
	language = {en},
	number = {6},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Simonsohn, Uri and Nelson, Leif D. and Simmons, Joseph P.},
	month = nov,
	year = {2014},
	pages = {666--681},
}

@article{simonsohn_specification_2015,
	title = {Specification {Curve}: {Descriptive} and {Inferential} {Statistics} on {All} {Reasonable} {Specifications}},
	issn = {1556-5068},
	shorttitle = {Specification {Curve}},
	url = {http://www.ssrn.com/abstract=2694998},
	doi = {10.2139/ssrn.2694998},
	language = {en},
	urldate = {2021-07-09},
	journal = {SSRN Electronic Journal},
	author = {Simonsohn, Uri and Simmons, Joseph P. and Nelson, Leif D.},
	year = {2015},
}

@article{neuroskeptic_nine_2012,
	title = {The {Nine} {Circles} of {Scientific} {Hell}},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	url = {http://journals.sagepub.com/doi/10.1177/1745691612459519},
	doi = {10.1177/1745691612459519},
	language = {en},
	number = {6},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {{Neuroskeptic}},
	month = nov,
	year = {2012},
	pages = {643--644},
}

@book{team_p_nodate,
	title = {P {\textbar} {Glossary}},
	url = {https://psyteachr.github.io/glossary},
	abstract = {Definitions of technical terms},
	urldate = {2021-07-09},
	author = {Team, psyTeachR},
}

@article{wasserstein_asa_2016,
	title = {The {ASA} {Statement} on \textit{p} -{Values}: {Context}, {Process}, and {Purpose}},
	volume = {70},
	issn = {0003-1305, 1537-2731},
	shorttitle = {The {ASA} {Statement} on \textit{p} -{Values}},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108},
	doi = {10.1080/00031305.2016.1154108},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {The American Statistician},
	author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
	month = apr,
	year = {2016},
	pages = {129--133},
}

@article{hackett_publishing_2020,
	title = {Publishing ethics in the era of paper mills},
	volume = {9},
	issn = {2046-6390},
	url = {https://journals.biologists.com/bio/article/9/10/bio056556/222806/Publishing-ethics-in-the-era-of-paper-mills},
	doi = {10.1242/bio.056556},
	language = {en},
	number = {10},
	urldate = {2021-07-09},
	journal = {Biology Open},
	author = {Hackett, Rachel and Kelly, Steven},
	month = oct,
	year = {2020},
	pages = {bio056556},
}

@article{byrne_digital_2020,
	title = {Digital magic, or the dark arts of the 21 $^{\textrm{st}}$ century—how can journals and peer reviewers detect manuscripts and publications from paper mills?},
	volume = {594},
	issn = {0014-5793, 1873-3468},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/1873-3468.13747},
	doi = {10.1002/1873-3468.13747},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {FEBS Letters},
	author = {Byrne, Jennifer A. and Christopher, Jana},
	month = feb,
	year = {2020},
	pages = {583--589},
}

@article{lakens_practical_2021,
	title = {The {Practical} {Alternative} to the \textit{p} {Value} {Is} the {Correctly} {Used} \textit{p} {Value}},
	volume = {16},
	issn = {1745-6916, 1745-6924},
	url = {http://journals.sagepub.com/doi/10.1177/1745691620958012},
	doi = {10.1177/1745691620958012},
	abstract = {Because of the strong overreliance on p values in the scientific literature, some researchers have argued that we need to move beyond p values and embrace practical alternatives. When proposing alternatives to p values statisticians often commit the “statistician’s fallacy,” whereby they declare which statistic researchers really “want to know.” Instead of telling researchers what they want to know, statisticians should teach researchers which questions they can ask. In some situations, the answer to the question they are most interested in will be the p value. As long as null-hypothesis tests have been criticized, researchers have suggested including minimum-effect tests and equivalence tests in our statistical toolbox, and these tests have the potential to greatly improve the questions researchers ask. If anyone believes p values affect the quality of scientific research, preventing the misinterpretation of p values by developing better evidence-based education and user-centered statistical software should be a top priority. Polarized discussions about which statistic scientists should use has distracted us from examining more important questions, such as asking researchers what they want to know when they conduct scientific research. Before we can improve our statistical inferences, we need to improve our statistical questions.},
	language = {en},
	number = {3},
	urldate = {2021-07-09},
	journal = {Perspectives on Psychological Science},
	author = {Lakens, Daniël},
	month = may,
	year = {2021},
	pages = {639--648},
}

@article{yamada_how_2018,
	title = {How to {Crack} {Pre}-registration: {Toward} {Transparent} and {Open} {Science}},
	volume = {9},
	issn = {1664-1078},
	shorttitle = {How to {Crack} {Pre}-registration},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2018.01831/full},
	doi = {10.3389/fpsyg.2018.01831},
	urldate = {2021-07-09},
	journal = {Frontiers in Psychology},
	author = {Yamada, Yuki},
	month = sep,
	year = {2018},
	pages = {1831},
}

@book{kreuter_improving_2013,
	address = {Hoboken, New Jersey},
	title = {Improving {Surveys} with {Paradata}: {Analytic} {Uses} of {Process} {Information}},
	isbn = {978-1-118-59686-9 978-0-470-90541-8},
	shorttitle = {Improving {Surveys} with {Paradata}},
	url = {http://doi.wiley.com/10.1002/9781118596869},
	language = {en},
	urldate = {2021-07-09},
	publisher = {John Wiley \& Sons, Inc.},
	editor = {Kreuter, Frauke},
	month = may,
	year = {2013},
	doi = {10.1002/9781118596869},
}

@misc{ikeda_questionable_2019,
	title = {Questionable research practices following pre-registration},
	url = {https://doi.org/10.24602/sjpr.62.3_281},
	language = {ja},
	urldate = {2021-07-09},
	publisher = {心理学評論刊行会},
	author = {Ikeda, Ayumi and Xu, Haoqin and Fuji, Naoto and Zhu, Siqi and Yamada, Yuki},
	year = {2019},
}

@article{cornwall_what_1995,
	title = {What is participatory research?},
	volume = {41},
	issn = {02779536},
	url = {https://linkinghub.elsevier.com/retrieve/pii/027795369500127S},
	doi = {10.1016/0277-9536(95)00127-S},
	language = {en},
	number = {12},
	urldate = {2021-07-09},
	journal = {Social Science \& Medicine},
	author = {Cornwall, Andrea and Jewkes, Rachel},
	month = dec,
	year = {1995},
	pages = {1667--1676},
}

@article{fletcher-watson_making_2019,
	title = {Making the future together: {Shaping} autism research through meaningful participation},
	volume = {23},
	issn = {1362-3613, 1461-7005},
	shorttitle = {Making the future together},
	url = {http://journals.sagepub.com/doi/10.1177/1362361318786721},
	doi = {10.1177/1362361318786721},
	abstract = {Participatory research methods connect researchers with relevant communities to achieve shared goals. These methods can deliver results that are relevant to people’s lives and thus likely to have a positive impact. In the context of a large and growing body of autism research, with continued poor implementation, and some evidence of community dissatisfaction, there is a powerful case for participatory autism research. In order to develop a framework for such collaborative working, a UK seminar series was organised and co-produced by autistic and non-autistic people with academic, practitioner and lived expertise. This article reports on the outcomes from the series, identifying five topics relevant to building a community of practice in participatory research: Respect, Authenticity, Assumptions, Infrastructure and Empathy. Each topic is connected to a specific example from within and beyond research, to inspire new practices in the field. We call for the development of participatory research skills among the autism research community and the facilitation of greater autistic leadership of, and partnership in, research. Such work, if delivered to a high standard, is likely to lead to better translation into practice and improved outcomes for autistic people and those who support them.},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {Autism},
	author = {Fletcher-Watson, Sue and Adams, Jon and Brook, Kabie and Charman, Tony and Crane, Laura and Cusack, James and Leekam, Susan and Milton, Damian and Parr, Jeremy R and Pellicano, Elizabeth},
	month = may,
	year = {2019},
	pages = {943--953},
}

@article{kiernan_participation_1999,
	title = {Participation in {Research} by {People} with {Learning} {Disability}: {Origins} and {Issues}},
	volume = {27},
	issn = {13544187, 14683156},
	shorttitle = {Participation in {Research} by {People} with {Learning} {Disability}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1468-3156.1999.tb00084.x},
	doi = {10.1111/j.1468-3156.1999.tb00084.x},
	language = {en},
	number = {2},
	urldate = {2021-07-09},
	journal = {British Journal of Learning Disabilities},
	author = {Kiernan, Chris},
	month = jun,
	year = {1999},
	pages = {43--47},
}

@book{leavy_research_2017,
	address = {New York ; London},
	title = {Research design: quantitative, qualitative, mixed methods, arts-based, and community-based participatory research approaches},
	isbn = {978-1-4625-2999-5 978-1-4625-1438-0},
	shorttitle = {Research design},
	abstract = {This user-friendly book provides a step-by-step guide to using the five major approaches to research design: quantitative, qualitative, mixed methods, arts-based, and community-based participatory research. Chapters on each approach follow a unique format--they present a template for a research proposal and explain in detail how to conceptualize and fill in every section. Terminology commonly used within each approach is identified, and key moments of ethical decision making are flagged. Interdisciplinary research examples draw on current events and social justice topics},
	publisher = {Guilford Press},
	author = {Leavy, Patricia},
	year = {2017},
	note = {OCLC: ocn959274855},
	keywords = {Social sciences, Methodology, Qualitative research, Research Methodology, Interdisciplinary research, Quantitative research},
}

@article{rose_participatory_2018,
	title = {Participatory research: real or imagined},
	volume = {53},
	issn = {0933-7954, 1433-9285},
	shorttitle = {Participatory research},
	url = {http://link.springer.com/10.1007/s00127-018-1549-3},
	doi = {10.1007/s00127-018-1549-3},
	language = {en},
	number = {8},
	urldate = {2021-07-09},
	journal = {Social Psychiatry and Psychiatric Epidemiology},
	author = {Rose, Diana},
	month = aug,
	year = {2018},
	pages = {765--771},
}

@article{ottmann_coproduction_2011,
	title = {Coproduction in {Practice}: {Participatory} {Action} {Research} to {Develop} a {Model} of {Community} {Aged} {Care}},
	volume = {24},
	issn = {1094-429X, 1573-9295},
	shorttitle = {Coproduction in {Practice}},
	url = {http://link.springer.com/10.1007/s11213-011-9192-x},
	doi = {10.1007/s11213-011-9192-x},
	language = {en},
	number = {5},
	urldate = {2021-07-09},
	journal = {Systemic Practice and Action Research},
	author = {Ottmann, Goetz and Laragy, Carmel and Allen, Jacqui and Feldman, Peter},
	month = oct,
	year = {2011},
	pages = {413--427},
}

@article{boivin_evaluating_2018,
	title = {Evaluating patient and public involvement in research},
	issn = {0959-8138, 1756-1833},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.k5147},
	doi = {10.1136/bmj.k5147},
	language = {en},
	urldate = {2021-07-10},
	journal = {BMJ},
	author = {Boivin, Antoine and Richards, Tessa and Forsythe, Laura and Grégoire, Alexandre and L’Espérance, Audrey and Abelson, Julia and Carman, Kristin L},
	month = dec,
	year = {2018},
	pages = {k5147},
}

@article{day_open_2020,
	title = {Open to the public: paywalls and the public rationale for open access medical research publishing},
	volume = {6},
	issn = {2056-7529},
	shorttitle = {Open to the public},
	url = {https://researchinvolvement.biomedcentral.com/articles/10.1186/s40900-020-0182-y},
	doi = {10.1186/s40900-020-0182-y},
	abstract = {Abstract
            Public voices have largely been absent from the discussions about open access publishing in medical research. Yet the public have a strong interest in ensuring open access of medical research findings because of their roles as funders, advocates, research participants, and patients. By limiting access to research outputs, the current publishing system makes it more difficult for research to be held accountable to the public. Paywalls undermine the work of public advocacy, which requires open access in order to lobby for policy changes and research funding. Research participants generously give their time and energy to research studies with the assumption that the results will be broadly disseminated. Finally, members of the public have a stake in open access publishing as a resource for health information and decision-making. This commentary explores these crucial roles of the public in order to develop a public rationale for open access medical research. We outline a critique of the current academic publishing ecosystem, re-focus the open access debate from a public perspective, and respond to some of the arguments against public open access. Although open access to medical research is not a panacea, removing paywalls and other barriers to public access is essential. The public are critical stakeholders of medical research data.},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Research Involvement and Engagement},
	author = {Day, Suzanne and Rennie, Stuart and Luo, Danyang and Tucker, Joseph D.},
	month = dec,
	year = {2020},
	pages = {8},
}

@misc{noauthor_involve_nodate,
	title = {{INVOLVE} – {INVOLVE} {Supporting} public involvement in {NHS}, public health and social care research},
	url = {https://www.invo.org.uk/},
	language = {en-GB},
	urldate = {2021-07-10},
}

@misc{noauthor_closed_nodate,
	title = {Closed access},
	url = {https://casrai.org/term/closed-access/},
	abstract = {Restricting access to Internet content via a paid subscription; is often called a paywall. The subscription business model is a business model where a customer must pay a subscription price to have access to the product/service. The model was pioneered by magazines and newspapers, and is now used by many businesses and websites. Synonyms: Paywall … Continue reading Closed access},
	language = {en-US},
	urldate = {2021-07-10},
	journal = {CASRAI},
}

@misc{noauthor_pci_nodate,
	title = {{PCI} {Registered} {Reports}},
	url = {https://rr.peercommunityin.org/about/about},
	urldate = {2021-07-10},
	journal = {PCI},
}

@misc{noauthor_peer_nodate,
	title = {Peer {Community} {In} – {A} free recommendation process of scientific preprints based on peer-reviews},
	url = {https://peercommunityin.org/},
	language = {en-US},
	urldate = {2021-07-10},
}

@misc{noauthor_plan_nodate,
	title = {'{Plan} {S}' and '{cOAlition} {S}' – {Accelerating} the transition to full and immediate {Open} {Access} to scientific publications},
	url = {https://www.coalition-s.org/},
	abstract = {{\textless}p{\textgreater}About Plan S Plan S is an initiative for Open Access publishing that was launched in September 2018. The plan is supported by cOAlition S, an international consortium of research funding and performing organisations. Plan S requires that, from 2021, scientific publications that result from research funded by public grants must be published in compliant […]{\textless}/p{\textgreater}},
	urldate = {2021-07-10},
}

@article{jafar_what_2018,
	title = {What is positionality and should it be expressed in quantitative studies?},
	issn = {1472-0205, 1472-0213},
	url = {https://emj.bmj.com/lookup/doi/10.1136/emermed-2017-207158},
	doi = {10.1136/emermed-2017-207158},
	language = {en},
	urldate = {2021-07-10},
	journal = {Emergency Medicine Journal},
	author = {Jafar, Anisa J N},
	month = jan,
	year = {2018},
	pages = {emermed--2017--207158},
}

@incollection{rogers_reflexivity_2013,
	title = {reflexivity},
	isbn = {978-0-19-959986-8},
	url = {https://www.oxfordreference.com/view/10.1093/acref/9780199599868.001.0001/acref-9780199599868-e-1530},
	abstract = {"reflexivity" published on  by Oxford University Press....},
	language = {en},
	urldate = {2021-07-10},
	booktitle = {A {Dictionary} of {Human} {Geography}},
	publisher = {Oxford University Press},
	author = {Rogers, Alisdair and Castree, Noel and Kitchin, Rob},
	month = sep,
	year = {2013},
}

@misc{noauthor_bias_nodate,
	title = {{BIAS} {\textbar} {Definition} of {BIAS} by {Oxford} {Dictionary} on {Lexico}.com also meaning of {BIAS}},
	url = {https://www.lexico.com/definition/bias},
	abstract = {What is the definition of BIAS? What is the meaning of BIAS? How do you use BIAS in a sentence? What are synonyms for BIAS?},
	language = {en},
	urldate = {2021-07-10},
	journal = {Lexico Dictionaries {\textbar} English},
}

@article{jacobson_social_2019,
	title = {Social {Identity} {Map}: {A} {Reflexivity} {Tool} for {Practicing} {Explicit} {Positionality} in {Critical} {Qualitative} {Research}},
	volume = {18},
	issn = {1609-4069, 1609-4069},
	shorttitle = {Social {Identity} {Map}},
	url = {http://journals.sagepub.com/doi/10.1177/1609406919870075},
	doi = {10.1177/1609406919870075},
	abstract = {The way that we as researchers view and interpret our social worlds is impacted by where, when, and how we are socially located and in what society. The position from which we see the world around us impacts our research interests, how we approach the research and participants, the questions we ask, and how we interpret the data. In this article, we argue that it is not a straightforward or easy task to conceptualize and practice positionality. We have developed a Social Identity Map that researchers can use to explicitly identify and reflect on their social identity to address the difficulty that many novice critical qualitative researchers experience when trying to conceptualize their social identities and positionality. The Social Identity Map is not meant to be used as a rigid tool but rather as a flexible starting point to guide researchers to reflect and be reflexive about their social location. The map involves three tiers: the identification of social identities (Tier 1), how these positions impact our life (Tier 2), and details that may be tied to the particularities of our social identity (Tier 3). With the use of this map as a guide, we aim for researchers to be able to better identify and understand their social locations and how they may pose challenges and aspects of ease within the qualitative research process. Being explicit about our social identities allows us (as researchers) to produce reflexive research and give our readers the tools to recognize how we produced the data. Being reflexive about our social identities, particularly in comparison to the social position of our participants, helps us better understand the power relations imbued in our research, further providing an opportunity to be reflexive about how to address this in a responsible and respectful way.},
	language = {en},
	urldate = {2021-07-10},
	journal = {International Journal of Qualitative Methods},
	author = {Jacobson, Danielle and Mustafa, Nida},
	month = jan,
	year = {2019},
	pages = {160940691987007},
}

@techreport{ludtke_comparison_2020,
	type = {preprint},
	title = {A {Comparison} of {Penalized} {Maximum} {Likelihood} {Estimation} and {Markov} {Chain} {Monte} {Carlo} {Techniques} for {Estimating} {Confirmatory} {Factor} {Analysis} {Models} with {Small} {Sample} {Sizes}},
	url = {https://osf.io/u3qag},
	abstract = {With small to modest sample sizes and complex models, maximum likelihood (ML) estimation of confirmatory factor analysis (CFA) models can show serious estimation problems such as nonconvergence or parameter estimates that are outside the admissible parameter space. In the present article, we discuss two Bayesian estimation methods for stabilizing parameter estimates of a CFA: Penalized maximum likelihood (PML) estimation and Markov Chain Monte Carlo (MCMC) methods. We clarify that these use different Bayesian point estimates from the joint posterior distribution—the mode (PML) of the joint posterior distribution, and the mean (EAP) or mode (MAP) of the marginal posterior distribution—and discuss under which conditions the two methods produce different results. In a simulation study, we show that the MCMC method clearly outperforms PML and that these performance gains can be explained by the fact that MCMC uses the EAP as a point estimate. We also argue that it is often advantageous to choose a parameterization in which the main parameters of interest are bounded and suggest the four-parameter beta distribution as a prior distribution for loadings and correlations. Using simulated data, we show that selecting weakly informative four-parameter beta priors can further stabilize parameter estimates, even in cases when the priors were mildly misspecified. Finally, we derive recommendations and propose directions for further research.},
	urldate = {2021-07-10},
	institution = {PsyArXiv},
	author = {Lüdtke, Oliver and Ulitzsch, Esther and Robitzsch, Alexander},
	month = oct,
	year = {2020},
	doi = {10.31234/osf.io/u3qag},
}

@misc{crosetto_is_2021,
	title = {Is {MDPI} a predatory publisher?},
	url = {https://paolocrosetto.wordpress.com/2021/04/12/is-mdpi-a-predatory-publisher/},
	abstract = {Edit April 20th, 2021: thanks to Christos Petrou I found a bug in my code. I was considering both “Section” and “Collection” articles as Speical Issue. The whole analysis ha…},
	language = {en},
	urldate = {2021-07-10},
	journal = {Paolo Crosetto},
	author = {Crosetto, Paolo},
	month = apr,
	year = {2021},
}

@article{xia_who_2015,
	title = {Who publishes in “predatory” journals?},
	volume = {66},
	issn = {23301635},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/asi.23265},
	doi = {10.1002/asi.23265},
	language = {en},
	number = {7},
	urldate = {2021-07-10},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Xia, Jingfeng and Harmon, Jennifer L. and Connolly, Kevin G. and Donnelly, Ryan M. and Anderson, Mary R. and Howard, Heather A.},
	month = jul,
	year = {2015},
	pages = {1406--1417},
}

@article{smith_prepare_2018,
	title = {{PREPARE}: guidelines for planning animal research and testing},
	volume = {52},
	issn = {0023-6772, 1758-1117},
	shorttitle = {{PREPARE}},
	url = {http://journals.sagepub.com/doi/10.1177/0023677217724823},
	doi = {10.1177/0023677217724823},
	abstract = {There is widespread concern about the quality, reproducibility and translatability of studies involving research animals. Although there are a number of reporting guidelines available, there is very little overarching guidance on how to plan animal experiments, despite the fact that this is the logical place to start ensuring quality. In this paper we present the PREPARE guidelines: Planning Research and Experimental Procedures on Animals: Recommendations for Excellence. PREPARE covers the three broad areas which determine the quality of the preparation for animal studies: formulation, dialogue between scientists and the animal facility, and quality control of the various components in the study. Some topics overlap and the PREPARE checklist should be adapted to suit specific needs, for example in field research. Advice on use of the checklist is available on the Norecopa website, with links to guidelines for animal research and testing, at https://norecopa.no/PREPARE .},
	language = {en},
	number = {2},
	urldate = {2021-07-10},
	journal = {Laboratory Animals},
	author = {Smith, Adrian J and Clutton, R Eddie and Lilley, Elliot and Hansen, Kristine E Aa and Brattelid, Trond},
	month = apr,
	year = {2018},
	pages = {135--141},
}

@article{bourne_ten_2017,
	title = {Ten simple rules to consider regarding preprint submission},
	volume = {13},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1005473},
	doi = {10.1371/journal.pcbi.1005473},
	language = {en},
	number = {5},
	urldate = {2021-07-10},
	journal = {PLOS Computational Biology},
	author = {Bourne, Philip E. and Polka, Jessica K. and Vale, Ronald D. and Kiley, Robert},
	month = may,
	year = {2017},
	pages = {e1005473},
}

@article{lewandowsky_research_2016,
	title = {Research integrity: {Don}'t let transparency damage science},
	volume = {529},
	issn = {0028-0836, 1476-4687},
	shorttitle = {Research integrity},
	url = {http://www.nature.com/articles/529459a},
	doi = {10.1038/529459a},
	language = {en},
	number = {7587},
	urldate = {2021-07-10},
	journal = {Nature},
	author = {Lewandowsky, Stephan and Bishop, Dorothy},
	month = jan,
	year = {2016},
	pages = {459--461},
}

@article{l_haven_preregistering_2019,
	title = {Preregistering qualitative research},
	volume = {26},
	issn = {0898-9621, 1545-5815},
	url = {https://www.tandfonline.com/doi/full/10.1080/08989621.2019.1580147},
	doi = {10.1080/08989621.2019.1580147},
	language = {en},
	number = {3},
	urldate = {2021-07-10},
	journal = {Accountability in Research},
	author = {L. Haven, Tamarinde and Van Grootel, Dr. Leonie},
	month = apr,
	year = {2019},
	pages = {229--244},
}

@article{elmore_preprints_2018,
	title = {Preprints: {What} {Role} {Do} {These} {Have} in {Communicating} {Scientific} {Results}?},
	volume = {46},
	issn = {0192-6233, 1533-1601},
	shorttitle = {Preprints},
	url = {http://journals.sagepub.com/doi/10.1177/0192623318767322},
	doi = {10.1177/0192623318767322},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {Toxicologic Pathology},
	author = {Elmore, Susan A.},
	month = jun,
	year = {2018},
	pages = {364--365},
}

@article{mertens_preregistration_2019,
	title = {Preregistration of {Analyses} of {Preexisting} {Data}},
	volume = {59},
	issn = {2054-670X},
	url = {http://www.psychologicabelgica.com/articles/10.5334/pb.493/},
	doi = {10.5334/pb.493},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Psychologica Belgica},
	author = {Mertens, Gaëtan and Krypotos, Angelos-Miltiadis},
	month = aug,
	year = {2019},
	pages = {338--352},
}

@article{simmons_preregistration_2021,
	title = {Pre‐registration: {Why} and {How}},
	volume = {31},
	issn = {1057-7408, 1532-7663},
	shorttitle = {Pre‐registration},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/jcpy.1208},
	doi = {10.1002/jcpy.1208},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Journal of Consumer Psychology},
	author = {Simmons, Joseph and Nelson, Leif and Simonsohn, Uri},
	month = jan,
	year = {2021},
	pages = {151--162},
}

@misc{noauthor_preregistration_nodate,
	title = {Preregistration pledge},
	url = {https://docs.google.com/forms/d/e/1FAIpQLSf8RflGizFJZamE874o8aDOhyU7UsNByR4dLmzhOtEOiu8KRQ/viewform?embedded=true&usp=embed_facebook},
	abstract = {"I pledge to preregister at least one study within 2 years of the time that 100 researchers in my field have joined this campaign"},
	language = {en},
	urldate = {2021-07-10},
	journal = {Google Docs},
}

@techreport{navarro_paths_2020,
	type = {preprint},
	title = {Paths in strange spaces: {A} comment on preregistration},
	shorttitle = {Paths in strange spaces},
	url = {https://osf.io/wxn58},
	abstract = {This is an archived version of a blog post on preregistration. The first half of the post argues that there is not a strong justification for preregistration as a tool to solve problems with statistical inference (p-hacking); the second half argues that preregistration has a stronger justification as one tool (among many) that can aid scientists in documenting our projects. [Note that this archival version exists only because the blog itself no longer does, and as the original has been cited multiple times there is value in ensuring that some version of the blog post remains accessible.]},
	urldate = {2021-07-10},
	institution = {PsyArXiv},
	author = {Navarro, Danielle},
	month = sep,
	year = {2020},
	doi = {10.31234/osf.io/wxn58},
}

@article{morey_peer_2016,
	title = {The {Peer} {Reviewers}' {Openness} {Initiative}: incentivizing open research practices through peer review},
	volume = {3},
	issn = {2054-5703},
	shorttitle = {The {Peer} {Reviewers}' {Openness} {Initiative}},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.150547},
	doi = {10.1098/rsos.150547},
	abstract = {Openness is one of the central values of science. Open scientific practices such as sharing data, materials and analysis scripts alongside published articles have many benefits, including easier replication and extension studies, increased availability of data for theory-building and meta-analysis, and increased possibility of review and collaboration even after a paper has been published. Although modern information technology makes sharing easier than ever before, uptake of open practices had been slow. We suggest this might be in part due to a social dilemma arising from misaligned incentives and propose a specific, concrete mechanism—reviewers withholding comprehensive review—to achieve the goal of creating the expectation of open practices as a matter of scientific principle.},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Royal Society Open Science},
	author = {Morey, Richard D. and Chambers, Christopher D. and Etchells, Peter J. and Harris, Christine R. and Hoekstra, Rink and Lakens, Daniël and Lewandowsky, Stephan and Morey, Candice Coker and Newman, Daniel P. and Schönbrodt, Felix D. and Vanpaemel, Wolf and Wagenmakers, Eric-Jan and Zwaan, Rolf A.},
	month = jan,
	year = {2016},
	pages = {150547},
}

@article{mourby_are_2018,
	title = {Are ‘pseudonymised’ data always personal data? {Implications} of the {GDPR} for administrative data research in the {UK}},
	volume = {34},
	issn = {02673649},
	shorttitle = {Are ‘pseudonymised’ data always personal data?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0267364918300153},
	doi = {10.1016/j.clsr.2018.01.002},
	language = {en},
	number = {2},
	urldate = {2021-07-10},
	journal = {Computer Law \& Security Review},
	author = {Mourby, Miranda and Mackey, Elaine and Elliot, Mark and Gowans, Heather and Wallace, Susan E. and Bell, Jessica and Smith, Hannah and Aidinlis, Stergios and Kaye, Jane},
	month = apr,
	year = {2018},
	pages = {222--233},
}

@article{hurlbert_pseudoreplication_1984,
	title = {Pseudoreplication and the {Design} of {Ecological} {Field} {Experiments}},
	volume = {54},
	issn = {0012-9615, 1557-7015},
	url = {https://onlinelibrary.wiley.com/doi/10.2307/1942661},
	doi = {10.2307/1942661},
	language = {en},
	number = {2},
	urldate = {2021-07-10},
	journal = {Ecological Monographs},
	author = {Hurlbert, Stuart H.},
	month = jun,
	year = {1984},
	pages = {187--211},
}

@article{davies_dont_2015,
	title = {Don't let spurious accusations of pseudoreplication limit our ability to learn from natural experiments (and other messy kinds of ecological monitoring)},
	volume = {5},
	issn = {20457758},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/ece3.1782},
	doi = {10.1002/ece3.1782},
	language = {en},
	number = {22},
	urldate = {2021-07-10},
	journal = {Ecology and Evolution},
	author = {Davies, G. Matt and Gray, Alan},
	month = nov,
	year = {2015},
	pages = {5295--5304},
}

@misc{lazic_genuine_2019,
	title = {Genuine replication and pseudoreplication: what's the difference? {\textbar} {BMJ} {Open} {Science}},
	url = {https://blogs.bmj.com/openscience/2019/09/16/genuine-replication-and-pseudoreplication-whats-the-difference/},
	urldate = {2021-07-10},
	journal = {BMJ Open Science},
	author = {Lazic, Stanley E.},
	month = sep,
	year = {2019},
}

@book{hunter_methods_2015,
	address = {Thousand Oaks, California},
	edition = {Third edition},
	title = {Methods of meta-analysis: correcting error and bias in research findings},
	isbn = {978-1-4522-8689-1},
	shorttitle = {Methods of meta-analysis},
	publisher = {SAGE},
	author = {Hunter, John E. and Schmidt, Frank L.},
	year = {2015},
	keywords = {Meta-analysis, Social sciences, Statistical methods},
}

@article{dickersin_publication_1993,
	title = {Publication {Bias}: {The} {Problem} {That} {Won}'t {Go} {Away}},
	volume = {703},
	issn = {0077-8923, 1749-6632},
	shorttitle = {Publication {Bias}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1749-6632.1993.tb26343.x},
	doi = {10.1111/j.1749-6632.1993.tb26343.x},
	language = {en},
	number = {1 Doing More Go},
	urldate = {2021-07-10},
	journal = {Annals of the New York Academy of Sciences},
	author = {Dickersin, Kay and Min, Yuan-I},
	month = dec,
	year = {1993},
	pages = {135--148},
}

@misc{noauthor_publication_2019,
	title = {Publication bias},
	url = {https://catalogofbias.org/biases/publication-bias/},
	abstract = {Publication bias refers to the likelihood of a study being published based on the findings of the study},
	language = {en},
	urldate = {2021-07-10},
	journal = {Catalog of Bias},
	month = may,
	year = {2019},
}

@article{lindsay_replication_2015,
	title = {Replication in {Psychological} {Science}},
	volume = {26},
	issn = {0956-7976, 1467-9280},
	url = {http://journals.sagepub.com/doi/10.1177/0956797615616374},
	doi = {10.1177/0956797615616374},
	language = {en},
	number = {12},
	urldate = {2021-07-10},
	journal = {Psychological Science},
	author = {Lindsay, D. Stephen},
	month = dec,
	year = {2015},
	pages = {1827--1832},
}

@article{franco_publication_2014,
	title = {Publication bias in the social sciences: {Unlocking} the file drawer},
	volume = {345},
	issn = {0036-8075, 1095-9203},
	shorttitle = {Publication bias in the social sciences},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.1255484},
	doi = {10.1126/science.1255484},
	language = {en},
	number = {6203},
	urldate = {2021-07-10},
	journal = {Science},
	author = {Franco, A. and Malhotra, N. and Simonovits, G.},
	month = sep,
	year = {2014},
	pages = {1502--1505},
}

@article{duval_trim_2000,
	title = {Trim and {Fill}: {A} {Simple} {Funnel}-{Plot}-{Based} {Method} of {Testing} and {Adjusting} for {Publication} {Bias} in {Meta}-{Analysis}},
	volume = {56},
	issn = {0006341X},
	shorttitle = {Trim and {Fill}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.0006-341X.2000.00455.x},
	doi = {10.1111/j.0006-341X.2000.00455.x},
	language = {en},
	number = {2},
	urldate = {2021-07-10},
	journal = {Biometrics},
	author = {Duval, Sue and Tweedie, Richard},
	month = jun,
	year = {2000},
	pages = {455--463},
}

@article{duval_nonparametric_2000,
	title = {A {Nonparametric} "{Trim} and {Fill}" {Method} of {Accounting} for {Publication} {Bias} in {Meta}-{Analysis}},
	volume = {95},
	issn = {01621459},
	url = {https://www.jstor.org/stable/2669529?origin=crossref},
	doi = {10.2307/2669529},
	number = {449},
	urldate = {2021-07-10},
	journal = {Journal of the American Statistical Association},
	author = {Duval, Sue and Tweedie, Richard},
	month = mar,
	year = {2000},
	pages = {89},
}

@article{lindsay_seven_2020,
	title = {Seven steps toward transparency and replicability in psychological science.},
	volume = {61},
	issn = {1878-7304, 0708-5591},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/cap0000222},
	doi = {10.1037/cap0000222},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {Canadian Psychology/Psychologie canadienne},
	author = {Lindsay, D. Stephen},
	month = nov,
	year = {2020},
	pages = {310--317},
}

@incollection{rothstein_publication_2006,
	address = {Chichester, UK},
	title = {Publication {Bias} in {Meta}-{Analysis}},
	isbn = {978-0-470-87016-7 978-0-470-87014-3},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/0470870168.ch1},
	urldate = {2021-07-10},
	booktitle = {Publication {Bias} in {Meta}-{Analysis}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Rothstein, Hannah R. and Sutton, Alexander J. and Borenstein, Michael},
	editor = {Rothstein, Hannah R. and Sutton, Alexander J. and Borenstein, Michael},
	month = mar,
	year = {2006},
	doi = {10.1002/0470870168.ch1},
	pages = {1--7},
}

@incollection{blobaum_trust_2016,
	address = {Cham},
	title = {Trust in {Science} and the {Science} of {Trust}},
	isbn = {978-3-319-28057-8 978-3-319-28059-2},
	url = {http://link.springer.com/10.1007/978-3-319-28059-2_8},
	urldate = {2021-07-10},
	booktitle = {Trust and {Communication} in a {Digitized} {World}},
	publisher = {Springer International Publishing},
	author = {Hendriks, Friederike and Kienhues, Dorothe and Bromme, Rainer},
	editor = {Blöbaum, Bernd},
	year = {2016},
	doi = {10.1007/978-3-319-28059-2_8},
	note = {Series Title: Progress in IS},
	pages = {143--159},
}

@article{huber_fostering_2019,
	title = {Fostering public trust in science: {The} role of social media},
	volume = {28},
	issn = {0963-6625, 1361-6609},
	shorttitle = {Fostering public trust in science},
	url = {http://journals.sagepub.com/doi/10.1177/0963662519869097},
	doi = {10.1177/0963662519869097},
	abstract = {The growing importance of social media for getting science news has raised questions about whether these online platforms foster or hinder public trust in science. Employing multilevel modeling, this study leverages a 20-country survey to examine the relationship between social media news use and trust in science. Results show a positive relationship between these variables across countries. Moreover, the between-country variation in this relationship is related to two cultural characteristics of a country, individualism/collectivism and power distance.},
	language = {en},
	number = {7},
	urldate = {2021-07-10},
	journal = {Public Understanding of Science},
	author = {Huber, Brigitte and Barnidge, Matthew and Gil de Zúñiga, Homero and Liu, James},
	month = oct,
	year = {2019},
	keywords = {comparative research, cross-cultural indicators, Hofstede, science communication, social media, trust in science},
	pages = {759--777},
}

@article{wingen_no_2020,
	title = {No {Replication}, {No} {Trust}? {How} {Low} {Replicability} {Influences} {Trust} in {Psychology}},
	volume = {11},
	issn = {1948-5506, 1948-5514},
	shorttitle = {No {Replication}, {No} {Trust}?},
	url = {http://journals.sagepub.com/doi/10.1177/1948550619877412},
	doi = {10.1177/1948550619877412},
	abstract = {In the current psychological debate, low replicability of psychological findings is a central topic. While the discussion about the replication crisis has a huge impact on psychological research, we know less about how it impacts public trust in psychology. In this article, we examine whether low replicability damages public trust and how this damage can be repaired. Studies 1–3 provide correlational and experimental evidence that low replicability reduces public trust in psychology. Additionally, Studies 3–5 evaluate the effectiveness of commonly used trust-repair strategies such as information about increased transparency (Study 3), explanations for low replicability (Study 4), or recovered replicability (Study 5). We found no evidence that these strategies significantly repair trust. However, it remains possible that they have small but potentially meaningful effects, which could be detected with larger samples. Overall, our studies highlight the importance of replicability for public trust in psychology.},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {Social Psychological and Personality Science},
	author = {Wingen, Tobias and Berkessel, Jana B. and Englich, Birte},
	month = may,
	year = {2020},
	pages = {454--463},
}

@article{schneider_rebuilding_2020,
	title = {({Re}){Building} {Trust}? {Investigating} the effects of open science badges on perceived trustworthiness in journal articles.},
	copyright = {CC-By Attribution 4.0 International},
	shorttitle = {({Re}){Building} {Trust}?},
	url = {https://osf.io/vgbrs/},
	doi = {10.17605/OSF.IO/VGBRS},
	abstract = {The Replication Crisis diminishes trust in empirical sciences and with it the perceived value of science (Lupia, 2018). Open Science Practices (i.a. open data, open analysis script, open materials) are an increasingly popular approach to deal with challenges in replication and to rebuilt trust (Geukes, Schönbrodt, Utesch, Geukes, \&amp; Back, 2016). First investigations could, however, deliver no evidence toward the effects of Open Science Practices (OSP) on trustworthiness (Wingen, Berkessel, \&amp; Englich, 2019). The study investigated the effect on a discipline level (psychology) with an abstract description of OSP. Within the ongoing discussion about incentives for OSP (e.g. badges), we want to shift the focus from discipline level to concrete individual journal articles and consider epistemic beliefs of readers to play a moderating role (Merk \&amp; Rosman, 2018): Will visible OSP (vs. not visible vs. visibly non-OSP) foster perceived trustworthiness when reading journal articles of empirical studies? Will multiplistic epistemic beliefs moderate the relationship between OSP and trustworthiness? The design will include three conditions: visible Open Science Practices (visOSP), Practices not visible (nonvis) and visible non-Open Science Practices (nonOSP). Two of the conditions are randomized within person. Realizing all three conditions within person would highlight the variation between conditions as too obvious and thus undermine blinding of subjects. visOSP condition: Subjects receive a title page of an empirical study (Title, Abstract, Keywords, Introduction, ...) together with three Open Science badges. The badges are explained using hints in style of speech bubbles and indicate that the authors engaged in the OSP open data, open analysis script and open materials. nonvis condition: Subjects receive a title page of an empirical study (Title, Abstract, Keywords, Introduction, ...) with no further information on Open Science, reflecting a "standard" journal article. nonOSP condition: Subjects receive a title page of an empirical study (Title, Abstract, Keywords, Introduction, ...) together with three Open Science badges. The badges are explained using hints in style of speech bubbles and indicate that the authors did not engage in the OSP open data, open analysis script and open materials. As participants are exposed to more than one condition, we create all three conditions for three different empirical studies (topics). This way we avoid participants to see one study topic twice under different conditions, which would undermine the blinding. Measured variables are perceives trustworthiness: We apply the Muenster Epistemic Trustworthiness Inventory (Hendriks, Kienhues, \&amp; Bromme, 2015) with all three subscales. However, as dependent variable we will only employ the subscale integrity. The other two subscales are used for further exploratory analyses. Topic-specific multiplism: We apply the subscale of topic specific multiplism from Merk et al. (2017) Topic-specific consistency: We apply the three item-measure from Merk et al. (2017), Treatment check: We test the perceived openness/ transparency of the empirical study. Additional small set of demographic variables will be assessed.},
	urldate = {2021-07-10},
	author = {Schneider, Jürgen and Merk, Samuel and Rosman, Tom},
	year = {2020},
	note = {Publisher: Open Science Framework},
}

@article{fanelli_opinion_2018,
	title = {Opinion: {Is} science really facing a reproducibility crisis, and do we need it to?},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Opinion},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1708272114},
	doi = {10.1073/pnas.1708272114},
	abstract = {Efforts to improve the reproducibility and integrity of science are typically justified by a narrative of crisis, according to which most published results are unreliable due to growing problems with research and publication practices. This article provides an overview of recent evidence suggesting that this narrative is mistaken, and argues that a narrative of epochal changes and empowerment of scientists would be more accurate, inspiring, and compelling.},
	language = {en},
	number = {11},
	urldate = {2021-07-10},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Fanelli, Daniele},
	month = mar,
	year = {2018},
	pages = {2628--2631},
}

@article{fanelli_pressures_2010,
	title = {Do {Pressures} to {Publish} {Increase} {Scientists}' {Bias}? {An} {Empirical} {Support} from {US} {States} {Data}},
	volume = {5},
	issn = {1932-6203},
	shorttitle = {Do {Pressures} to {Publish} {Increase} {Scientists}' {Bias}?},
	url = {https://dx.plos.org/10.1371/journal.pone.0010271},
	doi = {10.1371/journal.pone.0010271},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {PLoS ONE},
	author = {Fanelli, Daniele},
	editor = {Scalas, Enrico},
	month = apr,
	year = {2010},
	pages = {e10271},
}

@misc{noauthor_pubpeer_nodate,
	title = {{PubPeer} - {Search} publications and join the conversation.},
	url = {https://www.pubpeer.com/},
	urldate = {2021-07-10},
	journal = {Pubpeer},
}

@book{lutz_programming_2019,
	address = {Beijing Boston Farnham Sebastopol Tokyo},
	edition = {Fourth edition},
	title = {Programming {Python}},
	isbn = {978-0-596-15810-1},
	language = {eng},
	publisher = {O'Reilly},
	author = {Lutz, Mark},
	year = {2019},
}

@article{brunner_estimating_2020,
	title = {Estimating {Population} {Mean} {Power} {Under} {Conditions} of {Heterogeneity} and {Selection} for {Significance}},
	volume = {4},
	issn = {2003-2714},
	url = {https://open.lnu.se/index.php/metapsychology/article/view/874},
	doi = {10.15626/MP.2018.874},
	abstract = {In scientific fields that use significance tests, statistical power is important for successful replications of significant results because it is the long-run success rate in a series of exact replication studies. For any population of significant results, there is a population of power values of the statistical tests on which conclusions are based. We give exact theoretical results showing how selection for significance affects the distribution of statistical power in a heterogeneous population of significance tests. In a set of large-scale simulation studies, we compare four methods for estimating population mean power of a set of studies selected for significance (a maximum likelihood model, extensions of p-curve and p-uniform, \& z-curve). The p-uniform and p-curve methods performed well with a fixed effects size and varying sample sizes. However, when there was substantial variability in effect sizes as well as sample sizes, both methods systematically overestimate mean power. With heterogeneity in effect sizes, the maximum likelihood model produced the most accurate estimates when the distribution of effect sizes matched the assumptions of the model, but z-curve produced more accurate estimates when the assumptions of the maximum likelihood model were not met. We recommend the use of z-curve to estimate the typical power of significant results, which has implications for the replicability of significant results in psychology journals.},
	urldate = {2021-07-10},
	journal = {Meta-Psychology},
	author = {Brunner, Jerry and Schimmack, Ulrich},
	month = may,
	year = {2020},
}

@techreport{bartos_z-curve20_2020,
	type = {preprint},
	title = {Z-{Curve}.2.0: {Estimating} {Replication} {Rates} and {Discovery} {Rates}},
	shorttitle = {Z-{Curve}.2.0},
	url = {https://osf.io/urgtn},
	abstract = {This article introduces z-curve.2.0 as a method that estimates the expected replication rate (ERR) and the expected discovery rate (EDR) based on the test-statistics of studies selected for significance. Z-curve.2.0 extends the work by Brunner and Schimmack (2019) in several ways. First, we show that a new estimation method using expectation-maximization outperforms the kernel-density approach of z-curve.1.0. Second, we examine the coverage of bootstrapped confidence intervals to provide information about the uncertainty in z-curve estimates. Third, we extended z-curve to estimate the number of all studies that were conducted, including studies with non-significant results that may not have been reported, solely on the basis of significant results. This allows us to estimate the EDR; that is, the percentage of significant results that were obtained in all studies. EDR can be used to assess the size of the file-drawer, estimate the maximum number of false positive results, and may provide a better estimate of the success rate in actual replication studies than the ERR because exact replications are impossible.},
	urldate = {2021-07-10},
	institution = {PsyArXiv},
	author = {Bartoš, František and Schimmack, Ulrich},
	month = jan,
	year = {2020},
	doi = {10.31234/osf.io/urgtn},
}

@misc{noauthor_zenodo_nodate,
	title = {Zenodo - {Research}. {Shared}.},
	url = {https://www.zenodo.org/},
	urldate = {2021-07-10},
	journal = {Zenodo},
}

@article{case_scholarship_1928,
	title = {Scholarship in sociology},
	volume = {12},
	journal = {Sociology and Social Research},
	author = {Case, C.M.},
	year = {1928},
	pages = {323--340},
}

@techreport{brown_introduction_2010,
	address = {United Kingdom},
	title = {An introduction to overlay journals},
	abstract = {An overlay journal performs all the activities of a scholarly journal and relies on structural links with one or more archives or repositories to perform its activities. This paper offers a briefing on the contribution overlay journals can make to scholarly communication. It explains what ‘overlay’ services are, how overlay journals have evolved and what makes their contribution to scholarly communication so valuable.},
	institution = {University College London},
	author = {Brown, J.},
	year = {2010},
	pages = {1--6},
}

@article{blohowiak_badges_2013,
	title = {Badges to {Acknowledge} {Open} {Practices}},
	url = {https://osf.io/tvyxz/},
	abstract = {The aim is to specify a standard by which we can say that a scientific study has been conducted in accordance with open-science principles and provide visual icons to allow advertising of such good behaviours. 
    Hosted on the Open Science Framework},
	language = {en},
	urldate = {2021-07-10},
	author = {Blohowiak, Ben B. and Cohoon, Johanna and de-Wit, Lee and Eich, Eric and Farach, Frank J. and Hasselman, Fred and Holcombe, Alex O. and Humphreys, Macartan and Lewis, Melissa and Nosek, Brian A.},
	month = feb,
	year = {2013},
	note = {Publisher: OSF},
}

@misc{noauthor_open_nodate-3,
	title = {Open {Source} in {Open} {Science} {\textbar} {FOSTER}},
	url = {https://www.fosteropenscience.eu/foster-taxonomy/open-source-open-science},
	urldate = {2021-07-09},
	journal = {Foster},
}

@article{bjorneborn_toward_2004,
	title = {Toward a basic framework for webometrics},
	volume = {55},
	issn = {1532-2882, 1532-2890},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/asi.20077},
	doi = {10.1002/asi.20077},
	language = {en},
	number = {14},
	urldate = {2021-07-10},
	journal = {Journal of the American Society for Information Science and Technology},
	author = {Björneborn, Lennart and Ingwersen, Peter},
	month = dec,
	year = {2004},
	pages = {1216--1227},
}

@article{henrich_weirdest_2010,
	title = {The weirdest people in the world?},
	volume = {33},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X0999152X/type/journal_article},
	doi = {10.1017/S0140525X0999152X},
	abstract = {Abstract
            
              Behavioral scientists routinely publish broad claims about human psychology and behavior in the world's top journals based on samples drawn entirely from Western, Educated, Industrialized, Rich, and Democratic (WEIRD) societies. Researchers – often implicitly – assume that either there is little variation across human populations, or that these “standard subjects” are as representative of the species as any other population. Are these assumptions justified? Here, our review of the comparative database from across the behavioral sciences suggests both that there is substantial variability in experimental results across populations and that WEIRD subjects are particularly unusual compared with the rest of the species – frequent outliers. The domains reviewed include visual perception, fairness, cooperation, spatial reasoning, categorization and inferential induction, moral reasoning, reasoning styles, self-concepts and related motivations, and the heritability of IQ. The findings suggest that members of WEIRD societies, including young children, are among the least representative populations one could find for generalizing about humans. Many of these findings involve domains that are associated with fundamental aspects of psychology, motivation, and behavior – hence, there are no obvious
              a priori
              grounds for claiming that a particular behavioral phenomenon is universal based on sampling from a single subpopulation. Overall, these empirical patterns suggests that we need to be less cavalier in addressing questions of
              human
              nature on the basis of data drawn from this particularly thin, and rather unusual, slice of humanity. We close by proposing ways to structurally re-organize the behavioral sciences to best tackle these challenges.},
	language = {en},
	number = {2-3},
	urldate = {2021-07-10},
	journal = {Behavioral and Brain Sciences},
	author = {Henrich, Joseph and Heine, Steven J. and Norenzayan, Ara},
	month = jun,
	year = {2010},
	pages = {61--83},
}

@book{henrich_weirdest_2020,
	address = {New York},
	title = {The {WEIRDest} people in the world: {How} the {West} {Became} {Psychologically} {Peculiar} and {Particularly} {Prosperous}},
	isbn = {978-0-374-17322-7},
	shorttitle = {The {WEIRDest} people in the world},
	abstract = {"Harvard University's Joseph Henrich, Chair of the Department of Human Evolutionary Biology, delivers a bold, epic investigation into the development of the Western mind, global psychological diversity, and its impact on the world"--},
	publisher = {Farrar, Straus and Giroux},
	author = {Henrich, Joseph Patrick},
	year = {2020},
	keywords = {Cognitive psychology, Developmental psychology, Human evolution, Social interaction},
}

@article{muthukrishna_beyond_2020,
	title = {Beyond {Western}, {Educated}, {Industrial}, {Rich}, and {Democratic} ({WEIRD}) {Psychology}: {Measuring} and {Mapping} {Scales} of {Cultural} and {Psychological} {Distance}},
	volume = {31},
	issn = {0956-7976, 1467-9280},
	shorttitle = {Beyond {Western}, {Educated}, {Industrial}, {Rich}, and {Democratic} ({WEIRD}) {Psychology}},
	url = {http://journals.sagepub.com/doi/10.1177/0956797620916782},
	doi = {10.1177/0956797620916782},
	abstract = {In this article, we present a tool and a method for measuring the psychological and cultural distance between societies and creating a distance scale with any population as the point of comparison. Because psychological data are dominated by samples drawn from Western, educated, industrialized, rich, and democratic (WEIRD) nations, and overwhelmingly, the United States, we focused on distance from the United States. We also present distance from China, the country with the largest population and second largest economy, which is a common cultural comparison. We applied the fixation index ( F
              ST
              ), a meaningful statistic in evolutionary theory, to the World Values Survey of cultural beliefs and behaviors. As the extreme WEIRDness of the literature begins to dissolve, our tool will become more useful for designing, planning, and justifying a wide range of comparative psychological projects. Our code and accompanying online application allow for comparisons between any two countries. Analyses of regional diversity reveal the relative homogeneity of the United States. Cultural distance predicts various psychological outcomes.},
	language = {en},
	number = {6},
	urldate = {2021-07-10},
	journal = {Psychological Science},
	author = {Muthukrishna, Michael and Bell, Adrian V. and Henrich, Joseph and Curtin, Cameron M. and Gedranovich, Alexander and McInerney, Jason and Thue, Braden},
	month = jun,
	year = {2020},
	pages = {678--701},
}

@article{borsboom_concept_2004,
	title = {The {Concept} of {Validity}.},
	volume = {111},
	issn = {1939-1471, 0033-295X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.111.4.1061},
	doi = {10.1037/0033-295X.111.4.1061},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {Psychological Review},
	author = {Borsboom, Denny and Mellenbergh, Gideon J. and van Heerden, Jaap},
	year = {2004},
	pages = {1061--1071},
}

@misc{noauthor_git_nodate,
	title = {Git - {About} {Version} {Control}},
	url = {https://git-scm.com/book/en/v2/Getting-Started-About-Version-Control},
	urldate = {2021-07-10},
	journal = {git},
}

@book{kelley_interpretation_1927,
	address = {Yonkers, New York},
	title = {Interpretation of educational measurements},
	abstract = {Among the outstanding contributions of the book are (1) the judgments of the relative excellence of assorted tests in some 70 fields of accomplishment, by Kelley, Franzen, Freeman, McCall, Otis, Trabue and Van Wagenen; (2) detailed and exact information on the statistical and other characteristics of the same tests, based on a questionnaire addressed to the text authors or (in the absence of reply) estimates by Kelley on the best data available; (3) a chapter of 47 pages condensing all the principal elementary statistical methods. In addition, there is constant emphasis upon the importance of the probable error, with some illustrative applications; for example, it is maintained that about 90\% of the abilities measured by our best "intelligence" and "achievement" tests are (due chiefly to the size of the probable errors) the same ability. A chapter sets forth the analytical procedures which lead to this conclusion and to four others earlier enunciated. "Idiosyncrasy," or inequality among abilities, which the author regards as highly valuable, is considered in two chapters; the remainder of the volume is devoted to a historical sketch of the mental test movement and a statement of the purposes of tests, the latter being illustrated by appropriate chapters},
	publisher = {World Book Co},
	author = {Kelley, TL},
	year = {1927},
}

@article{rose_universal_2000,
	title = {Universal {Design} for {Learning}},
	volume = {15},
	issn = {0162-6434, 2381-3121},
	url = {http://journals.sagepub.com/doi/10.1177/016264340001500307},
	doi = {10.1177/016264340001500307},
	language = {en},
	number = {3},
	urldate = {2021-07-10},
	journal = {Journal of Special Education Technology},
	author = {Rose, David},
	month = jun,
	year = {2000},
	pages = {45--49},
}

@book{rose_teaching_2002,
	address = {Alexandria, Va},
	title = {Teaching every student in the {Digital} {Age}: universal design for learning},
	isbn = {978-0-87120-599-5},
	shorttitle = {Teaching every student in the {Digital} {Age}},
	publisher = {Association for Supervision and Curriculum Development},
	author = {Rose, David H. and Meyer, Anne},
	year = {2002},
	keywords = {Education, Children with disabilities, Cognitive styles, Educational technology, Individualized instruction},
}

@article{hitchcock_providing_2002,
	title = {Providing {New} {Access} to the {General} {Curriculum}: {Universal} {Design} for {Learning}},
	volume = {35},
	issn = {0040-0599, 2163-5684},
	shorttitle = {Providing {New} {Access} to the {General} {Curriculum}},
	url = {http://journals.sagepub.com/doi/10.1177/004005990203500201},
	doi = {10.1177/004005990203500201},
	language = {en},
	number = {2},
	urldate = {2021-07-10},
	journal = {TEACHING Exceptional Children},
	author = {Hitchcock, Chuck and Meyer, Anne and Rose, David and Jackson, Richard},
	month = nov,
	year = {2002},
	pages = {8--17},
}

@article{flake_measurement_2020,
	title = {Measurement {Schmeasurement}: {Questionable} {Measurement} {Practices} and {How} to {Avoid} {Them}},
	volume = {3},
	issn = {2515-2459, 2515-2467},
	shorttitle = {Measurement {Schmeasurement}},
	url = {http://journals.sagepub.com/doi/10.1177/2515245920952393},
	doi = {10.1177/2515245920952393},
	abstract = {In this article, we define questionable measurement practices (QMPs) as decisions researchers make that raise doubts about the validity of the measures, and ultimately the validity of study conclusions. Doubts arise for a host of reasons, including a lack of transparency, ignorance, negligence, or misrepresentation of the evidence. We describe the scope of the problem and focus on how transparency is a part of the solution. A lack of measurement transparency makes it impossible to evaluate potential threats to internal, external, statistical-conclusion, and construct validity. We demonstrate that psychology is plagued by a measurement schmeasurement attitude: QMPs are common, hide a stunning source of researcher degrees of freedom, and pose a serious threat to cumulative psychological science, but are largely ignored. We address these challenges by providing a set of questions that researchers and consumers of scientific research can consider to identify and avoid QMPs. Transparent answers to these measurement questions promote rigorous research, allow for thorough evaluations of a study’s inferences, and are necessary for meaningful replication studies.},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Flake, Jessica Kay and Fried, Eiko I.},
	month = dec,
	year = {2020},
	pages = {456--465},
}

@article{sijtsma_playing_2016,
	title = {Playing with {Data}—{Or} {How} to {Discourage} {Questionable} {Research} {Practices} and {Stimulate} {Researchers} to {Do} {Things} {Right}},
	volume = {81},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/10.1007/s11336-015-9446-0},
	doi = {10.1007/s11336-015-9446-0},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Psychometrika},
	author = {Sijtsma, Klaas},
	month = mar,
	year = {2016},
	pages = {1--15},
}

@article{john_measuring_2012,
	title = {Measuring the {Prevalence} of {Questionable} {Research} {Practices} {With} {Incentives} for {Truth} {Telling}},
	volume = {23},
	issn = {0956-7976, 1467-9280},
	url = {http://journals.sagepub.com/doi/10.1177/0956797611430953},
	doi = {10.1177/0956797611430953},
	abstract = {Cases of clear scientific misconduct have received significant media attention recently, but less flagrantly questionable research practices may be more prevalent and, ultimately, more damaging to the academic enterprise. Using an anonymous elicitation format supplemented by incentives for honest reporting, we surveyed over 2,000 psychologists about their involvement in questionable research practices. The impact of truth-telling incentives on self-admissions of questionable research practices was positive, and this impact was greater for practices that respondents judged to be less defensible. Combining three different estimation methods, we found that the percentage of respondents who have engaged in questionable practices was surprisingly high. This finding suggests that some questionable practices may constitute the prevailing research norm.},
	language = {en},
	number = {5},
	urldate = {2021-07-10},
	journal = {Psychological Science},
	author = {John, Leslie K. and Loewenstein, George and Prelec, Drazen},
	month = may,
	year = {2012},
	pages = {524--532},
}

@article{banks_editorial_2016,
	title = {Editorial: {Evidence} on {Questionable} {Research} {Practices}: {The} {Good}, the {Bad}, and the {Ugly}},
	volume = {31},
	issn = {0889-3268, 1573-353X},
	shorttitle = {Editorial},
	url = {http://link.springer.com/10.1007/s10869-016-9456-7},
	doi = {10.1007/s10869-016-9456-7},
	language = {en},
	number = {3},
	urldate = {2021-07-10},
	journal = {Journal of Business and Psychology},
	author = {Banks, George C. and Rogelberg, Steven G. and Woznyj, Haley M. and Landis, Ronald S. and Rupp, Deborah E.},
	month = sep,
	year = {2016},
	pages = {323--338},
}

@article{fiedler_long_2012,
	title = {The {Long} {Way} {From} α-{Error} {Control} to {Validity} {Proper}: {Problems} {With} a {Short}-{Sighted} {False}-{Positive} {Debate}},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	shorttitle = {The {Long} {Way} {From} α-{Error} {Control} to {Validity} {Proper}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691612462587},
	doi = {10.1177/1745691612462587},
	abstract = {Several influential publications have sensitized the community of behavioral scientists to the dangers of inflated effects and false-positive errors leading to the unwarranted publication of nonreplicable findings. This issue has been related to prominent cases of data fabrication and survey results pointing to bad practices in empirical science. Although we concur with the motives behind these critical arguments, we note that an isolated debate of false positives may itself be misleading and counter-productive. Instead, we argue that, given the current state of affairs in behavioral science, false negatives often constitute a more serious problem. Referring to Wason’s (1960) seminal work on inductive reasoning, we show that the failure to assertively generate and test alternative hypotheses can lead to dramatic theoretical mistakes, which cannot be corrected by any kind of rigor applied to statistical tests of the focal hypotheses. We conclude that a scientific culture rewarding strong inference (Platt, 1964) is more likely to see progress than a culture preoccupied with tightening its standards for the mere publication of original findings.},
	language = {en},
	number = {6},
	urldate = {2021-07-10},
	journal = {Perspectives on Psychological Science},
	author = {Fiedler, Klaus and Kutzner, Florian and Krueger, Joachim I.},
	month = nov,
	year = {2012},
	pages = {661--669},
}

@article{fiedler_questionable_2016,
	title = {Questionable {Research} {Practices} {Revisited}},
	volume = {7},
	issn = {1948-5506, 1948-5514},
	url = {http://journals.sagepub.com/doi/10.1177/1948550615612150},
	doi = {10.1177/1948550615612150},
	abstract = {The current discussion of questionable research practices (QRPs) is meant to improve the quality of science. It is, however, important to conduct QRP studies with the same scrutiny as all research. We note problems with overestimates of QRP prevalence and the survey methods used in the frequently cited study by John, Loewenstein, and Prelec. In a survey of German psychologists, we decomposed QRP prevalence into its two multiplicative components, proportion of scientists who ever committed a behavior and, if so, how frequently they repeated this behavior across all their research. The resulting prevalence estimates are lower by order of magnitudes. We conclude that inflated prevalence estimates, due to problematic interpretation of survey data, can create a descriptive norm (QRP is normal) that can counteract the injunctive norm to minimize QRPs and unwantedly damage the image of behavioral sciences, which are essential to dealing with many societal problems.},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Social Psychological and Personality Science},
	author = {Fiedler, Klaus and Schwarz, Norbert},
	month = jan,
	year = {2016},
	pages = {45--52},
}

@article{page_prisma_2021,
	title = {{PRISMA} 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews},
	issn = {1756-1833},
	shorttitle = {{PRISMA} 2020 explanation and elaboration},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.n160},
	doi = {10.1136/bmj.n160},
	language = {en},
	urldate = {2021-07-10},
	journal = {BMJ},
	author = {Page, Matthew J and Moher, David and Bossuyt, Patrick M and Boutron, Isabelle and Hoffmann, Tammy C and Mulrow, Cynthia D and Shamseer, Larissa and Tetzlaff, Jennifer M and Akl, Elie A and Brennan, Sue E and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M and Hróbjartsson, Asbjørn and Lalu, Manoj M and Li, Tianjing and Loder, Elizabeth W and Mayo-Wilson, Evan and McDonald, Steve and McGuinness, Luke A and Stewart, Lesley A and Thomas, James and Tricco, Andrea C and Welch, Vivian A and Whiting, Penny and McKenzie, Joanne E},
	month = mar,
	year = {2021},
	pages = {n160},
}

@article{moher_hong_2020,
	title = {The {Hong} {Kong} {Principles} for assessing researchers: {Fostering} research integrity},
	volume = {18},
	issn = {1545-7885},
	shorttitle = {The {Hong} {Kong} {Principles} for assessing researchers},
	url = {https://dx.plos.org/10.1371/journal.pbio.3000737},
	doi = {10.1371/journal.pbio.3000737},
	language = {en},
	number = {7},
	urldate = {2021-07-10},
	journal = {PLOS Biology},
	author = {Moher, David and Bouter, Lex and Kleinert, Sabine and Glasziou, Paul and Sham, Mai Har and Barbour, Virginia and Coriat, Anne-Marie and Foeger, Nicole and Dirnagl, Ulrich},
	month = jul,
	year = {2020},
	pages = {e3000737},
}

@book{higgins_cochrane_2020,
	address = {Hoboken, NJ},
	edition = {Second edition},
	series = {Cochrane book series},
	title = {Cochrane handbook for systematic reviews of interventions},
	isbn = {978-1-119-53662-8},
	abstract = {"Systematic reviews summarise primary research. They are central to the evidence- based medicine movement and are widely acknowledged as the best form of evidence on which to base healthcare decisions. The Cochrane Collaboration exists to produce systematic reviews of healthcare treatments. To be reliable, systematic reviews should be conducted to the highest level of scientific rigour. This book enables Cochrane and other systematic review authors to do this and to ensure their review is of the highest quality and avoid methodological pitfalls"--},
	publisher = {Wiley-Blackwell},
	editor = {Higgins, Julian P. T. and Cochrane Collaboration},
	year = {2020},
	keywords = {Meta-Analysis as Topic, Evidence-Based Medicine, methods, Outcome and Process Assessment (Health Care), Systematic Reviews as Topic},
}

@article{webster_how_2020,
	title = {How {STRANGE} are your study animals?},
	volume = {582},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/d41586-020-01751-5},
	doi = {10.1038/d41586-020-01751-5},
	language = {en},
	number = {7812},
	urldate = {2021-07-10},
	journal = {Nature},
	author = {Webster, Michael M. and Rutz, Christian},
	month = jun,
	year = {2020},
	pages = {337--340},
}

@article{giner-sorolla_spsp_2019,
	title = {{SPSP} {Power} {Analysis} {Working} {Group} 2019},
	url = {https://osf.io/9bt5s/},
	abstract = {Archive for papers produced by the Power Analysis Working Group and related materials. 
    Hosted on the Open Science Framework},
	language = {en},
	urldate = {2021-07-10},
	author = {Giner-Sorolla, Roger and Carpenter, Tom and Montoya, Amanda and Neil Lewis, Jr},
	month = aug,
	year = {2019},
	note = {Publisher: OSF},
}

@book{cohen_statistical_1988,
	address = {Hillsdale, N.J},
	edition = {2nd ed},
	title = {Statistical power analysis for the behavioral sciences},
	isbn = {978-0-8058-0283-2},
	publisher = {L. Erlbaum Associates},
	author = {Cohen, Jacob},
	year = {1988},
	keywords = {Social sciences, Statistical methods, Probabilities, Statistical power analysis},
}

@article{cohen_statistical_1962,
	title = {The statistical power of abnormal-social psychological research: {A} review.},
	volume = {65},
	issn = {0096-851X},
	shorttitle = {The statistical power of abnormal-social psychological research},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0045186},
	doi = {10.1037/h0045186},
	language = {en},
	number = {3},
	urldate = {2021-07-10},
	journal = {The Journal of Abnormal and Social Psychology},
	author = {Cohen, Jacob},
	month = sep,
	year = {1962},
	pages = {145--153},
}

@techreport{carter_considerations_2021,
	type = {preprint},
	title = {Considerations of sample size and power calculations given a range of analytical scenarios},
	url = {https://osf.io/tcqrn},
	abstract = {The sample size of a study is a key design and planning consideration. However, sample size and power calculations are often either poorly reported or not reported at all, which suggests they may not form a routine part of study planning. Inadequate understanding of sample size and statistical power can result in poor quality studies. Journals increasingly require a justification of sample size, for example through the use of reporting checklists. However, for meaningful improvements in research quality to be made, researchers need to consider sample size and power at the design stage of a study, rather than at the publication stage. Here we briefly illustrate sample size and statistical power in the context of different research questions and how they should be viewed as a critical design consideration.},
	urldate = {2021-07-10},
	institution = {PsyArXiv},
	author = {Carter, Alice and Tilling, Kate and Munafo, Marcus Robert},
	month = jan,
	year = {2021},
	doi = {10.31234/osf.io/tcqrn},
}

@article{nimon_statistical_2012,
	title = {Statistical {Assumptions} of {Substantive} {Analyses} {Across} the {General} {Linear} {Model}: {A} {Mini}-{Review}},
	volume = {3},
	issn = {1664-1078},
	shorttitle = {Statistical {Assumptions} of {Substantive} {Analyses} {Across} the {General} {Linear} {Model}},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2012.00322/abstract},
	doi = {10.3389/fpsyg.2012.00322},
	urldate = {2021-07-10},
	journal = {Frontiers in Psychology},
	author = {Nimon, Kim F.},
	year = {2012},
}

@article{hoekstra_are_2012,
	title = {Are {Assumptions} of {Well}-{Known} {Statistical} {Techniques} {Checked}, and {Why} ({Not})?},
	volume = {3},
	issn = {1664-1078},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2012.00137/abstract},
	doi = {10.3389/fpsyg.2012.00137},
	urldate = {2021-07-10},
	journal = {Frontiers in Psychology},
	author = {Hoekstra, Rink and Kiers, Henk and Johnson, Addie},
	year = {2012},
}

@article{hahn_assumptions_1993,
	title = {Assumptions for {Statistical} {Inference}},
	volume = {47},
	issn = {0003-1305, 1537-2731},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1993.10475924},
	doi = {10.1080/00031305.1993.10475924},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {The American Statistician},
	author = {Hahn, Gerald J. and Meeker, William Q.},
	month = feb,
	year = {1993},
	pages = {1--11},
}

@book{garson_testing_2012,
	address = {United States},
	edition = {2012 edition},
	title = {Testing {Statistical} {Assumptions}},
	publisher = {North Carolina State University},
	author = {Garson, G. D},
	year = {2012},
}

@techreport{american_psychological_associationtask_force_on_socioeconomic_status_report_2007,
	address = {Washington, D.C.},
	title = {Report of the {APA} task force on {Socioeconomic} status},
	institution = {American Psychological Association},
	author = {{American Psychological Association,Task Force on Socioeconomic Status}},
	year = {2007},
}

@article{voracek_which_2019,
	title = {Which {Data} to {Meta}-{Analyze}, and {How}?: {A} {Specification}-{Curve} and {Multiverse}-{Analysis} {Approach} to {Meta}-{Analysis}},
	volume = {227},
	issn = {2190-8370, 2151-2604},
	shorttitle = {Which {Data} to {Meta}-{Analyze}, and {How}?},
	url = {https://econtent.hogrefe.com/doi/10.1027/2151-2604/a000357},
	doi = {10.1027/2151-2604/a000357},
	abstract = {Abstract. Which data to analyze, and how, are fundamental questions of all empirical research. As there are always numerous flexibilities in data-analytic decisions (a “garden of forking paths”), this poses perennial problems to all empirical research. Specification-curve analysis and multiverse analysis have recently been proposed as solutions to these issues. Building on the structural analogies between primary data analysis and meta-analysis, we transform and adapt these approaches to the meta-analytic level, in tandem with combinatorial meta-analysis. We explain the rationale of this idea, suggest descriptive and inferential statistical procedures, as well as graphical displays, provide code for meta-analytic practitioners to generate and use these, and present a fully worked real example from digit ratio (2D:4D) research, totaling 1,592 meta-analytic specifications. Specification-curve and multiverse meta-analysis holds promise to resolve conflicting meta-analyses, contested evidence, controversial empirical literatures, and polarized research, and to mitigate the associated detrimental effects of these phenomena on research progress.},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Zeitschrift für Psychologie},
	author = {Voracek, Martin and Kossmeier, Michael and Tran, Ulrich S.},
	month = jan,
	year = {2019},
	pages = {64--82},
}

@article{evans_class_2021,
	title = {In a {Class} on {Their} {Own}: {Investigating} the {Role} of {Social} {Integration} in the {Association} {Between} {Social} {Class} and {Mental} {Well}-{Being}},
	issn = {0146-1672, 1552-7433},
	shorttitle = {In a {Class} on {Their} {Own}},
	url = {http://journals.sagepub.com/doi/10.1177/01461672211021190},
	doi = {10.1177/01461672211021190},
	abstract = {It has been established that people from lower social classes tend to have poorer mental well-being compared with people from higher classes. Research also suggests that people from the lower classes are also less socially integrated. This research investigated the role of social integration in the relationship between social class and mental well-being across three studies (Study 1 N = 15,028; Study 2 N = 1,946; Study 3 N = 461). Across all studies, social class had an indirect effect on mental well-being via social integration. Moderation results found that social integration buffers the negative impact of financial issues on mental well-being, social support buffers the effects of class on mental ill-health, and family support amplifies rather than reduces social class differences in mental well-being. We propose that although improving social integration has the potential to improve the mental well-being of lower class populations, some caveats need to be considered.},
	language = {en},
	urldate = {2021-07-10},
	journal = {Personality and Social Psychology Bulletin},
	author = {Evans, Olivia and Rubin, Mark},
	month = jun,
	year = {2021},
	pages = {014616722110211},
}

@incollection{jetten_social_2019,
	address = {Cham},
	title = {Social {Class} {Differences} in {Social} {Integration} at {University}: {Implications} for {Academic} {Outcomes} and {Mental} {Health}},
	isbn = {978-3-030-28855-6 978-3-030-28856-3},
	shorttitle = {Social {Class} {Differences} in {Social} {Integration} at {University}},
	url = {http://link.springer.com/10.1007/978-3-030-28856-3_6},
	language = {en},
	urldate = {2021-07-10},
	booktitle = {The {Social} {Psychology} of {Inequality}},
	publisher = {Springer International Publishing},
	author = {Rubin, Mark and Evans, Olivia and McGuffog, Romany},
	editor = {Jetten, Jolanda and Peters, Kim},
	year = {2019},
	doi = {10.1007/978-3-030-28856-3_6},
	pages = {87--102},
}

@article{rubin_explaining_2021,
	title = {Explaining the association between subjective social status and mental health among university students using an impact ratings approach},
	volume = {1},
	issn = {2662-9283},
	url = {https://link.springer.com/10.1007/s43545-020-00031-3},
	doi = {10.1007/s43545-020-00031-3},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {SN Social Sciences},
	author = {Rubin, Mark},
	month = jan,
	year = {2021},
	pages = {20},
}

@misc{noauthor_httpsimprovingpsychorg_nodate,
	title = {https://improvingpsych.org/},
	shorttitle = {https},
	url = {https://improvingpsych.org/},
	language = {en-US},
	urldate = {2021-07-10},
}

@misc{sortee_sortee_nodate,
	title = {{SORTEE}},
	url = {https://www.sortee.org/},
	abstract = {SORTEE blog},
	language = {en-us},
	urldate = {2021-07-10},
	journal = {SORTEE},
	author = {SORTEE},
}

@article{frith_fast_2020,
	title = {Fast {Lane} to {Slow} {Science}},
	volume = {24},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661319302426},
	doi = {10.1016/j.tics.2019.10.007},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Trends in Cognitive Sciences},
	author = {Frith, Uta},
	month = jan,
	year = {2020},
	pages = {1--2},
}

@article{nelson_lets_2012,
	title = {Let's {Publish} \textit{{Fewer}} {Papers}},
	volume = {23},
	issn = {1047-840X, 1532-7965},
	url = {http://www.tandfonline.com/doi/abs/10.1080/1047840X.2012.705245},
	doi = {10.1080/1047840X.2012.705245},
	language = {en},
	number = {3},
	urldate = {2021-07-10},
	journal = {Psychological Inquiry},
	author = {Nelson, Leif D. and Simmons, Joseph P. and Simonsohn, Uri},
	month = jul,
	year = {2012},
	pages = {291--293},
}

@misc{the_slow_science_academy_slow_2010,
	title = {The {Slow} {Science} {Manifesto}},
	url = {http://slow-science.org/},
	urldate = {2021-07-10},
	journal = {SLOW-SCIENCE.org — Bear with us, while we think.},
	author = {{The Slow Science Academy}},
	year = {2010},
}

@article{noauthor_osf_nodate-1,
	title = {{OSF} {\textbar} {StudySwap}: {A} platform for interlab replication, collaboration, and research resource exchange},
	shorttitle = {{OSF} {\textbar} {StudySwap}},
	url = {https://osf.io/meetings/StudySwap/},
	abstract = {Hosted on the Open Science Framework},
	language = {en},
	urldate = {2021-07-10},
	note = {Publisher: OSF},
}

@article{chartier_studyswap_2018,
	title = {{StudySwap}: {A} {Platform} for {Interlab} {Replication}, {Collaboration}, and {Resource} {Exchange}},
	volume = {1},
	issn = {2515-2459, 2515-2467},
	shorttitle = {{StudySwap}},
	url = {http://journals.sagepub.com/doi/10.1177/2515245918808767},
	doi = {10.1177/2515245918808767},
	abstract = {The resources needed to conduct psychological research (i.e., time, access to participants, equipment, expertise, etc.) are sometimes distributed inefficiently: Resources going unused at one lab may be needed to complete projects at another lab. This inefficient distribution of resources can be an impediment to scientific progress and to individuals’ careers. StudySwap ( https://osf.io/view/StudySwap ) is an online platform where researchers can post brief de-scriptions of research resources that are available for use ( haves) or that they need and another researcher may have ( needs). This Tutorial provides instructions for posting haves and needs on StudySwap, responding to the posts of other researchers, and creating exchange agreements that define expectations of all collaborative parties prior to data collection or other resource exchanges. Ultimately, we hope that StudySwap can be used to increase the efficiency with which psychology’s collective research resources are being used.},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Chartier, Christopher R. and Riegelman, Amy and McCarthy, Randy J.},
	month = dec,
	year = {2018},
	pages = {574--579},
}

@book{tenny_statistical_2021,
	title = {Statistical {Significance}},
	url = {https://www.ncbi.nlm.nih.gov/books/NBK459346/},
	abstract = {In research, statistical significance is a measure of the probability of the null hypothesis being true compared to the acceptable level of uncertainty regarding the true answer. If we break apart a study design, we can better understand statistical significance.[1][2][3][4][5][6][7]},
	language = {en},
	urldate = {2021-07-10},
	publisher = {StatPearls Publishing},
	author = {Tenny, Steven and Abdelgawad, Ibrahim},
	month = may,
	year = {2021},
	pmid = {29083828},
	note = {Publication Title: StatPearls [Internet]},
}

@article{cassidy_failing_2019,
	title = {Failing {Grade}: 89\% of {Introduction}-to-{Psychology} {Textbooks} {That} {Define} or {Explain} {Statistical} {Significance} {Do} {So} {Incorrectly}},
	volume = {2},
	issn = {2515-2459, 2515-2467},
	shorttitle = {Failing {Grade}},
	url = {http://journals.sagepub.com/doi/10.1177/2515245919858072},
	doi = {10.1177/2515245919858072},
	abstract = {Null-hypothesis significance testing (NHST) is commonly used in psychology; however, it is widely acknowledged that NHST is not well understood by either psychology professors or psychology students. In the current study, we investigated whether introduction-to-psychology textbooks accurately define and explain statistical significance. We examined 30 introductory-psychology textbooks, including the best-selling books from the United States and Canada, and found that 89\% incorrectly defined or explained statistical significance. Incorrect definitions and explanations were most often consistent with the odds-against-chance fallacy. These results suggest that it is common for introduction-to-psychology students to be taught incorrect interpretations of statistical significance. We hope that our results will create awareness among authors of introductory-psychology books and provide the impetus for corrective action. To help with classroom instruction, we provide slides that correctly describe NHST and may be useful for introductory-psychology instructors.},
	language = {en},
	number = {3},
	urldate = {2021-07-10},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Cassidy, Scott A. and Dimova, Ralitza and Giguère, Benjamin and Spence, Jeffrey R. and Stanley, David J.},
	month = sep,
	year = {2019},
	pages = {233--239},
}

@article{noauthor_transparency_2016,
	title = {Transparency: {The} {Emerging} {Third} {Dimension} of {Open} {Science} and {Open} {Data}},
	volume = {25},
	issn = {2213-056X},
	shorttitle = {Transparency},
	url = {https://www.liberquarterly.eu/article/10.18352/lq.10113},
	doi = {10.18352/lq.10113},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {LIBER QUARTERLY},
	month = mar,
	year = {2016},
	pages = {153--171},
}

@article{elliott_making_2019,
	title = {Making {Open} {Science} {Work} for {Science} and {Society}},
	volume = {127},
	issn = {0091-6765, 1552-9924},
	url = {https://ehp.niehs.nih.gov/doi/10.1289/EHP4808},
	doi = {10.1289/EHP4808},
	language = {en},
	number = {7},
	urldate = {2021-07-10},
	journal = {Environmental Health Perspectives},
	author = {Elliott, Kevin C. and Resnik, David B.},
	month = jul,
	year = {2019},
	pages = {075002},
}

@article{gioia_multiparadigm_1990,
	title = {Multiparadigm {Perspectives} on {Theory} {Building}},
	volume = {15},
	issn = {0363-7425, 1930-3807},
	url = {http://journals.aom.org/doi/10.5465/amr.1990.4310758},
	doi = {10.5465/amr.1990.4310758},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {Academy of Management Review},
	author = {Gioia, Dennis A. and Pitre, Evelyn},
	month = oct,
	year = {1990},
	pages = {584--602},
}

@article{corley_building_2011,
	title = {Building {Theory} about {Theory} {Building}: {What} {Constitutes} a {Theoretical} {Contribution}?},
	volume = {36},
	issn = {0363-7425, 1930-3807},
	shorttitle = {Building {Theory} about {Theory} {Building}},
	url = {http://journals.aom.org/doi/10.5465/amr.2009.0486},
	doi = {10.5465/amr.2009.0486},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Academy of Management Review},
	author = {Corley, Kevin G. and Gioia, Dennis A.},
	month = jan,
	year = {2011},
	pages = {12--32},
}

@techreport{borsboom_theory_2020,
	type = {preprint},
	title = {Theory {Construction} {Methodology}: {A} practical framework for theory formation in psychology},
	shorttitle = {Theory {Construction} {Methodology}},
	url = {https://osf.io/w5tp8},
	abstract = {This paper aims to improve theory formation in psychology by developing a practical methodology for constructing explanatory theories: Theory Construction Methodology (TCM). TCM is a sequence of five steps. First, the theorist identifies empirical phenomena to become the target of explanation. Second, the theorist constructs a proto-theory: a set of theoretical principles that potentially explain these phenomena. Third, the proto-theory is used to construct a formal model: a set of model equations or simulation models that encode the explanatory principles. Fourth, the theorist investigates this model’s explanatory adequacy. This is done by formalizing the empirical phenomena in terms of the model, and assessing whether the model indeed reproduces them. Fifth, the theorist studies the overall adequacy of the theory by evaluating whether phenomena are indeed reproduced faithfully, whether explanatory principles are parsimonious and substantively plausible, and whether the theory implies new predictions to promote further research. We illustrate TCM with an example taken from the intelligence literature (the mutualism model of intelligence), discuss the place of TCM in the larger scheme of scientific research, and propose an outline for a university curriculum that can systematically educate psychologists in the process of theory formation.},
	urldate = {2021-07-10},
	institution = {PsyArXiv},
	author = {Borsboom, Denny and van der Maas, Han and Dalege, Jonas and Kievit, Rogier and Haig, Brian},
	month = feb,
	year = {2020},
	doi = {10.31234/osf.io/w5tp8},
}

@misc{schafersman_introduction_1997,
	title = {An {Introduction} to {Science}: {Scientific} {Thinking} and {Scientific} {Method}},
	url = {https://www.geo.sunysb.edu/esp/files/scientific-method.html},
	urldate = {2021-07-10},
	journal = {An Introduction to Science},
	author = {Schafersman, Steven},
	month = jan,
	year = {1997},
}

@article{wacker_definition_1998,
	title = {A definition of theory: research guidelines for different theory-building research methods in operations management},
	volume = {16},
	issn = {02726963},
	shorttitle = {A definition of theory},
	url = {http://doi.wiley.com/10.1016/S0272-6963(98)00019-9},
	doi = {10.1016/S0272-6963(98)00019-9},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {Journal of Operations Management},
	author = {Wacker, John G},
	month = jul,
	year = {1998},
	pages = {361--385},
}

@misc{noauthor_swissrn_nodate,
	title = {{SwissRN}},
	url = {http://www.swissrn.org/},
	language = {en},
	urldate = {2021-07-10},
}

@misc{noauthor_domov_nodate,
	title = {Domov {\textbar} {SKRN} ({Slovak} {Reproducibility} network)},
	url = {https://slovakrn.wixsite.com/skrn},
	abstract = {Oficiálna stránka Spoločenstva otvorenej vedy/Slovak Reproducibility Network.},
	language = {en},
	urldate = {2021-07-10},
	journal = {SKRN},
}

@article{tiokhin_competition_2021,
	title = {Competition for priority harms the reliability of science, but reforms can help},
	issn = {2397-3374},
	url = {http://www.nature.com/articles/s41562-020-01040-1},
	doi = {10.1038/s41562-020-01040-1},
	language = {en},
	urldate = {2021-07-10},
	journal = {Nature Human Behaviour},
	author = {Tiokhin, Leonid and Yan, Minhua and Morgan, Thomas J. H.},
	month = jan,
	year = {2021},
}

@article{laine_afraid_2017,
	title = {Afraid of {Scooping} – {Case} {Study} on {Researcher} {Strategies} against {Fear} of {Scooping} in the {Context} of {Open} {Science}},
	volume = {16},
	issn = {1683-1470},
	url = {http://datascience.codata.org/articles/10.5334/dsj-2017-029/},
	doi = {10.5334/dsj-2017-029},
	language = {en},
	urldate = {2021-07-10},
	journal = {Data Science Journal},
	author = {Laine, Heidi},
	month = jun,
	year = {2017},
	pages = {29},
}

@article{houtkoop_data_2018,
	title = {Data {Sharing} in {Psychology}: {A} {Survey} on {Barriers} and {Preconditions}},
	volume = {1},
	issn = {2515-2459, 2515-2467},
	shorttitle = {Data {Sharing} in {Psychology}},
	url = {http://journals.sagepub.com/doi/10.1177/2515245917751886},
	doi = {10.1177/2515245917751886},
	abstract = {Despite its potential to accelerate academic progress in psychological science, public data sharing remains relatively uncommon. In order to discover the perceived barriers to public data sharing and possible means for lowering them, we conducted a survey, which elicited responses from 600 authors of articles in psychology. The results confirmed that data are shared only infrequently. Perceived barriers included respondents’ belief that sharing is not a common practice in their fields, their preference to share data only upon request, their perception that sharing requires extra work, and their lack of training in sharing data. Our survey suggests that strong encouragement from institutions, journals, and funders will be particularly effective in overcoming these barriers, in combination with educational materials that demonstrate where and how data can be shared effectively.},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Houtkoop, Bobby Lee and Chambers, Chris and Macleod, Malcolm and Bishop, Dorothy V. M. and Nichols, Thomas E. and Wagenmakers, Eric-Jan},
	month = mar,
	year = {2018},
	pages = {70--85},
}

@article{lu_note_2019,
	title = {A note on {Type} {S}/{M} errors in hypothesis testing},
	volume = {72},
	issn = {00071102},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/bmsp.12132},
	doi = {10.1111/bmsp.12132},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {British Journal of Mathematical and Statistical Psychology},
	author = {Lu, Jiannan and Qiu, Yixuan and Deng, Alex},
	month = feb,
	year = {2019},
	pages = {1--17},
}

@article{hartgerink_too_2017,
	title = {Too {Good} to be {False}: {Nonsignificant} {Results} {Revisited}},
	volume = {3},
	issn = {2474-7394},
	shorttitle = {Too {Good} to be {False}},
	url = {https://online.ucpress.edu/collabra/article/3/1/9/112371/Too-Good-to-be-False-Nonsignificant-Results},
	doi = {10.1525/collabra.71},
	abstract = {Due to its probabilistic nature, Null Hypothesis Significance Testing (NHST) is subject to decision errors. The concern for false positives has overshadowed the concern for false negatives in the recent debates in psychology. This might be unwarranted, since reported statistically nonsignificant findings may just be ‘too good to be false’. We examined evidence for false negatives in nonsignificant results in three different ways. We adapted the Fisher test to detect the presence of at least one false negative in a set of statistically nonsignificant results. Simulations show that the adapted Fisher method generally is a powerful method to detect false negatives. We examined evidence for false negatives in the psychology literature in three applications of the adapted Fisher method. These applications indicate that (i) the observed effect size distribution of nonsignificant effects exceeds the expected distribution assuming a null-effect, and approximately two out of three (66.7\%) psychology articles reporting nonsignificant results contain evidence for at least one false negative, (ii) nonsignificant results on gender effects contain evidence of true nonzero effects, and (iii) the statistically nonsignificant replications from the Reproducibility Project Psychology (RPP) do not warrant strong conclusions about the absence or presence of true zero effects underlying these nonsignificant results. We conclude that false negatives deserve more attention in the current debate on statistical practices in psychology. Potentially neglecting effects due to a lack of statistical power can lead to a waste of research resources and stifle the scientific discovery process.},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Collabra: Psychology},
	author = {Hartgerink, C. H. J. and Wicherts, J. M. and van Assen, M. A. L. M.},
	month = jan,
	year = {2017},
	pages = {9},
}

@article{lind_content_2017,
	title = {Content {Analysis} by the {Crowd}: {Assessing} the {Usability} of {Crowdsourcing} for {Coding} {Latent} {Constructs}},
	volume = {11},
	issn = {1931-2458, 1931-2466},
	shorttitle = {Content {Analysis} by the {Crowd}},
	url = {https://www.tandfonline.com/doi/full/10.1080/19312458.2017.1317338},
	doi = {10.1080/19312458.2017.1317338},
	language = {en},
	number = {3},
	urldate = {2021-07-10},
	journal = {Communication Methods and Measures},
	author = {Lind, Fabienne and Gruber, Maria and Boomgaarden, Hajo G.},
	month = jul,
	year = {2017},
	pages = {191--209},
}

@article{herrmannova_semantometrics_2016,
	title = {Semantometrics: {Towards} {Fulltext}-based {Research} {Evaluation}},
	shorttitle = {Semantometrics},
	url = {http://arxiv.org/abs/1605.04180},
	doi = {10.1145/2910896.2925448},
	abstract = {Over the recent years, there has been a growing interest in developing new research evaluation methods that could go beyond the traditional citation-based metrics. This interest is motivated on one side by the wider availability or even emergence of new information evidencing research performance, such as article downloads, views and Twitter mentions, and on the other side by the continued frustrations and problems surrounding the application of purely citation-based metrics to evaluate research performance in practice. Semantometrics are a new class of research evaluation metrics which build on the premise that full-text is needed to assess the value of a publication. This paper reports on the analysis carried out with the aim to investigate the properties of the semantometric contribution measure, which uses semantic similarity of publications to estimate research contribution, and provides a comparative study of the contribution measure with traditional bibliometric measures based on citation counting.},
	urldate = {2021-07-10},
	journal = {Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
	author = {Herrmannova, Drahomira and Knoth, Petr},
	month = jun,
	year = {2016},
	note = {arXiv: 1605.04180},
	keywords = {Computer Science - Digital Libraries},
	pages = {235--236},
}

@book{lee_doing_1993,
	address = {London ; Newbury Park, Calif},
	title = {Doing research on sensitive topics},
	isbn = {978-0-8039-8860-6 978-0-8039-8861-3},
	publisher = {Sage Publications},
	author = {Lee, Raymond M.},
	year = {1993},
	keywords = {Social sciences, Research, Interviewing, Social surveys},
}

@article{schmidt_worksheet_1987,
	title = {A {Worksheet} for {Authorship} of {Scientific} {Articles} on {JSTOR}},
	volume = {68},
	url = {https://www.jstor.org/stable/20166549},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Bulletin of the Ecological Society of America},
	author = {Schmidt, Robert. H.},
	month = mar,
	year = {1987},
	pages = {8--10},
}

@misc{noauthor_welcome_nodate,
	title = {Welcome to {Sherpa} {Romeo} - v2.sherpa},
	url = {https://v2.sherpa.ac.uk/romeo/},
	urldate = {2021-07-10},
	journal = {Sherpa Romeo},
}

@misc{noauthor_uk_nodate,
	title = {{UK} {Reproducibility} {Network}},
	url = {https://www.ukrn.org/},
	urldate = {2021-07-10},
	journal = {UK Reproducibility Network},
}

@misc{noauthor_grn_nodate,
	title = {{GRN} · {German} {Reproducibility} {Network}},
	url = {https://reproducibilitynetwork.de/},
	urldate = {2021-07-10},
	journal = {German Reproducibility Network},
}

@misc{noauthor_australian_nodate,
	title = {Australian {Reproducibility} {Network}},
	url = {http://www.aus-rn.org/},
	urldate = {2021-07-10},
	journal = {Australian Reproducibility Network},
}

@misc{noauthor_riot_nodate,
	title = {{RIOT} {Science} {Club} - {Riot} {Science} {Club}},
	url = {http://riotscience.co.uk/},
	urldate = {2021-07-10},
	journal = {Reproducible, Interpretable, Open, \& Transparent Science},
}

@article{chuard_evidence_2019,
	title = {Evidence that nonsignificant results are sometimes preferred: {Reverse} {P}-hacking or selective reporting?},
	volume = {17},
	issn = {1545-7885},
	shorttitle = {Evidence that nonsignificant results are sometimes preferred},
	url = {https://dx.plos.org/10.1371/journal.pbio.3000127},
	doi = {10.1371/journal.pbio.3000127},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {PLOS Biology},
	author = {Chuard, Pierre J. C. and Vrtílek, Milan and Head, Megan L. and Jennions, Michael D.},
	month = jan,
	year = {2019},
	pages = {e3000127},
}

@misc{kamraro_responsible_2014,
	type = {Text},
	title = {Responsible research \& innovation},
	url = {https://ec.europa.eu/programmes/horizon2020/en/h2020-section/responsible-research-innovation},
	abstract = {Responsible research \& innovation},
	language = {en},
	urldate = {2021-07-10},
	journal = {Horizon 2020 - European Commission},
	author = {kamraro},
	month = apr,
	year = {2014},
}

@article{lin_trust_2020,
	title = {The {TRUST} {Principles} for digital repositories},
	volume = {7},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/s41597-020-0486-7},
	doi = {10.1038/s41597-020-0486-7},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Scientific Data},
	author = {Lin, Dawei and Crabtree, Jonathan and Dillo, Ingrid and Downs, Robert R. and Edmunds, Rorie and Giaretta, David and De Giusti, Marisa and L’Hours, Hervé and Hugo, Wim and Jenkyns, Reyna and Khodiyar, Varsha and Martone, Maryann E. and Mokrane, Mustapha and Navale, Vivek and Petters, Jonathan and Sierman, Barbara and Sokolova, Dina V. and Stockhause, Martina and Westbrook, John},
	month = dec,
	year = {2020},
	pages = {144},
}

@techreport{fraser_predicting_2021,
	type = {preprint},
	title = {Predicting reliability through structured expert elicitation with {repliCATS} ({Collaborative} {Assessments} for {Trustworthy} {Science})},
	url = {https://osf.io/2pczv},
	abstract = {Replication is a hallmark of scientific research. As replications of individual studies are resource intensive, techniques for predicting the replicability are required. We introduce a new technique to evaluating replicability, the repliCATS (Collaborative Assessments for Trustworthy Science) process, a structured expert elicitation approach based on the IDEA protocol. The repliCATS process is delivered through an underpinning online platform and applied to the evaluation of research claims in social and behavioural sciences. This process can be deployed for both rapid assessment of small numbers of claims, and assessment of high volumes of claims over an extended period. Pilot data suggests that the accuracy of the repliCATS process meets or exceeds that of other techniques used to predict replicability. An important advantage of the repliCATS process is that it collects qualitative data that has the potential to assist with problems like understanding the limits of generalizability of scientific claims. The repliCATS process has potential applications in alternative peer review and in the allocation of effort for replication studies.},
	urldate = {2021-07-10},
	institution = {MetaArXiv},
	author = {Fraser, Hannah and Bush, Martin and Wintle, Bonnie and Mody, Fallon and Smith, Eden T. and Hanea, Anca and Gould, Elliot and Hemming, Victoria and Hamilton, Daniel George and Rumpff, Libby and Wilkinson, David Peter and Pearson, Ross and Singleton Thorn, Felix and Ashton, raquel and Willcox, Aaron and Gray, Charles T. and Head, Andrew and Ross, Melissa and Groenewegen, Rebecca and Marcoci, Alexandru and Vercammen, Ans and Parker, Timothy H. and Hoekstra, Rink and Nakagawa, Shinichi and Mandel, David R. and van Ravenzwaaij, Don and McBride, Marissa and Sinnott, Richard O. and Vesk, Peter Anton and Burgman, Mark and Fidler, Fiona},
	month = feb,
	year = {2021},
	doi = {10.31222/osf.io/2pczv},
}

@misc{noauthor_collaborative_nodate,
	title = {Collaborative {Assessment} {forTrustworthy} {Science}{\textbar}{The} {repliCATS} project},
	url = {https://replicats.research.unimelb.edu.au/},
	urldate = {2021-07-10},
	journal = {University of Melbourne},
}

@article{wicherts_degrees_2016,
	title = {Degrees of {Freedom} in {Planning}, {Running}, {Analyzing}, and {Reporting} {Psychological} {Studies}: {A} {Checklist} to {Avoid} p-{Hacking}},
	volume = {7},
	issn = {1664-1078},
	shorttitle = {Degrees of {Freedom} in {Planning}, {Running}, {Analyzing}, and {Reporting} {Psychological} {Studies}},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2016.01832/full},
	doi = {10.3389/fpsyg.2016.01832},
	urldate = {2021-07-10},
	journal = {Frontiers in Psychology},
	author = {Wicherts, Jelte M. and Veldkamp, Coosje L. S. and Augusteijn, Hilde E. M. and Bakker, Marjan and van Aert, Robbie C. M. and van Assen, Marcel A. L. M.},
	month = nov,
	year = {2016},
}

@misc{noauthor_european_nodate,
	title = {The {European} {Code} of {Conduct} for {Research} {Integrity} {\textbar} {ALLEA}},
	url = {https://allea.org/code-of-conduct/},
	language = {en-US},
	urldate = {2021-07-10},
}

@misc{medin_rigor_2012,
	type = {Blog},
	title = {Rigor {Without} {Rigor} {Mortis}: {The} {APS} {Board} {Discusses} {Research} {Integrity}},
	url = {https://www.psychologicalscience.org/observer/scientific-rigor},
	journal = {Association for Psychological Science},
	author = {Medin, D.L.},
	month = feb,
	year = {2012},
}

@article{barba_terminologies_2018,
	title = {Terminologies for {Reproducible} {Research}},
	url = {http://arxiv.org/abs/1802.03311},
	abstract = {Reproducible research---by its many names---has come to be regarded as a key concern across disciplines and stakeholder groups. Funding agencies and journals, professional societies and even mass media are paying attention, often focusing on the so-called "crisis" of reproducibility. One big problem keeps coming up among those seeking to tackle the issue: different groups are using terminologies in utter contradiction with each other. Looking at a broad sample of publications in different fields, we can classify their terminology via decision tree: they either, A---make no distinction between the words reproduce and replicate, or B---use them distinctly. If B, then they are commonly divided in two camps. In a spectrum of concerns that starts at a minimum standard of "same data+same methods=same results," to "new data and/or new methods in an independent study=same findings," group 1 calls the minimum standard reproduce, while group 2 calls it replicate. This direct swap of the two terms aggravates an already weighty issue. By attempting to inventory the terminologies across disciplines, I hope that some patterns will emerge to help us resolve the contradictions.},
	urldate = {2021-07-10},
	journal = {arXiv:1802.03311 [cs]},
	author = {Barba, Lorena A.},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.03311},
	keywords = {Computer Science - Digital Libraries},
}

@article{peng_reproducible_2011,
	title = {Reproducible {Research} in {Computational} {Science}},
	volume = {334},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.1213847},
	doi = {10.1126/science.1213847},
	language = {en},
	number = {6060},
	urldate = {2021-07-10},
	journal = {Science},
	author = {Peng, R. D.},
	month = dec,
	year = {2011},
	pages = {1226--1227},
}

@article{stodden_trust_2011,
	title = {Trust {Your} {Science}? {Open} {Your} {Data} and {Code}},
	shorttitle = {Trust {Your} {Science}?},
	url = {https://academiccommons.columbia.edu/doi/10.7916/D8CJ8Q0P},
	doi = {10.7916/D8CJ8Q0P},
	abstract = {This is a view on the reproducibility of computational sciences by Victoria Stodden. It contains information on the Reproducibility, Replicability, and Repeatability of code created by the other sciences. Stodden also talks about the rising prominence of computational sciences as we are in the digital age and what that means for the future of science and collecting data.},
	urldate = {2021-07-10},
	author = {Stodden, Victoria C.},
	year = {2011},
	note = {Publisher: Columbia University},
	keywords = {Information science},
}

@misc{noauthor_recommended_nodate,
	title = {Recommended {Data} {Repositories} {\textbar} {Scientific} {Data}},
	copyright = {©2021 Macmillan Publishers Limited. All Rights Reserved.},
	url = {https://www.nature.com/sdata/policies/repositories},
	abstract = {Recommended Data Repositories},
	language = {en},
	urldate = {2021-07-10},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
ISSN: 2052-4463},
}

@misc{noauthor_what_nodate-4,
	title = {What is a reporting guideline? {\textbar} {The} {EQUATOR} {Network}},
	url = {https://www.equator-network.org/about-us/what-is-a-reporting-guideline/},
	urldate = {2021-07-10},
}

@article{elm_strengthening_2007,
	title = {Strengthening the reporting of observational studies in epidemiology ({STROBE}) statement: guidelines for reporting observational studies},
	volume = {335},
	issn = {0959-8138, 1468-5833},
	shorttitle = {Strengthening the reporting of observational studies in epidemiology ({STROBE}) statement},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.39335.541782.AD},
	doi = {10.1136/bmj.39335.541782.AD},
	language = {en},
	number = {7624},
	urldate = {2021-07-10},
	journal = {BMJ},
	author = {Elm, Erik von and Altman, Douglas G and Egger, Matthias and Pocock, Stuart J and Gøtzsche, Peter C and Vandenbroucke, Jan P},
	month = oct,
	year = {2007},
	pages = {806--808},
}

@misc{noauthor_reproducibilitea_nodate,
	title = {{ReproducibiliTea}},
	url = {https://reproducibilitea.org/},
	abstract = {ReproducibiliTea - Journal Clubs for Open Science},
	language = {en},
	urldate = {2021-07-10},
	journal = {ReproducibiliTea},
}

@article{the_consort_group_consort_2010,
	title = {{CONSORT} 2010 {Statement}: updated guidelines for reporting parallel group randomised trials},
	volume = {11},
	issn = {1745-6215},
	shorttitle = {{CONSORT} 2010 {Statement}},
	url = {https://trialsjournal.biomedcentral.com/articles/10.1186/1745-6215-11-32},
	doi = {10.1186/1745-6215-11-32},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Trials},
	author = {{the CONSORT Group} and Schulz, Kenneth F and Altman, Douglas G and Moher, David},
	month = dec,
	year = {2010},
	pages = {32},
}

@article{liu_replication_2020,
	title = {Replication {Markets}: {Results}, {Lessons}, {Challenges} and {Opportunities} in {AI} {Replication}},
	shorttitle = {Replication {Markets}},
	url = {http://arxiv.org/abs/2005.04543},
	abstract = {The last decade saw the emergence of systematic large-scale replication projects in the social and behavioral sciences, (Camerer et al., 2016, 2018; Ebersole et al., 2016; Klein et al., 2014, 2018; Collaboration, 2015). These projects were driven by theoretical and conceptual concerns about a high fraction of "false positives" in the scientific publications (Ioannidis, 2005) (and a high prevalence of "questionable research practices" (Simmons, Nelson, and Simonsohn, 2011). Concerns about the credibility of research findings are not unique to the behavioral and social sciences; within Computer Science, Artificial Intelligence (AI) and Machine Learning (ML) are areas of particular concern (Lucic et al., 2018; Freire, Bonnet, and Shasha, 2012; Gundersen and Kjensmo, 2018; Henderson et al., 2018). Given the pioneering role of the behavioral and social sciences in the promotion of novel methodologies to improve the credibility of research, it is a promising approach to analyze the lessons learned from this field and adjust strategies for Computer Science, AI and ML In this paper, we review approaches used in the behavioral and social sciences and in the DARPA SCORE project. We particularly focus on the role of human forecasting of replication outcomes, and how forecasting can leverage the information gained from relatively labor and resource-intensive replications. We will discuss opportunities and challenges of using these approaches to monitor and improve the credibility of research areas in Computer Science, AI, and ML.},
	urldate = {2021-07-10},
	journal = {arXiv:2005.04543 [cs]},
	author = {Liu, Yang and Gordon, Michael and Wang, Juntao and Bishop, Michael and Chen, Yiling and Pfeiffer, Thomas and Twardy, Charles and Viganola, Domenico},
	month = may,
	year = {2020},
	note = {arXiv: 2005.04543},
	keywords = {Computer Science - Social and Information Networks, Computer Science - Computers and Society, Computer Science - Artificial Intelligence},
}

@misc{noauthor_replication_nodate,
	title = {Replication {Markets} – {Reliable} research replicates…you can bet on it.},
	url = {https://www.replicationmarkets.com/},
	language = {en-US},
	urldate = {2021-07-10},
}

@article{king_replication_1995,
	title = {Replication, {Replication}},
	volume = {28},
	issn = {10490965},
	url = {https://www.jstor.org/stable/420301?origin=crossref},
	doi = {10.2307/420301},
	number = {3},
	urldate = {2021-07-10},
	journal = {PS: Political Science and Politics},
	author = {King, Gary},
	month = sep,
	year = {1995},
	pages = {444},
}

@techreport{chambers_past_2020,
	type = {preprint},
	title = {The past, present, and future of {Registered} {Reports}},
	url = {https://osf.io/43298},
	abstract = {Registered Reports are a form of empirical publication in which study proposals are peer reviewed and pre-accepted before research is undertaken. By deciding which articles are published based on the question, theory, and methods, Registered Reports offer a remedy for a range of reporting and publication biases. Here we reflect on the history, progress and future prospects of the Registered Reports initiative, and also offer practical guidance for authors, reviewers, and editors. We review early evidence that Registered Reports are working as intended, while at the same time acknowledging that they are not a universal solution for irreproducibility. We also consider how the policies and practices surrounding Registered Reports are changing, or must change in the future, to address limitations and adapt to new challenges. We conclude that Registered Reports are promoting reproducibility, transparency and self-correction across disciplines, and may help reshape how society evaluates research and researchers.},
	urldate = {2021-07-10},
	institution = {MetaArXiv},
	author = {Chambers, Christopher D and Tzavella, Loukia},
	month = feb,
	year = {2020},
	doi = {10.31222/osf.io/43298},
}

@article{chambers_registered_2015,
	title = {Registered {Reports}: {Realigning} incentives in scientific publishing},
	volume = {66},
	issn = {00109452},
	shorttitle = {Registered {Reports}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010945215001136},
	doi = {10.1016/j.cortex.2015.03.022},
	language = {en},
	urldate = {2021-07-10},
	journal = {Cortex},
	author = {Chambers, Christopher D. and Dienes, Zoltan and McIntosh, Robert D. and Rotshtein, Pia and Willmes, Klaus},
	month = may,
	year = {2015},
	pages = {A1--A2},
}

@article{chambers_registered_2013,
	title = {Registered {Reports}: {A} new publishing initiative at {Cortex}},
	volume = {49},
	issn = {00109452},
	shorttitle = {Registered {Reports}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010945212003735},
	doi = {10.1016/j.cortex.2012.12.016},
	language = {en},
	number = {3},
	urldate = {2021-07-10},
	journal = {Cortex},
	author = {Chambers, Christopher D.},
	month = mar,
	year = {2013},
	pages = {609--610},
}

@article{findley_can_2016,
	title = {Can {Results}-{Free} {Review} {Reduce} {Publication} {Bias}? {The} {Results} and {Implications} of a {Pilot} {Study}},
	volume = {49},
	issn = {0010-4140, 1552-3829},
	shorttitle = {Can {Results}-{Free} {Review} {Reduce} {Publication} {Bias}?},
	url = {http://journals.sagepub.com/doi/10.1177/0010414016655539},
	doi = {10.1177/0010414016655539},
	abstract = {In 2015, Comparative Political Studies embarked on a landmark pilot study in research transparency in the social sciences. The editors issued an open call for submissions of manuscripts that contained no mention of their actual results, incentivizing reviewers to evaluate manuscripts based on their theoretical contributions, research designs, and analysis plans. The three papers in this special issue are the result of this process that began with 19 submissions. In this article, we describe the rationale for this pilot, expressly articulating the practices of preregistration and results-free review. We document the process of carrying out the special issue with a discussion of the three accepted papers, and critically evaluate the role of both preregistration and results-free review. Our main conclusions are that results-free review encourages much greater attention to theory and research design, but that it raises thorny problems about how to anticipate and interpret null findings. We also observe that as currently practiced, results-free review has a particular affinity with experimental and cross-case methodologies. Our lack of submissions from scholars using qualitative or interpretivist research suggests limitations to the widespread use of results-free review.},
	language = {en},
	number = {13},
	urldate = {2021-07-10},
	journal = {Comparative Political Studies},
	author = {Findley, Michael G. and Jensen, Nathan M. and Malesky, Edmund J. and Pepinsky, Thomas B.},
	month = nov,
	year = {2016},
	pages = {1667--1703},
}

@misc{center_for_open_science_registered_nodate,
	title = {Registered {Reports}},
	url = {https://www.cos.io/initiatives/registered-reports},
	abstract = {Registered Reports},
	language = {en},
	urldate = {2021-07-10},
	author = {{Center for Open Science}},
}

@misc{bmj_introducing_2015,
	title = {Introducing ‘{How} to write and publish a {Study} {Protocol}’ using {BMJ}’s new {eLearning} programme: {Research} to {Publication}},
	shorttitle = {Introducing ‘{How} to write and publish a {Study} {Protocol}’ using {BMJ}’s new {eLearning} programme},
	url = {https://blogs.bmj.com/bmjopen/2015/09/22/introducing-how-to-write-and-publish-a-study-protocol-using-bmjs-new-elearning-programme-research-to-publication/},
	abstract = {Study protocols are an integral part of medical research. They provide a documented record of a researcher’s plan of action, detailing in advance a study’s rationale, methodology and analyses. Publication of study protocols ensures greater transparency in the research process and protects the wider community against a number of damaging research practices. These include the [...]Read More...},
	language = {en-US},
	urldate = {2021-07-10},
	journal = {BMJ Open},
	author = {{BMJ}},
	month = sep,
	year = {2015},
}

@misc{noauthor_data_nodate-2,
	title = {Data {Management} {Expert} {Guide} - {CESSDA} {TRAINING}},
	url = {https://www.cessda.eu/Training/Training-Resources/Library/Data-Management-Expert-Guide},
	urldate = {2021-07-10},
	journal = {CESSDA},
}

@article{bramoulle_research_2007,
	title = {Research {Cycles}},
	issn = {1556-5068},
	url = {http://www.ssrn.com/abstract=965816},
	doi = {10.2139/ssrn.965816},
	language = {en},
	urldate = {2021-07-10},
	journal = {SSRN Electronic Journal},
	author = {Bramoulle, Yann and Saint-Paul, Gilles},
	year = {2007},
}

@book{corti_managing_2019,
	address = {Thousand Oaks, CA},
	edition = {2nd edition},
	title = {Managing and sharing research data: a guide to good practice},
	isbn = {978-1-5264-6026-4 978-1-5264-6025-7},
	shorttitle = {Managing and sharing research data},
	publisher = {SAGE Publications},
	author = {Corti, Louise},
	year = {2019},
}

@book{elman_production_2020,
	address = {Cambridge New York Port Melbourne New Delhi Singapore},
	series = {Strategies for social inquiry},
	title = {The production of knowledge: enhancing progress in social science},
	isbn = {978-1-108-70828-9 978-1-108-48677-4},
	shorttitle = {The production of knowledge},
	abstract = {Whilst a great deal of progress has been made in recent decades, concerns persist about the course of the social sciences. Progress in these disciplines is hard to assess and core scientific goals such as discovery, transparency, reproducibility, and cumulation remain frustratingly out of reach. Despite having technical acumen and an array tools at their disposal, today's social scientists may be only slightly better equipped to vanquish error and construct an edifice of truth than their forbears - who conducted analyses with slide rules and wrote up results with typewriters. This volume considers the challenges facing the social sciences, as well as possible solutions. In doing so, we adopt a systemic view of the subject matter. What are the rules and norms governing behavior in the social sciences? What kinds of research, and which sorts of researcher, succeed and fail under the current system? In what ways does this incentive structure serve, or subvert, the goal of scientific progress?},
	language = {eng},
	publisher = {Cambridge University Press},
	editor = {Elman, Colin and Gerring, John and Mahoney, James},
	year = {2020},
}

@misc{noauthor_home_nodate,
	title = {Home {\textbar} re3data.org},
	url = {https://www.re3data.org/},
	urldate = {2021-07-10},
	journal = {DataCite Schema},
}

@misc{lakens_20_2020,
	title = {The 20\% {Statistician}: {Red} {Team} {Challenge}},
	shorttitle = {The 20\% {Statistician}},
	url = {http://daniellakens.blogspot.com/2020/05/red-team-challenge.html},
	urldate = {2021-07-10},
	journal = {The 20\% Statistician},
	author = {Lakens, Daniel},
	month = may,
	year = {2020},
}

@misc{noauthor_r_nodate,
	title = {R: {The} {R} {Project} for {Statistical} {Computing}},
	url = {https://www.r-project.org/},
	urldate = {2021-07-10},
	journal = {R Project},
}

@misc{noy_ontology_2001,
	title = {Ontology {Development} 101: {A} {Guide} to {Creating} {Your} {First} {Ontology}},
	url = {https://protege.stanford.edu/publications/ontology_development/ontology101.pdf},
	publisher = {Stanford Knowledge Systems Laboratory Technical Report  KSL-01-05 and Stanford Medical Informatics Technical Report SMI-2001-0880},
	author = {Noy, Natalya F. and Guinness, Deborah L.},
	month = mar,
	year = {2001},
}

@book{finlay_reflexivity_2003,
	address = {Malden, MA},
	title = {Reflexivity: a practical guide for researchers in health and social sciences},
	isbn = {978-0-632-06414-4},
	shorttitle = {Reflexivity},
	publisher = {Blackwell Science},
	editor = {Finlay, Linda and Gough, Brendan},
	year = {2003},
	keywords = {Social sciences, Qualitative research, Research Methodology, Medical sciences, Reflection (Philosophy)},
}

@misc{medical_research_centre_identifiability_2019,
	title = {Identifiability, anonymisation and pseudonymisation},
	url = {https://mrc.ukri.org/documents/pdf/gdpr-guidance-note-5-identifiability-anonymisation-and-pseudonymisation/},
	publisher = {Medical Research Centre},
	author = {{Medical Research Centre}},
	month = sep,
	year = {2019},
}

@techreport{working_group_1_of_the_joint_committee_for_guides_in_metrology_jcgm_evaluation_2008,
	address = {France},
	title = {Evaluation of measurement data — {Guide} to the expression of uncertainty in measurement},
	url = {https://www.bipm.org/documents/20126/2071204/JCGM_100_2008_E.pdf/cb0ef43f-baa5-11cf-3f85-4dcd86f77bd6},
	institution = {JCGM},
	author = {{Working Group 1 of the Joint Committee for Guides in Metrology JCGM}},
	year = {2008},
	pages = {1--120},
}

@misc{mischel_becoming_2009,
	title = {Becoming a {Cumulative} {Science}},
	url = {https://www.psychologicalscience.org/observer/becoming-a-cumulative-science},
	journal = {Association for Psychological Science},
	author = {Mischel, Walter},
	month = jan,
	year = {2009},
}

@article{curran_seemingly_2009,
	title = {The seemingly quixotic pursuit of a cumulative psychological science: {Introduction} to the special issue.},
	volume = {14},
	issn = {1939-1463, 1082-989X},
	shorttitle = {The seemingly quixotic pursuit of a cumulative psychological science},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0015972},
	doi = {10.1037/a0015972},
	language = {en},
	number = {2},
	urldate = {2021-07-11},
	journal = {Psychological Methods},
	author = {Curran, Patrick J.},
	year = {2009},
	pages = {77--80},
}

@book{muller_tyranny_2018,
	address = {Princeton},
	title = {The tyranny of metrics},
	isbn = {978-0-691-17495-2},
	publisher = {Princeton University Press},
	author = {Muller, Jerry Z.},
	year = {2018},
	keywords = {Measurement, Evaluation, Organizational effectiveness, Performance, Performance standards},
}

@misc{noauthor_what_nodate-5,
	title = {What is data sharing? {\textbar} {Support} {Centre} for {Data} {Sharing}},
	url = {https://eudatasharing.eu/what-data-sharing},
	urldate = {2021-07-11},
	journal = {Support Centre for Data Sharing},
}

@article{devezer_case_2021,
	title = {The case for formal methodology in scientific reform},
	volume = {8},
	issn = {2054-5703},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.200805},
	doi = {10.1098/rsos.200805},
	abstract = {Current attempts at methodological reform in sciences come in response to an overall lack of rigor in methodological and scientific practices in experimental sciences. However, most methodological reform attempts suffer from similar mistakes and over-generalizations to the ones they aim to address. We argue that this can be attributed in part to lack of formalism and first principles. Considering the costs of allowing false claims to become canonized, we argue for formal statistical rigor and scientific nuance in methodological reform. To attain this rigor and nuance, we propose a five-step formal approach for solving methodological problems. To illustrate the use and benefits of such formalism, we present a formal statistical analysis of three popular claims in the metascientific literature: (i) that reproducibility is the cornerstone of science; (ii) that data must not be used twice in any analysis; and (iii) that exploratory projects imply poor statistical practice. We show how our formal approach can inform and shape debates about such methodological claims.},
	language = {en},
	number = {3},
	urldate = {2021-07-11},
	journal = {Royal Society Open Science},
	author = {Devezer, Berna and Navarro, Danielle J. and Vandekerckhove, Joachim and Ozge Buzbas, Erkan},
	month = mar,
	year = {2021},
	pages = {rsos.200805, 200805},
}

@misc{noauthor_directory_nodate,
	title = {Directory of {Open} {Access} {Journals}},
	url = {https://doaj.org/apply/transparency/},
	abstract = {DOAJ is a community-curated online directory that indexes and provides access to high quality, open access, peer-reviewed journals.},
	language = {en},
	urldate = {2021-07-11},
}

@misc{noauthor_icmje_nodate,
	title = {{ICMJE} {\textbar} {Home}},
	url = {http://www.icmje.org/},
	urldate = {2021-07-11},
	journal = {International Committee of Medical Journal Editors},
}

@article{steckler_importance_2008,
	title = {The {Importance} of {External} {Validity}},
	volume = {98},
	issn = {0090-0036, 1541-0048},
	url = {http://ajph.aphapublications.org/doi/10.2105/AJPH.2007.126847},
	doi = {10.2105/AJPH.2007.126847},
	language = {en},
	number = {1},
	urldate = {2021-07-11},
	journal = {American Journal of Public Health},
	author = {Steckler, Allan and McLeroy, Kenneth R.},
	month = jan,
	year = {2008},
	pages = {9--10},
}

@article{campbell_factors_1957,
	title = {Factors relevant to the validity of experiments in social settings.},
	volume = {54},
	issn = {1939-1455, 0033-2909},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0040950},
	doi = {10.1037/h0040950},
	language = {en},
	number = {4},
	urldate = {2021-07-11},
	journal = {Psychological Bulletin},
	author = {Campbell, Donald T.},
	year = {1957},
	pages = {297--312},
}

@article{lewandowsky_worldview-motivated_2021,
	title = {Worldview-motivated rejection of science and the norms of science},
	volume = {215},
	issn = {00100277},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027721002390},
	doi = {10.1016/j.cognition.2021.104820},
	language = {en},
	urldate = {2021-07-11},
	journal = {Cognition},
	author = {Lewandowsky, Stephan and Oberauer, Klaus},
	month = oct,
	year = {2021},
	pages = {104820},
}

@article{kerr_right-wing_2021,
	title = {Right-wing authoritarianism and social dominance orientation predict rejection of science and scientists},
	volume = {24},
	issn = {1368-4302, 1461-7188},
	url = {http://journals.sagepub.com/doi/10.1177/1368430221992126},
	doi = {10.1177/1368430221992126},
	abstract = {Previous research has highlighted how ideological factors such as political self-identification, religiosity and conspiracy thinking influence our beliefs about scientific issues such as climate change and vaccination. Across three studies (combined N = 9,022) we expand on this line of inquiry to show for the first time that the ideological attitudes relating to authoritarianism and group-based dominance predict disagreement with the scientific consensus in several scientific domains. We show these effects are almost entirely mediated by varying combinations of ideological (political ideology, religiosity, free-market endorsement, conspiracy thinking) and science-specific (scientific knowledge, trust in scientists) constructs, depending on the scientific issue in question. Importantly, a general distrust of science and scientists emerges as the most consistent mediator across different scientific domains. We find that, consistent with previous research, the ideological roots of rejection of science vary across scientific issues. However, we also show that these roots may share a common origin in ideological attitudes regarding authority and equality.},
	language = {en},
	number = {4},
	urldate = {2021-07-11},
	journal = {Group Processes \& Intergroup Relations},
	author = {Kerr, John R. and Wilson, Marc S.},
	month = jun,
	year = {2021},
	pages = {550--567},
}

@article{azevedo_ideological_2021,
	title = {The ideological basis of antiscientific attitudes: {Effects} of authoritarianism, conservatism, religiosity, social dominance, and system justification},
	volume = {24},
	issn = {1368-4302, 1461-7188},
	shorttitle = {The ideological basis of antiscientific attitudes},
	url = {http://journals.sagepub.com/doi/10.1177/1368430221990104},
	doi = {10.1177/1368430221990104},
	abstract = {Serious concerns about public distrust of scientific experts and the spread of misinformation are growing in the US and elsewhere. To gauge ideological and psychological variability in attitudes toward science, we conducted an extensive analysis of public opinion data based on a nationally representative survey of U.S. adults ( N = 1,500) and a large replication sample ( N = 2,119). We estimated the unique effects of partisanship, symbolic and operational forms of political ideology, right-wing authoritarianism (RWA), social dominance orientation (SDO), and general system justification (GSJ), after adjusting for demographic factors. Multiverse analyses revealed that (a) conservatism and SDO were significant predictors of distrust of climate science in {\textgreater} 99.9\% of model specifications, with conservatism accounting for 80\% of the total variance; (b) conservatism, RWA, religiosity, (male) sex, (low) education, (low) income, and distrust of climate science were significant predictors of skepticism about science in general (vs. faith) in {\textgreater} 99.9\% of model specifications; (c) conservatism, RWA, (low) education, and distrust of climate science were significant predictors of trust in ordinary people (over scientific experts) {\textgreater} 99.9\% of the time; and (d) GSJ was a significant predictor of trust in scientific experts (over ordinary people) 81\% of the time, after adjusting for all other demographic and ideological factors. Implications for the role of science in democratic society are discussed.},
	language = {en},
	number = {4},
	urldate = {2021-07-11},
	journal = {Group Processes \& Intergroup Relations},
	author = {Azevedo, Flávio and Jost, John T.},
	month = jun,
	year = {2021},
	pages = {518--549},
}

@misc{azevedo_ideology_nodate,
	title = {Ideology {May} {Help} {Explain} {Anti}-{Scientific} {Attitudes} {\textbar} {Psychology} {Today}},
	url = {https://www.psychologytoday.com/intl/blog/social-justice-pacifists/202107/ideology-may-help-explain-anti-scientific-attitudes},
	abstract = {Political conservatism is a strong predictor of the rejection of science.},
	language = {en},
	urldate = {2021-07-11},
	author = {Azevedo, Flávio},
}

@article{anderson_role_2012,
	title = {The {Role} of {Media} and {Deference} to {Scientific} {Authority} in {Cultivating} {Trust} in {Sources} of {Information} about {Emerging} {Technologies}},
	volume = {24},
	issn = {1471-6909, 0954-2892},
	url = {https://academic.oup.com/ijpor/article-lookup/doi/10.1093/ijpor/edr032},
	doi = {10.1093/ijpor/edr032},
	language = {en},
	number = {2},
	urldate = {2021-07-11},
	journal = {International Journal of Public Opinion Research},
	author = {Anderson, Ashley A. and Scheufele, Dietram A. and Brossard, Dominique and Corley, Elizabeth A.},
	year = {2012},
	pages = {225--237},
}

@article{bak_education_2001,
	title = {Education and {Public} {Attitudes} toward {Science}: {Implications} for the "{Deficit} {Model}" of {Education} and {Support} for {Science} and {Technology}},
	volume = {82},
	issn = {0038-4941},
	shorttitle = {Education and {Public} {Attitudes} toward {Science}},
	url = {https://www.jstor.org/stable/42955760},
	abstract = {Objective. By critically examining the deficit model, this research attempts to grasp the multifaceted relationships between education and public attitudes toward science. Methods. It analyzes a series of nationwide surveys of public attitudes toward science conducted over a decade. Results. First, respondents' levels of education and levels of scientific knowledge make independent contributions to public attitudes toward science. Second, college (and postgraduate) majors have very weak effects on public attitudes toward science. Third, education is a much weaker predictor of public attitudes toward controversial scientific research, compared to its strong influence on science in general. Conclusions. Although education may indeed enhance public support for science in general, it may not help much to reduce tensions around politicized, controversial scientific research. For scientific controversies, gender might be a more important variable than education.},
	number = {4},
	urldate = {2021-07-11},
	journal = {Social Science Quarterly},
	author = {Bak, Hee-Je},
	year = {2001},
	note = {Publisher: [University of Texas Press, Wiley]},
	pages = {779--795},
}

@article{brewer_whose_2013,
	title = {Whose {Science} {Do} {You} {Believe}? {Explaining} {Trust} in {Sources} of {Scientific} {Information} {About} the {Environment}},
	volume = {35},
	issn = {1075-5470, 1552-8545},
	shorttitle = {Whose {Science} {Do} {You} {Believe}?},
	url = {http://journals.sagepub.com/doi/10.1177/1075547012441691},
	doi = {10.1177/1075547012441691},
	abstract = {Given that trust plays a key role in the communication of scientific information about the environment to the public, this study examines what explains trust in specific sources of such information. In doing so, it analyzes whether—and, if so, how—political ideology, support for environmental regulation, religiosity, trust in people, and trust in government predict trust in scientists, the Environmental Protection Agency, environmental organizations, news media, and science media. It also examines whether trust in scientists is associated with trust in the other sources in light of how each of the latter draws on the credibility of the former.},
	language = {en},
	number = {1},
	urldate = {2021-07-11},
	journal = {Science Communication},
	author = {Brewer, Paul R. and Ley, Barbara L.},
	month = feb,
	year = {2013},
	pages = {115--137},
}

@article{evans_relationship_1995,
	title = {The relationship between knowledge and attitudes in the public understanding of science in {Britain}},
	volume = {4},
	issn = {0963-6625},
	url = {https://doi.org/10.1088/0963-6625/4/1/004},
	doi = {10.1088/0963-6625/4/1/004},
	abstract = {The belief that greater understanding leads to more positive attitudes informs many practical initiatives in the public understanding of science. However, there has been comparatively little empirical study of the justification for this belief. This paper explores the relationship between understanding of science and levels of support for science using a national sample of over 2000 British respondents. The analysis indicates that the internal consistency of attitudes towards science is poor, and that the links between attitudes towards science in general and attitudes towards specific areas of scientific research are weak. Understanding of science is weakly related to more positive attitudes in general: but, more significantly, it is also associated with more coherent and more discriminating attitudes. Of particular importance is the finding that while knowledgeable members of the public are more favourably disposed towards science in general, they are less supportive of morally contentious areas of research than are those who are less knowledgeable. Although an informed public opinion is likely to provide a slightly more supportive popular basis for some areas of scientific research, it could serve to constrain research in controversial areas such as human embryology.},
	language = {en},
	number = {1},
	urldate = {2021-07-11},
	journal = {Public Understanding of Science},
	author = {Evans, Geoffrey and Durant, John},
	month = jan,
	year = {1995},
	note = {Publisher: SAGE Publications Ltd},
	pages = {57--74},
}

@article{hayes_gender_2000,
	title = {Gender differences in scientific knowledge and attitudes toward science: a comparative study of four {Anglo}-{American} nations},
	volume = {9},
	issn = {0963-6625},
	shorttitle = {Gender differences in scientific knowledge and attitudes toward science},
	url = {https://doi.org/10.1088/0963-6625/9/4/306},
	doi = {10.1088/0963-6625/9/4/306},
	abstract = {Despite a lack of empirical verification, research analysts and populist commentators have long assumed that a key factor in explaining anti-scientific attitudes among women is their greater disinterest and ignorance of scientific developments. Using nationally representative Anglo-American data from the 1993 International Social Survey Programme (ISSP) Environment Survey, the results of this analysis question that assumption. Women in the United States, Canada, Great Britain and New Zealand are indeed less knowledgeable and hold less favorable attitudes toward science than men. However, in all but the United States, these gender differences in scientific attitudes are due to male-female disparities in educational background and religious belief, not to variations in scientific knowledge. Thus, in Canada, Great Britain and New Zealand, it is not gender per se but rather differences in social background that explain citizens' views. A somewhat different pattern emerges in the United States. Here, it is differences in levels of scientific knowledge and not demographic background, including gender, which explains public variation in attitudes toward science. The implications of these findings for both research analysts and policy makers are briefly discussed.},
	language = {en},
	number = {4},
	urldate = {2021-07-11},
	journal = {Public Understanding of Science},
	author = {Hayes, Bernadette C. and Tariq, Vicki N.},
	month = oct,
	year = {2000},
	note = {Publisher: SAGE Publications Ltd},
	pages = {433--447},
}

@article{nisbet_knowledge_2002,
	title = {Knowledge, {Reservations}, or {Promise}?: {A} {Media} {Effects} {Model} for {Public} {Perceptions} of {Science} and {Technology}},
	volume = {29},
	issn = {0093-6502},
	shorttitle = {Knowledge, {Reservations}, or {Promise}?},
	url = {https://doi.org/10.1177/009365002236196},
	doi = {10.1177/009365002236196},
	abstract = {This study introduces a media effects model specific to public perceptions of science and technology. Analysis of the National Science Board's Science and Engineering Indicators Survey provides evidence that different media—newspapers, general television, science television, and science magazines—do affect perceptions differently. These media effects are direct but also indirect, as mediated through effects on science knowledge. Although newspaper reading, science television viewing, and science magazine reading all promote positive perceptions of science, given the relative size of its audience, the impact of general television viewing remains the most compelling finding. The negative images of science on television appear to cultivate scientific reservations, whereas television's portrayal of science as sometimes omnipotent, and offering hope for the future, appears to also promote a competing schema related to the promise of science. Television's direct effect on reservations is reinforced through the medium's negative relationship with science knowledge.},
	language = {en},
	number = {5},
	urldate = {2021-07-11},
	journal = {Communication Research},
	author = {Nisbet, Matthew C. and Scheufele, Dietram A. and Shanahan, James and Moy, Patricia and Brossard, Dominique and Lewenstein, Bruce V.},
	month = oct,
	year = {2002},
	note = {Publisher: SAGE Publications Inc},
	pages = {584--608},
}

@article{liu_understanding_2009,
	title = {Understanding public support for stem cell research: media communication, interpersonal communication and trust in key actors},
	volume = {18},
	issn = {0963-6625},
	shorttitle = {Understanding public support for stem cell research},
	url = {https://doi.org/10.1177/0963662508097625},
	doi = {10.1177/0963662508097625},
	abstract = {This paper analyzes data from a 2005 telephone survey of 1200 people in the US that included questions about attitudes toward stem cell research and a broad range of communication variables. After all controls, trust in university scientists and religious leaders, exposure to national television news, familiarity, and religious service attendance produced statistically significant main effects on perception of research benefits, together explaining about 31\% of the variance. Interpersonal communication may also have contingent effects.},
	language = {en},
	number = {6},
	urldate = {2021-07-11},
	journal = {Public Understanding of Science},
	author = {Liu, Hui and Priest, Susanna},
	month = nov,
	year = {2009},
	note = {Publisher: SAGE Publications Ltd},
	keywords = {interpersonal communication, media exposure, public opinion, stem cell research, trust},
	pages = {704--718},
}
